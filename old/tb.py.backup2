#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Effective tight binding module
by Daniel Jung"""
# 06/01/2011-07/06/2011
import commands as cm
import glob
import inspect
import itertools as it
import optparse as opt
import os
import platform as pf
#import pyximport; pyximport.install(); import tbc
import re
import sys
import time
import h5py as hdf
import numpy as np
import numpy.random as rd
import scipy as sp
import scipy.fftpack as fp
import scipy.linalg as la
import scipy.sparse as spa
import scipy.sparse.linalg as sla
import scipy.stats as st
#import tbc
import scipy.optimize as opti

# Exclude these classes from instanciating automatically
noprocs = ['_List']

# Define call routine
def call():
  # 06/01/2011
  # This function has to be called by the scripts, passing the command line
  # with all command line arguments. The first argument is the name of the
  # calling script (plus path, has to be removed), deciding what function
  # has to be called.

  # Separate arguments from script name
  cl = basename(sys.argv[0], '.py')

  # Call function that corresponds to the script
  obj = eval('_'+capitalize(cl))()
  obj.funcmode = False
  obj()

  # Return with positive exit status
  return 0





#==============================#
# General function definitions #
#==============================#

def basename(path, suffix=''):
  """My variation of os.path.basename, in which a given suffix can be canceled
  out (like in the php version of this function)."""
  # 06/01/2011-28/01/2011
  # former mytools.basename() from 05/01/2010
  basename = os.path.basename(path)
  suffixlen = len(suffix)
  if suffixlen > 0:
    if basename[-suffixlen:] == suffix:
      basename = basename[:-suffixlen]
  return basename



def capitalize(string):
  """Return string with first letter uppercase and the rest of the characters
  lowercase."""
  # 28/01/2011
  if not typename(string) == 'str':
    raise TypeError, 'string expected'
  return string[:1].upper()+string[1:].lower()



def dump(*args, **kwargs):
  """Print values of the passed arguments to the screen, together with additional information
  about the value, like length or shape of a list or an array. The name of the value can be
  specified by using keyword arguments."""
  # 10/01/2011-06/04/2011
  # former mytools.dump from 20/04/2010
  for arg in args:
    if typename(arg) == 'ndarray':
      print arg.shape, arg
    elif typename(arg) == 'list':
      print len(arg), arg
    else:
      print arg
  for key, value in kwargs.iteritems():
    if typename(value) == 'ndarray':
      print key, value.shape, value
    elif typename(value) == 'list':
      print key, len(value), value
    else:
      print key, value



class struct(object):
  """Basic class that offers structure-/record-like behavior.
  Has all properties of a normal dictionary, but in addition the values may
  be accessed like class variables (like in "obj.value").
  Furthermore, the keys are always sorted alphabetically when accessing the
  contents of an instance of struct."""
  # 24/01/2011-06/04/2011

  def __init__(self, *args, **kwargs):
    for arg in args:
      if typename(arg) == 'dict' or typename(arg) == 'struct':
        self.update(arg)
      else:
        raise TypeError

    for kwarg in kwargs:
      setattr(self, kwarg, kwargs[kwarg])

  def __str__(self):
    return ', '.join([str(s)+'='+str(self.__dict__[s]) for s in self.keys()])

  def __iter__(self):
    keys = self.keys()
    for key in keys:
      yield key

  def __repr__(self):
    return self.__class__.__name__+'('+', '.join([str(s)+'='+repr(self.__dict__[s]) for s in self.keys()])+')'

  def __len__(self):
    return len(self.__dict__)

  def __setitem__(self, key, value):
    setattr(self, key, value)

  def __getitem__(self, key):
    return self.__dict__[key]

  def __delitem__(self, key):
    delattr(self, key)

  def keys(self):
    keys = self.__dict__.keys()
    keys.sort()
    return keys

  def values(self):
    keys = self.__dict__.keys()
    keys.sort()
    return tuple([self[key] for key in keys]) #self.__dict__.values()

  def has_key(self, key):
    return self.__dict__.has_key(key)

  def get(self, key, default=None):
    return self.__dict__.get(key, default)

  def clear(self):
    return self.__dict__.clear()

  def setdefault(self, key, default):
    return self.__dict__.setdefault(key, default)

  def iterkeys(self):
    return self.__dict__.iterkeys()

  def itervalues(self):
    return self.__dict__.itervalues()

  def iteritems(self):
    return self.__dict__.iteritems()

  def pop(self, key, default=None):
    return self.__dict__.pop(key, default)

  def popitem(self):
    return self.__dict__.popitem()

  def copy(self):
    return struct(self.__dict__)

  def update(self, *args, **kwargs):
    for arg in args:
      if typename(arg) == 'struct':
        self.__dict__.update(arg.__dict__)
      elif typename(arg) == 'dict':
        self.__dict__.update(arg)
      else:
        raise TypeError
    self.__dict__.update(kwargs)

  def __iadd__(self, other):
    self.update(other)
    return self

  def __contains__(self, key):
    return key in self.__dict__

  def __eq__(self, other):
    if not typename(other) == 'struct' and not typename(other) == 'dict':
      raise NotImplementedError, 'comparison only possible with other being an instance of struct or dict'
    if typename(other) == 'struct':
      return self.__dict__ == other.__dict__
    else:
      return self.__dict__ == other

  def __ne__(self, other):
    return not self == other

  def intersection(self, *others):
    """Return a new structure that contains only elements that are common to all
    of the input structures (with values all being equal)."""
    # 07/02/2011

    # Check type of input arguments
    for index, o in enumerate(others):
      if not typename(o) in ['struct', 'dict']:
        raise TypeError, 'input argument no. %i is neither of type struct, nor of type dict' % (index+1)

    # Initialize output structure
    output = self.copy()

    # Go through the other structures and kick out all elements that are not
    # present in this structure, or that do not contain the same values
    for other in others:
      for okey in output.copy():
        if not okey in other:
          del(output[okey])
        else:
          if not equal(output[okey], other[okey]):
            del(output[okey])

    # Return new structure
    return output

  def __and__(self, other):
    """Implement ampersand operator (&). Return new struct that only contains
    elements that are common to both of the input structures (with values all
    being equal)."""
    # 07/02/2011
    return self.intersection(other)



def isiterable(obj):
  """Checks if an object is iterable. Returns True for lists, tuples and
  dictionaries. Returns False for scalars (float, int, etc.), strings, bool
  and None."""
  # 27/01/2011
  # former mytools.isiterable
  # Inicial idea from:
  # http://bytes.com/topic/python/answers/514838-how-test-if-object-sequence-iterable
  #return isinstance(obj, basestring) or getattr(obj, '__iter__', False)
  # I found this to be better:
  return not getattr(obj, '__iter__', False) == False



def opt2range(opt, lower=None, upper=None):
  """Return list of integers as specified by an option string of the form
  "x:y:z". z has to be a positive integer, x and y have to be non-negative
  integers. Use lower and upper to define the lower and upper limits. In this
  way, the user can specify ranges by leaving x or y empty."""
  # 29/01/2011-24/02/2011
  assert typename(opt) == 'str', 'string input required'
  strlist = opt.split(':')
  if len(strlist) > 0 and strlist[0] == '' and lower != None:
    strlist[0] = int(lower)
  if len(strlist) > 1 and strlist[1] == '' and upper != None:
    strlist[1] = int(upper)
  intlist = [int(m) if m != '' else 0 for m in strlist]
  assert len(intlist) in [1, 2, 3], 'bad order range: %s. Only one, two or three values may be given, separated by a colon (:)' % opt
  if len(intlist) < 2:
    intlist.append(intlist[0]+1)
  if len(intlist) < 3:
    intlist.append(1)
  assert all([b >= 0 for b in intlist]), 'bad order range: Only positive integers or zero allowed.'
  result = range(*intlist)
  result.sort()
  return result



def opt2ranges(opt, lower=None, upper=None):
  """Return list of integers as specified by an option string of the form
  "x1:y1:z1,x2:y2:z2,...". Each z has to be a positive integer, x and y have to
  be positive integers or zero. Use lower and upper to define the lower and
  upper limits for the ranges. In this way, the user can specify ranges by
  leaving x or y empty."""
  # 29/01/2011-24/02/2011
  assert typename(opt) == 'str', 'string input required'
  rangelist = opt.split(',')
  resultset = set()
  for rangestr in rangelist:
    resultset.update(opt2range(rangestr, lower=lower, upper=upper))
  result = list(resultset)
  result.sort()
  return result



def opt2list(opt, dtype=int):
  """Return list of values as specified by an option string of the form
  "x1,x2,x3,x4,x5". dtype specifies the type of the values (int, float,
  str, etc.). Default: int."""
  # 31/01/2011
  assert typename(opt) == 'str', 'string input required'
  if opt == '':
    return []
  else:
    if dtype == str:
      result = []
      for r in opt.split(','):
        if not r == '':
          result.append(r)
      return result
    else:
      return [dtype(value) if value != '' else dtype(0) for value in opt.split(',')]



def sepnumstr(string):
  """Separate numeric values from characters in a string. Return resulting
  numeric values and character strings as a list."""
  # 03/02/2011-06/04/2011
  if not typename(string) == 'str':
    raise TypeError, 'string expected'

  # If string is empty, just return empty list
  if string == '':
    return []

  numchars = '-0123456789.' # characters that belong to a numeric value
  result = []
  currval = '' # current value
  currisnum = string[0] in numchars # if current value is numeric
  for char in string:
    if (char in numchars) == currisnum:
      currval += char
    else:
      if currisnum:
        if currval == '.':
          result.append(0.)
        elif '.' in currval:
          result.append(float(currval))
        else:
          result.append(int(currval))
      else:
        result.append(currval)
      currval = char
      currisnum = not currisnum

  # Add last value
  if currisnum:
    if currval == '.':
      result.append(0.)
    elif '.' in currval:
      result.append(float(currval))
    else:
      result.append(int(currval))
  else:
    result.append(currval)

  # Return result
  return result



def equaltype(seq):
  """Test if all elements of the sequence or set have the same type."""
  # 30/03/2011
  seq = list(seq)
  first = seq.pop()
  for element in seq:
    if typename(element) != typename(first):
      return False
  return True

def allscalar(seq):
  """Test if all elements of the sequence or set are scalar."""
  # 30/03/2011
  for element in seq:
    if isiterable(element):
      return False
  return True

def anyobject(seq):
  """Test if any element of the sequence or set is an instance of a
  user-defined class."""
  # 30/03/2011
  for element in seq:
    if isobject(element):
      return True
  return False

def savehdf(hdfobj, key=None, data=None, **kwargs):
  """Add data to a HDF5 file using h5py. Handles almost any native Python
  type, also nested lists and tuples, sets and dictionaries, as well as Numpy
  arrays. Sequenze types can also be empty (but Numpy arrays not), None and boolean
  values are also supported."""
  # 05/02/2011-30/03/2011
  if key != None and data != None:
    kwargs[key] = data
  for key, data in kwargs.iteritems():
    dtype = typename(data)
    ktype = typename(key)

    # Check key type
    if ktype != 'str':
      key = repr(key)

    # Delete preexisting key to overwrite existing data
    if key in hdfobj:
      del(hdfobj[key])

    # Distinguish different data types
    if dtype == 'NoneType':
      newobj = hdfobj.create_dataset(key, data=repr(data))
    elif dtype == 'bool':
      newobj = hdfobj.create_dataset(key, data=data)
    elif dtype in ('int', 'long', 'float', 'float64', 'complex'):
      #if dtype == 'float64':
      #  data = float(data)
      newobj = hdfobj.create_dataset(key, data=data)
    elif dtype == 'str':
      newobj = hdfobj.create_dataset(key, data=data)
    elif dtype in ('list', 'tuple'):
      if len(data) == 0:
        newobj = hdfobj.create_dataset(key, data=repr(eval(dtype+'()')))
      elif allscalar(data) and equaltype(data) and not anyobject(data):
        newobj = hdfobj.create_dataset(key, data=data)
      else:
        newobj = hdfobj.create_group(key)
        newkeys = ['key'+str(k) for k in xrange(len(data))]
        savehdf(newobj, **dict(zip(newkeys, data)))
    elif dtype in ('set', 'frozenset'):
      if len(data) == 0:
        newobj = hdfobj.create_dataset(key, data=dtype+'()')
      elif allscalar(data) and equaltype(data):
        newobj = hdfobj.create_dataset(key, data=tuple(data))
      else:
        newobj = hdfobj.create_group(key)
        newkeys = ['key'+str(k) for k in xrange(len(data))]
        savehdf(newobj, **dict(zip(newkeys, tuple(data))))
    elif dtype == 'dict':
      newobj = hdfobj.create_group(key)
      for k, d in data.iteritems():
        savehdf(newobj, key=k, data=d)
    elif dtype == 'struct':
      newobj = hdfobj.create_group(key)
      savehdf(newobj, **data)
    elif dtype in ('ndarray', 'matrix'):
      if 0 in data.shape:
        # Empty array or matrix. Save string representation
        newobj = hdfobj.create_dataset(key, data=repr(data))
      else:
        newobj = hdfobj.create_dataset(key, data=data)
    elif dtype in ('csc_matrix', 'csr_matrix', 'bsr_matrix', 'lil_matrix', 'dok_matrix', 'coo_matrix', 'dia_matrix'):
      if dtype != 'csr_matrix':
        # Convert to csr_matrix:
        data = data.tocsr()
      newobj = hdfobj.create_group(key)
      savehdf(newobj, key='data', data=data.data, indices=data.indices, indptr=data.indptr, shape=data.shape)
    elif hasattr(data, '__dict__'):
      # If the object offers a dictionary, save this and hope it will be enough
      # to reconstruct the object.
      newobj = hdfobj.create_group(key)
      savehdf(newobj, **data.__dict__)
    else:
      raise TypeError, 'datatype not supported: %s' % dtype

    # Save attributes
    newobj.attrs.create('DATE', time.ctime())
    newobj.attrs.create('DTYPE', dtype)
    newobj.attrs.create('KTYPE', ktype)

def loadhdf(hdfobj, *keys):
  """Load data from HDF5 file using h5py. Handles almost any native Python
  type, also nested lists and tuples, sets and dictionaries, as well as Numpy
  arrays. Sequenze types can also be empty (but Numpy arrays not), None and boolean
  values are also supported."""
  # 05/02/2011-30/03/2011
  values = []
  for key in keys:
    if key in hdfobj:
      obj = hdfobj[key]

      # Load attributes
      if 'DTYPE' in obj.attrs:
        dtype = obj.attrs.get('DTYPE')
      elif hasattr(obj, 'value'):
        dtype = typename(obj.value)
      else:
        # Assume it is a struct. In this way, param group can be loaded without
        # error message
        dtype = 'struct'
        #raise TypeError, 'group without DTYPE attribute found: %s' % obj.name

      # Distinguish different data types
      if dtype == 'NoneType':
        value = eval(obj.value)
      elif dtype == 'bool':
        value = obj.value
      elif dtype in ('int', 'long', 'float', 'complex'):
        value = eval(dtype)(obj.value)
      elif dtype == 'str':
        value = str(obj.value)
      elif dtype in ('list', 'tuple'):
        if typename(obj) == 'Group':
          ks = obj.keys()
          ks.sort()
          value = []
          for k in ks:
            value.append(loadhdf(obj, k))
          value = eval(dtype)(value)
        elif typename(obj.value) == 'str':
          # Empty lists and tuples
          value = eval(dtype)(eval(obj.value))
        else:
          # Lists and tuples that were saved as a 1D ndarray
          value = eval(dtype)(obj.value)
      elif dtype in ('set', 'frozenset'):
        if typename(obj) == 'Group':
          ks = obj.keys()
          value = []
          for k in ks:
            value.append(loadhdf(obj, k))
          value = eval(dtype)(value)
        elif typename(obj.value) == 'str':
          # Empty sets and frozensets
          value = eval(dtype)(eval(obj.value))
        else:
          # Sets and frozensets that were saved as a 1D ndarray
          value = eval(dtype)(obj.value)
      elif dtype == 'dict':
        assert typename(obj) == 'Group'
        ks = obj.keys()
        value = {}
        for k in ks:
          if 'KTYPE' in obj[k].attrs:
            ktype = obj[k].attrs.get('KTYPE')
          else:
            ktype = 'str'
          if ktype == 'str':
            value[k] = loadhdf(obj, k)
          else:
            value[eval(k)] = loadhdf(obj, k)
      elif dtype == 'struct':
        assert typename(obj) == 'Group'
        ks = obj.keys()
        value = struct()
        for k in ks:
          value[k] = loadhdf(obj, k)
      elif dtype == 'ndarray':
        if typename(obj.value) == 'str':
          # Empty array
          string = obj.value
          string = 'np.'+string
          ind = string.find('dtype=')
          if ind >= 0:
            string = string[:(ind+6)]+'np.'+string[(ind+6):]
          value = eval(string)
        else:
          value = np.array(obj.value)
      elif dtype == 'matrix':
        if typename(obj.value) == 'str':
          # Empty matrix
          string = obj.value
          string = 'np.'+string
          ind = string.find('dtype=')
          if ind >= 0:
            string = string[:(ind+6)]+'np.'+string[(ind+6):]
          value = eval(string)
        else:
          value = np.matrix(obj.value)
      elif dtype in ('csc_matrix', 'csr_matrix', 'bsr_matrix', 'lil_matrix', 'dok_matrix', 'coo_matrix', 'dia_matrix'):
        shape = loadhdf(obj, 'shape')
        value = spa.csr_matrix(shape)
        value.indptr = loadhdf(obj, 'indptr')
        value.indices = loadhdf(obj, 'indices')
        value.data = loadhdf(obj, 'data')

        # Convert to respective sparse matrix format
        if dtype != 'csr_matrix':
          value = getattr(value, 'to'+dtype[:3])()
      elif dtype in ('SuperCell', 'Lattice', 'Neighbor', 'Site'):
        assert typename(obj) == 'Group'
        ks = obj.keys()
        value = eval(dtype)(3) # The dimensionality will be overwritten anyway
        for k in ks:
          value.__dict__[k] = loadhdf(obj, k)
      else:
        # Try to create an instance of a user-defined class
        assert typename(obj) == 'Group'
        ks = obj.keys()
        value = eval(dtype)()
        for k in ks:
          value.__dict__[k] = loadhdf(obj, k)

      # Append to list and continue
      values.append(value)
    else:
      raise KeyError, 'no key named %s in HDF5 file object' % key

  # Return values
  if len(values) == 1:
    return values[0]
  else:
    return values

def expandstr(string, length=None, char=' ', flip=False):
  """Return the string, but expand it to the given length with the given character.
  If flip is True, fill characters in front of string instead of behind it."""
  # 09/02/2011
  # former mytools.expandstr
  string = str(string)
  lenght = int(length)

  l = len(string)
  if length == None:
    length = l

  output = ''

  if flip:
    output += char*(length-l)
    output += string
  else:
    output += string
    output += char*(length-l)

  return output



def equal(*objects):
  """My version of the function "all" with equality check (==), that
  works with all types of objects, even with scalars and nested lists."""
  # 09/02/2011
  # former mytools.equal
  if len(objects) > 2:
    a = objects[0]
    for b in objects[1:]:
      if not equal(a, b):
        return False
    return True
  assert len(objects) == 2, 'at least two objects have to be specified'
  a, b = objects

  if not isiterable(a) and not isiterable(b):
    return a == b
  elif isiterable(a) and isiterable(b):
    if not isobject(a) and not isobject(b):
      if not len(a) == len(b):
        return False
      else:
        for i in xrange(len(a)):
          if not equal(a[i], b[i]):
            return False
        return True
    elif isobject(a) and isobject(b):
      return a.__dict__ == b.__dict__
    else:
      return False
  else:
    return False



def isobject(obj):
  # 09/02/2011
  # former mytools.isobject
  return not getattr(obj, '__dict__', False) == False



def eqlist(**dictionary):
  """Print a dictionary to stdout as a list of elements in the form
  "key = value", aligning all equality signs. Also the contents are nicely
  formatted in this way. If keyword maxshape is specified, only display the
  contents of those numpy arrays that do not have a dimension larger than this
  value. Instead, just note the shape of the array. For sparse matrices,
  maxshape gives the maximum number of nonzero elements. If the keyword dense
  is set to True, sparse matrices are converted to dense matrices first."""
  # 10/02/2011-24/02/2011

  # Handle special keyword arguments
  if 'maxshape' in dictionary:
    maxshape = dictionary.pop('maxshape')
  else:
    maxshape = 15 # Default value
  if 'dense' in dictionary:
    dense = dictionary.pop('dense')
  else:
    dense = False # Default value

  # Local function definition
  def strrep(value, indent=0):
    """Return string representation of value, but in multirow format,
    with the given indentation after each line break."""

    # Is value a sparse matrix, and has the dense keyword been set to True?
    if typename(value) in ['csr_matrix', 'csc_matrix'] and dense:
      value = value.todense()

    # 10/02/2011
    if typename(value) == 'list':
      if 'list' in types(value) or 'tuple' in types(value) or 'dict' in types(value) or 'struct' in types(value) or 'ndarray' in types(value):
        return '['+(',\n'+' '*(indent+1)).join(strrep(v, indent=indent+1) for v in value)+']'
      else:
        if len(value) <= maxshape:
          return str(value)
        else:
          return 'list of length '+str(len(value))
    elif typename(value) == 'tuple':
      if 'list' in types(value) or 'tuple' in types(value) or 'dict' in types(value) or 'struct' in types(value) or 'ndarray' in types(value):
        return '('+(',\n'+' '*(indent+1)).join(strrep(v, indent=indent+1) for v in value)+')'
      else:
        if len(value) <= maxshape:
          return str(value)
        else:
          return 'tuple of length '+str(len(value))
    elif typename(value) == 'dict':
      # Build key-value pairs
      if len(value) > 0:
        maxkeylen = max([len(key) for key in value])
      else:
        maxkeylen = 0
      kvpairs = []
      for key in value:
        kvpairs.append(expandstr(key, length=maxkeylen)+': '+strrep(value[key], indent=indent+1+maxkeylen+2))
      #maxpairlen = max([len(p) for p in kvpairs])
      return '{'+(',\n'+' '*(indent+1)).join(kvpairs)+'}'
    elif typename(value) == 'struct':
      # Build key-value pairs
      if len(value) > 0:
        maxkeylen = max([len(key) for key in value])
      else:
        maxkeylen = 0
      kvpairs = []
      for key in value:
        kvpairs.append(expandstr(key, length=maxkeylen)+' = '+strrep(value[key], indent=indent+7+maxkeylen+3))
      #maxpairlen = max([len(p) for p in kvpairs])
      return 'struct('+(',\n'+' '*(indent+7)).join(kvpairs)+')'
    elif typename(value) in ['ndarray', 'matrix']:
      # Distinguish different dimensionalities
      #if len(value.shape) < 2:
      #  strvalue = str(value)
      #else:
      # Only print the contents of an array if it is not too big
      if np.all(np.array(value.shape) <= maxshape):
        strvalue = str(value)
      else:
        strvalue = 'ndarray with shape '+str(value.shape)

      # Make sure that the string representation of the array has
      # the right indentation at each line break
      if '\n' in strvalue:
        l = [s.strip() for s in strvalue.split('\n')]
        strvalue = ('\n'+' '*(indent+1)).join(l)

      # Return string representation of the array
      return strvalue
    elif typename(value) in ['csr_matrix', 'csc_matrix', 'lil_matrix', 'dia_matrix', 'coo_matrix', 'bsc_matrix', 'dok_matrix']:
      strvalue = repr(value)

      # Show data if number of nonzero elements not bigger than maxshape
      if value.nnz <= maxshape:
        """lines = str(value).split('\n')
        strarray = []
        for line in lines:
          strarray.append(line.split('\t'))
        strarray = np.array(strarray)
        maxlen0 = max([len(s) for s in strarray[:, 0]])
        maxlen1 = max([len(s) for s in strarray[:, 1]])
        for row in strarray:
          str0 = expandstr(row[0], length=maxlen0)
          str1 = expandstr(row[1], length=maxlen1, flip=True)
          strvalue += '\n'+str0+' = '+str1"""
        value = value.tocoo()
        maxrowlen = max([len(str(r)) for r in value.row])
        maxcollen = max([len(str(c)) for c in value.col])
        maxdatalen = max([len(str(d)) for d in value.data])
        for row, col, data in zip(value.row, value.col, value.data):
          rowstr = expandstr(row, length=maxrowlen, flip=True)
          colstr = expandstr(col, length=maxcollen, flip=True)
          datastr = expandstr(data, length=maxdatalen, flip=True)
          strvalue += '\n(%s, %s) = %s' % (rowstr, colstr, datastr)

      # Make sure that the string representation of the array has
      # the right indentation at each line break
      if '\n' in strvalue:
        l = [s.strip() for s in strvalue.split('\n')]
        strvalue = ('\n'+' '*indent).join(l)

      # Return string representation of the array
      return strvalue
    else:
      return str(value)

  # Print to stdout
  if len(dictionary) == 0:
    return False
  maxkeylen = max([len(key) for key in dictionary])
  keys = dictionary.keys()
  keys.sort()
  for key in keys:
    print expandstr(key, length=maxkeylen)+' = '+strrep(dictionary[key], indent=maxkeylen+3)



def npc():
  """Return number of processor cores of this machine. Supported operating
  systems: Linux/Unix, MacOS, Windows."""
  # 10/02/2011
  # former mytools.detectCPUs
  # based on code from http://www.boduch.ca/2009/06/python-cpus.html

  # Linux, Unix and Mac OS
  if hasattr(os, 'sysconf'):
    if os.sysconf_names.has_key('SC_NPROCESSORS_ONLN'):
      # Linux and Unix
      npc = os.sysconf('SC_NPROCESSORS_ONLN')
      if isinstance(npc, int) and npc > 0:
        return npc
    else:
      # Mac OS:
      return int(os.popen2('sysctl -n hw.ncpu')[1].read())

  # Windows
  if os.environ.has_key('NUMBER_OF_PROCESSORS'):
    npc = int(os.environ['NUMBER_OF_PROCESSORS'])
    if npc > 0:
      return npc

  # Otherwise, return default value
  return 1

def com(x, y=None):
  """Return a unique "combination value" of two integers.
  Also accepts vectors (1D arrays) of integers.
  Must be integers between 0 and 15. If y is omitted, y = x is
  assumed. Returns scalar integer between 0 and 255.
  x and y must contain integers between 0 and 15, so that there are only 256 possible
  combinations and the data type numpy.ubyte is sufficient to hold the returned value. Thus, only
  systems with up to 16 different atom species and each of it having 16 different orbital species
  are allowed."""
  # 10/01/2011
  # former mytools.combination
  if y == None:
    y = x
  x = np.array(x, dtype=np.uint8)
  y = np.array(y, dtype=np.uint8)
  if len(x.shape) == 0:
    x = np.array([x])
  if len(y.shape) == 0:
    y = np.array([y])
  assert len(x.shape) < 2 and len(y.shape) < 2, 'bad input values: Only 0- and 1-dimensional data structures allowed (scalars and vectors)'
  assert np.all(x >= 0) and np.all(x <= 15) and np.all(y >= 0) and np.all(y <= 15), 'bad input values: All input values must be integers between 0 and 15.'
  result = x[:, None]+16*y
  result = result.squeeze()
  if len(result.shape) == 0:
    return int(result)
  else:
    return result

#def sep

def typename(value):
  """Return name of the type of value."""
  # 10/02/2011
  return type(value).__name__

def dist(a, b, decimals=1):
  """Return distance matrix of two position lists. The returned square
  matrix will contain the Euclidian distances of all combinations of
  positions between the first and the second position list. If the second
  position list is omitted, return distances of all combinations of
  positions of the first list with itself.

  Requires two 2D arrays a and b with dimensions n_a x d and n_b x d.
  Returns square matrix with dimensions n_b x n_a. d is the dimensionality
  of the space where the positions live in (number of coordinates).

  If the keyword decimals is given, the results are rounded to the number
  of decimals (default is 1)."""
  # 10/02/2011
  # former mh.distance_matrix

  # If second argument was omitted, take first arguement instead
  if b == None:
    b = a

  # Make sure a and b are arrays
  a = np.array(a)
  b = np.array(b)

  # Get shapes of the position lists
  assert a.shape[1] == b.shape[1], 'bad position lists: both position lists have to contain coordinates with the same dimensionality, but one has %i and the other has %i' % (a.shape[1], b.shape[1])
  m, d = a.shape
  n = b.shape[0]

  delta = np.zeros((m, n))
  for dind in xrange(d): # Dimension index
    adata = a[:, dind]
    bdata = b[:, dind]
    delta += (adata[:, None]-bdata)**2
  return np.round(np.sqrt(delta), decimals=decimals)

def types(value):
  """Return list of typenames that the iterable value contains."""
  # 10/02/2011
  if not typename(value) in ['list', 'tuple', 'dict', 'struct']:
    raise TypeError, 'expecting value of type list, tuple, dict or struct'
  types = []
  for v in value:
    if typename(value) in ['dict', 'struct']:
      types.append(typename(value[v]))
    else:
      types.append(typename(v))
  return types



class Progress:
  """Display progress of a certain loop. Initialize before loop. Call step once
  in each loop. If loop is left early (break), or if you want to make sure the
  line break was done after the loop, call end. To reset the counter, call
  reset.

  On initialization, the number of iterations nstep must be specified.
  Additional keyword arguments:
  text  : User-defined text message (instead of "Progress")
  width : Width of the current shell window. Default: 80

  Future ideas:
  - Find window width automatically (at least possible on unix-like systems)
  - Multiple progress bars at once, to show status of multiple subprocesses
  - allow nested progress bars, passing and multiplying step numbers to the
    next instance"""
  # 13/02/2011-29/04/2011

  def __init__(self, nstep, text='Progress', width=80, verbose=True):
    self._nstep = nstep
    self._step = 0
    self._oldstr = ''
    self._end = False
    self._text = text
    self._width = width
    self._verbose = verbose

    if self._nstep == 0:
      self._verbose = False

    if not self._verbose:
      return
    self.write()

  def step(self):
    if not self._verbose:
      return
    if self._step < self._nstep:
      self._step += 1
      self.write()

  def reset(self):
    if not self._verbose:
      return
    self._step = 0
    self.write()
    if self._end:
      self._end = False

  def write(self):
    if not self._verbose:
      return
    if self._nstep == 1:
      # Just say "done" at the end.
      newstr = self._text+': '
      if self._step == 1:
        newstr += 'Done.'
      if newstr != self._oldstr:
        sys.stdout.write('\r'+newstr)
      if self._step == self._nstep:
        self.end()
      sys.stdout.flush()
      self._oldstr = newstr
    else:
      barlen = self._width-9-len(self._text)-1 # Length of the progress bar
      newstr = self._text+': '+expandstr(int(np.round(float(self._step)/self._nstep*100)), 3, flip=True)+'%'
      if barlen > 0:
        newstr += ' ['+expandstr('='*int(np.round(float(self._step)/self._nstep*barlen)), barlen)+']'
      if newstr != self._oldstr:
        sys.stdout.write('\r'+newstr)
      if self._step == self._nstep:
        self.end()
      sys.stdout.flush()
      self._oldstr = newstr

  def end(self):
    if not self._verbose:
      return
    if not self._end:
      sys.stdout.write('\n')
      self._end = True

  def __del__(self):
    self.end()

class Monitor():
  """Monitor the values of certain variables within a loop. Update the line by
  using carriage return each time the step method is called. Do this until
  the end method is called.

  Future ideas:
  - Maybe could keep the order of the arguments as specified
  - To fulfill the above, maybe abandon positional arguments and use them in
    the constructor to define the order the keyword arguments should always
    be presented in
  - remember the maximum length the string representations had before, so no
    wobbling around anymore"""
  # 26/05/2011
  def __init__(self, *args, **kwargs):
    # Fetch special keyword arguments
    try:
      self._width = kwargs.pop('width')
    except KeyError:
      self._width = 80
    try:
      self._verbose = kwargs.pop('verbose')
    except KeyError:
      self._verbose = True
    try:
      self._floatf = kwargs.pop('floatf')
    except KeyError:
      self._floatf = '%.2f'
    try:
      self._sep = kwargs.pop('sep')
    except KeyError:
      self._sep = '   '
    try:
      self._order = kwargs.pop('order') #.split(',')
    except KeyError:
      self._order = []

    # Store the remaining arguments
    self._args = args
    self._kwargs = kwargs

    # Define additional attributes
    self._oldstr = ''
    self._end = False

    # Do not do anything if no arguments were given
    #if len(args) == 0 and len(kwargs) == 0:
    #  self._verbose = False
    if not self._verbose:
      return

    # First output already on initialisation
    self.write()

  def step(self, *args, **kwargs):
    # Only update values if in verbose mode
    if not self._verbose:
      return

    # Update values
    self._args = args # Hmm, not good...
    self._kwargs.update(kwargs)

    # Write current values
    self.write()

  def end(self):
    # Only execute if verbose is set to True
    if not self._verbose:
      return

    # Do the line break (if not already done)
    if not self._end:
      sys.stdout.write('\n')
      self._end = True

  def reset(self):
    """to reuse this object"""

    # Only do something in verbose mode
    if not self._verbose:
      return

    # Reset this instance
    self.write()
    if self._end:
      self._end = False

  def write(self):
    # Only write if in verbose mode
    if not self._verbose:
      return

    # Define conversion logic
    def convert(obj, floatf):
      if typename(obj) in ['str', 'int']:
        return str(obj)
      elif typename(obj).startswith('float'):
        return floatf.__mod__(obj)
      else:
        return str(obj)

    # Collect all string representations in a list
    strlist = []
    for arg in self._args:
      strlist.append(convert(arg, self._floatf))

    # First, collect the keyword arguments whose keyword exists in the order list
    kwargs = self._kwargs.copy()
    for kw in self._order:
      try:
        arg = kwargs.pop(kw)
        strlist.append(kw+'='+convert(arg, self._floatf))
      except KeyError:
        pass

    # Then, collect the rest of the keyword arguments for which the order was
    # not defined
    for kw, arg in kwargs.iteritems():
      strlist.append(kw+'='+convert(arg, self._floatf))

    # Convert list to string and write it (if it has changed)
    newstr = self._sep.join(strlist)
    newstr += ' '*(self._width-1-len(newstr))
    newstr = newstr[:(self._width-1)] # Truncate the rest to avoid display errors
    if newstr != self._oldstr:
      # Do carriage return first to overwrite the current line
      sys.stdout.write('\r'+newstr)
      sys.stdout.flush()
    self._oldstr = newstr

  def __del__(self):
    self.end()




def printcols(strlist):
  """print the given list of strings in column format (i.e. like the bash
  command ls), respecting the width of the shell window."""
  # 13/02/2011
  # former mytools.printcols
  numstr = len(strlist)

  # Try to get the width of the shell window (may fail on Windows)
  try:
    cols = int(cm.getoutput('tput cols'))-1
  except ValueError:
    cols = 80

  # Determine the maximum string width
  maxwidth = max([len(s) for s in strlist])

  # Calculate number of columns
  numcols = cols/(maxwidth+2)

  # Calculate number of required rows
  numrows = int(np.ceil(1.*numstr/numcols))

  # Print
  for rind in xrange(numrows):   # Row index
    for cind in xrange(numcols): # Column index
      sind = cind*numrows+rind   # String list index
      if sind < numstr:
        print strlist[sind]+' '*(maxwidth-len(strlist[sind])+1),
    print

def humanbytes(bytes):
  """Return given byte count (integer) in a human readable format (string).
  Example: 664070 --> 649Ki.
  Supported binary prefixes: kibi, mebi, gibi, tebi, pebi, exbi, zebi, yobi."""
  # 13/02/2011
  # former mytools.humanbytes
  assert typename(bytes) in ['int', 'long'], 'integer expected, but value of type %s given' % typename(bytes)
  assert bytes >= 0, 'bad byte count: %i. Must be positive integer or zero' % bytes

  # Define units
  unittable = {0: '', 1: 'Ki', 2: 'Mi', 3: 'Gi', 4: 'Ti', 5: 'Pi', 6: 'Ei', 7: 'Xi', 8: 'Yi'}

  # Calculate human readable string representation
  i = bytes
  u = 0
  while i > 1024:
    if not u+1 in unittable:
      break
    i = int(round(float(i)/1024))
    u += 1
  return str(i)+unittable[u]

def jackson(value, n=None, trunc=None):
  """Apply Jackson kernel factor g_n to value. trunc is the truncation number. If trunc
  is not set, set trunc = len(value). If n is not set, set n = range(trunc)."""
  # 16/02/2011-24/02/2011
  if isiterable(value):
    # Get and check value and parameters
    assert len(value) > 0, 'bad value. len(value) > 0 has to be satisfied'
    value = np.array(value)
    if n == None:
      n = np.arange(len(value))
    else:
      assert typename(n) == 'int', 'bad polynomial order n: %i. Must be integer'
      assert n >= 0, 'bad polynomial order n: %i. Must be non-negative integer' % n
      n = np.arange(n, len(value)+n)
    if trunc == None:
      trunc = len(value)
    else:
      assert typename(trunc) == 'int', 'bad truncation number. Must be integer'
      assert trunc > 0, 'bad truncation number: %i. Must be positive integer' % trunc
    assert np.all(n <= trunc), 'polynomial order n is greater than truncation number'

    # Calculate factors g_n
    g = ((trunc-n+1)*np.cos(np.pi*n/(trunc+1))+np.sin(np.pi*n/(trunc+1))/np.tan(np.pi/(trunc+1)))/(trunc+1)

    # Multiply values by g-factors and return result
    return (value.transpose()*g).transpose()
  else:
    # Get and check value and parameters
    assert typename(n) == 'int', 'bad polynomial order n: %i. Must be integer'
    assert n >= 0, 'bad polynomial order n: %i. Must be non-negative integer' % n
    assert typename(trunc) == 'int', 'bad truncation number. Must be integer'
    assert trunc > 0, 'bad truncation number: %i. Must be positive integer' % trunc
    assert n <= trunc, 'polynomial order n is greater than truncation number'

    # Calculate factors g_n
    g = ((trunc-n+1)*np.cos(np.pi*n/(trunc+1))+np.sin(np.pi*n/(trunc+1))/np.tan(np.pi/(trunc+1)))/(trunc+1)

    # Multiply values by g-factors and return result
    return value*g

def dirichlet(value, n=None, trunc=None):
  """Apply Dirichlet kernel factor g_n to value, which is always 1. In other words,
  the value is not changed by this function. The function only exists for the sake of
  completeness."""
  # 24/02/2011
  return value

def fejer(value, n=None, trunc=None):
  """Apply FejÃ©r kernel factor g_n to value. trunc is the truncation number. If trunc
  is not set, set trunc = len(value). If n is not set, set n = range(trunc)."""
  # 24/02/2011
  if isiterable(value):
    # Get and check value and parameters
    assert len(value) > 0, 'bad value. len(value) > 0 has to be satisfied'
    value = np.array(value)
    if n == None:
      n = np.arange(len(value))
    else:
      assert typename(n) == 'int', 'bad polynomial order n: %i. Must be integer'
      assert n >= 0, 'bad polynomial order n: %i. Must be non-negative integer' % n
      n = np.arange(n, len(value)+n)
    if trunc == None:
      trunc = len(value)
    else:
      assert typename(trunc) == 'int', 'bad truncation number. Must be integer'
      assert trunc > 0, 'bad truncation number: %i. Must be positive integer' % trunc
    assert np.all(n <= trunc), 'polynomial order n is greater than truncation number'

    # Calculate factors g_n
    g = 1.-n.astype(float)/trunc

    # Multiply values by g-factors and return result
    return (value.transpose()*g).transpose()
  else:
    raise NotImplemented, 'Handling scalars not yet supported'



def chebexpansion(x, mu, nt):
  """Carry out Chebyshev expansion to reconstruct a function f(x), given the moments mu.

  Future idea: Could allow user-defined discretization function (instead of cosine)."""
  # 21/02/2011
  return #(mu[0]+2*np.sum(mu[1:]*np.cos(np.pi*x



def scnnmat(dims, pot=0., hop=1., bcond='p', format='lil'):
  """Return Hamiltonian matrix of a simple dim-dimensional tight-binding system
  with dimensions "dims" (tuple of positive integers of length dim), site
  potentials "pot" (float or 1D-array of floats with length size = prod(dims)),
  constant isotropic next-neighbor hopping "hop" (float) and boundary conditions
  "bcond" (string consisting of characters "s", "p" and "a").
  Return matrix in a sparse format specified by "format".

  bcond may be at most of length dim. In this way, each dimension can have it's
  own boundary condition."""
  # 28/02/2011-31/03/2011

  # Check arguments
  assert format in ['lil', 'dok', 'csr', 'csc', 'dia', 'coo', 'bsr', 'dense'], 'unknown format. Must be one of lil, dok, coo, dia, csr, csc, bsr or dense'
  if isiterable(dims):
    dims = tuple(dims)
  else:
    dims = (dims,)
  size = np.prod(dims, dtype=int)
  dim = len(dims)
  assert dim > 0, 'bad dimensions tuple: Must have at least one element'

  # Check boundary condition string
  assert len(bcond) <= dim, 'bad boundary condition: %s. Number of given boundary conditions is greater than dimensionality of the system (%i)' % (bcond, dim)
  assert len(bcond) > 0, 'bad boundary condition: May not be empty string. At least one character (s, p or a) has to be given'
  if len(bcond) < dim:
    bcond += bcond[-1]*(dim-len(bcond))

  # Method:
  # 1. Build matrix of dims[:-1] recursevely, set the dims[-1] blocks with it
  # 2. Built matrix of dims[-1] recursevely, set stretched slices dims[:-1] times
  # That's it!
  # Now even better: Use scipy.sparse.kron for the first step. Use setdiag for the
  # second step. No for-loops needed anymore.

  # Step 1
  subdims = dims[:-1]
  subsize = np.prod(subdims, dtype=int)
  if subsize > 1:
    # Calculate submatrix recursevely
    mat = spa.kron(spa.eye(dims[-1], dims[-1]), scnnmat(subdims, hop=hop, bcond=bcond[:-1]), format='lil')
  else:
    # Initialize matrix
    mat = spa.lil_matrix((size, size))

  # Step 2
  # If periodic or anti-periodic boundary conditions are given, set respective
  # elements as well. Do this first, because they may be overwritten by the
  # direct hoppings in the next step.
  if bcond[-1] in ['p', 'a']:
    if bcond[-1] == 'p':
      bcondhoparray = np.ones((subsize))*(-hop)
    else:
      bcondhoparray = np.ones((subsize))*hop
    mat.setdiag(bcondhoparray, size-subsize)
    mat.setdiag(bcondhoparray, subsize-size)
  elif bcond[-1] == 's':
    # Do not set anything
    pass
  else:
    raise ValueError, 'bad boundary condition: %s. Expecting either "s" (static), "p" (periodic) or "a" (antiperiodic)' % bcond[-1]

  # Set off-diagonals with hopping
  hoparray = np.ones((size-subsize))*(-hop)
  mat.setdiag(hoparray, subsize)
  mat.setdiag(hoparray, -subsize)

  # Set diagonal elements with potential
  if isiterable(pot):
    pot = np.array(pot)
    assert len(pot.shape) == 1, 'potentials have wrong shape. Must be 1D-array-like'
    assert len(pot) == size, 'wrong number of potentials: Expecting %i, but got %i' % (size, len(pot))
    mat.setdiag(pot)
  else:
    if pot != 0.: # Save this step if potentials are zero anyway
      mat.setdiag(np.ones((size))*pot)

  # Convert matrix if needed
  if format != 'lil':
    mat = getattr(mat, 'to'+format)()

  # Return matrix
  return mat



class tic:
  """Implements a python version of the Matlab tic and toc functions."""
  # 27/02/2011

  def __init__(self):
    self._start = time.time()

  def toc(self):
    return time.time()-self._start





class SuperCell(object):
  """Define tight binding supercell, using an object-oriented user-interface.
  May contain multiple sites or whole lattices of sites. Each site may hold
  several entities.

  Future ideas:
  - maybe use numpy.allclose for the neighbor distance checks?
  """
  # 05/03/2011-31/03/2011

  def __init__(self, dim, label=None):
    # Dimensionality of the system
    dim = int(dim)
    assert dim > 0, 'dimensionality of the supercell must be positive integer'
    self.dim = dim

    # Label
    if label == None:
      self.label = typename(self) #+'%iD' % self.dim
    else:
      self.label = label

    # Margin, may be important for periodic boundary conditions
    self.margin = (0,)*dim

    # Boundary conditions
    self.bcond = 'p'*dim

    # List of sites
    self._sites = [] # List of objects

    # List of lattices
    self._lats = [] # List of objects

    # List of parameters (hoppings, potentials)
    self._params = [] # List of dictionaries or structs

    # Tolerance in finding the outermost sites
    # To apply periodic boundary conditions to lattices
    self.tol = .1 # Float

  def add_site(self, site=None, coord=None, label=None):
    """Add a site to the supercell, at any given coordinate."""

    if site == None:
      # Create a new instance
      site = Site(self.dim, coord=coord, label=label) #, stype=stype
    else:
      # An instance is already given by the site argument. So, just update certain values if needed
      ain(site.coord, coord)
      ain(site.label, label)

    # Store and return
    self._sites.append(site)
    return site

  def add_lat(self, lat=None, shape=None, bcond=None, origin=None, bvects=None, label=None):
    """Add a lattice to the supercell, containing multiple sites that are
    defined through a unitcell that is repeated periodically a specified number
    of times in each dimension."""
    if lat == None:
      # Create a new instance
      lat = Lattice(self.dim, shape=shape, bcond=bcond, origin=origin, bvects=bvects, label=label) #ltype=ltype,
    else:
      # An instance is already given by lat. Just update attributes if needed
      ain(lat.shape, shape)
      ain(lat.bcond, bcond)
      ain(lat.origin, origin)
      ain(lat.bvects, bvects)
      ain(lat.label, label)

    # Store and return
    self._lats.append(lat)
    return lat

  def hamilt(self, format='lil', verbose=False, recalc=False, pgroup='param', scdset='supercell', extension='.h5'): #, getcoords=False, gettypes=False
    """Calculate and return Hamiltonian matrix of the whole tight system,
    including all lattices and sites that were defined within the supercell."""

    if 'hlink' in self.__dict__:
      # Take the neighbor Hamiltonian from the other file, specified by hlink, and
      # just substitute the intra-cell hoppings and potentials by those of this file
      hlink = self.hlink
      if not os.path.isfile(hlink):
        hlink += extension
      if os.path.isfile(hlink): # What if this relative path cannot be reached because the call was made in a directory other than the current working directory?
        f = hdf.File(self.hlink, 'r+')
        if pgroup in f:
          if scdset in f[pgroup]:
            sc = loadhdf(f[pgroup], scdset)
          else:
            raise NameError, 'HDF5 file %s does not contain a dataset named %s in the group %s', (self.hlink, scdset, pgroup)
        else:
          raise NameError, 'no group named %s found in HDF5 file %s' % (pgroup, self.hlink)

        # Get number of lattices and sites that are defined in the supercell
        nl = len(self._lats)
        ns = len(self._sites)
        nt = nl+ns

        # Substitute random hoppings/potentials by those of this realization
        indmat = np.array([None,]*nt**2).reshape(nt, -1).tolist()
        for ind, lat in enumerate(self._lats):
          # Steal the neighbor hamiltonian from the other file
          nhamilt = sc._lats[ind].nhamilt(verbose=verbose, recalc=recalc, format='lil')

          # Set block with Hamiltonian matrix of this lattice, using nhamilt from
          # the other file
          indmat[ind][ind] = lat.hamilt(nhamilt=nhamilt, recalc=recalc, verbose=verbose)
        for ind, site in enumerate(self._sites):
          indmat[nl+ind][nl+ind] = site.hamilt(recalc=recalc, verbose=verbose)
        hamilt = spa.bmat(indmat, format='lil')

        # Maybe the neighbor matrices were constructed just now and have to be saved
        # to the other file (overwrite supercell)
        savehdf(f[pgroup], key=scdset, data=sc)
        f.close()

      else:
        raise IOError, 'file %s does not exist' % self.hlink
    elif not '_hamilt' in self.__dict__ or recalc:
      # Then create it

      nl = len(self._lats)
      ns = len(self._sites)
      nt = nl+ns

      # Set the blocks on the main diagonal
      indmat = np.array([None,]*nt**2).reshape(nt, -1).tolist()
      for ind, lat in enumerate(self._lats):
        indmat[ind][ind] = lat.hamilt(verbose=verbose, recalc=recalc)
      for ind, site in enumerate(self._sites):
        indmat[nl+ind][nl+ind] = site.hamilt(verbose=verbose, recalc=recalc)
      hamilt = spa.bmat(indmat, format='lil')

      # Now, also the hoppings would have to be found, but I will code this
      # later as I don't need it now...

      # Store matrix
      object.__setattr__(self, '_hamilt', hamilt)
    else:
      # Get matrix
      hamilt = self._hamilt

    # Convert matrix if needed
    assert format in ['lil', 'dok', 'csr', 'csc', 'dia', 'coo', 'bsr', 'dense'], 'unknown format. Must be one of lil, dok, coo, dia, csr, csc, bsr or dense'
    if format != 'lil':
      hamilt = getattr(hamilt, 'to'+format)()

    # Return Hamiltonian matrix
    return hamilt

  #def add_hop(self, e1, e2, hop, iso=False)
  def add_param(self, hop, dcon=None, scon=None, econ=None): # always isotropic, use old algorithm
    """Define a hopping parameter that will be set between single sites and the
    sites of lattices, following a set of conditions."""
    # Fills ptable with entries
    # Respect anisotropic hopping here in the future as well?
    raise NotImplementedError

  def __setattr__(self, name, value):
    # Do it normally
    object.__setattr__(self, name, value)

    # Delete hamiltonian matrix. It has to be recreated, as parameters may have changed.
    if '_hamilt' in self.__dict__:
      del(self._hamilt)

  def dimensions(self):
    """Return system dimensions of the supercell. The dimensions depend
    exclusively on the dimensions and coordinates of the lattices and sites
    that are defined within the supercell, plus the margin."""
    raise NotImplementedError

  def __repr__(self):
    return self.label

  def add_scnn(self, pot=0., hop=-1., shape=None, bcond=None, origin=None, bvects=None, label='scNN'):
    """Create a dim-dimensional 1-band ordered face-centered cubic lattice with only constant
    isotropic next-neighbor hopping, where dim is the dimensionality of the containing supercell."""

    # Create lattice
    lat = self.add_lat(shape=shape, bcond=bcond, origin=origin, bvects=bvects, label=label)

    # Add a site with a potential to the unitcell
    site = lat.add_site()
    ent = site.add_ent(pot=pot)

    # Add isotropic next-neighbor hopping
    neigh = lat.add_neigh(label='NN')
    neigh.add_hop(ent, ent, hop)
    lat.add_vect(neigh, permall=True)

    # Return object reference
    return lat

  def add_fccnn(self, pot=0., hop=-1., shape=None, bcond=None, origin=None, bvects=None, label='fccNN'):
    """Create a 3-dimensional 1-band ordered face-centered cubic lattice with only constant
    isotropic next-neighbor hopping."""

    # Make sure supercell is 3D
    assert self.dim == 3, 'an fcc lattice can only be created in a 3D system'

    # Create lattice
    lat = self.add_lat(shape=shape, bcond=bcond, origin=origin, bvects=bvects, label=label)

    # Add the four sites that are in the conventional unitcell of a fcc lattice
    sA = lat.add_site(coord=(0., 0., 0.), label='SiteA')
    sB = lat.add_site(coord=(.5, .5, 0.), label='SiteB')
    sC = lat.add_site(coord=(.5, 0., .5), label='SiteC')
    sD = lat.add_site(coord=(0., .5, .5), label='SiteD')

    # Add a potential to each of the sites
    A = sA.add_ent(pot=pot, label='A')
    B = sB.add_ent(pot=pot, label='B')
    C = sC.add_ent(pot=pot, label='C')
    D = sD.add_ent(pot=pot, label='D')

    # Define intra-unitcell hoppings
    lat.add_hop(A, B, hop, iso=True)
    lat.add_hop(A, C, hop, iso=True)
    lat.add_hop(A, D, hop, iso=True)
    lat.add_hop(B, C, hop, iso=True)
    lat.add_hop(B, D, hop, iso=True)
    lat.add_hop(C, D, hop, iso=True)

    # Define neighbors
    n001 = lat.add_neigh(label='N001')
    lat.add_vect(n001, vect=(0, 0, 1), iso=True) # Change them all in this way!
    n010 = lat.add_neigh(label='N010')
    lat.add_vect(n010, vect=(0, 1, 0), iso=True)
    n100 = lat.add_neigh(label='N100')
    lat.add_vect(n100, vect=(1, 0, 0), iso=True)
    n011 = lat.add_neigh(label='N011')
    lat.add_vect(n011, vect=(0, 1, 1), iso=True)
    n101 = lat.add_neigh(label='N101')
    lat.add_vect(n101, vect=(1, 0, 1), iso=True)
    n110 = lat.add_neigh(label='N110')
    lat.add_vect(n110, vect=(1, 1, 0), iso=True)
    n01_1 = lat.add_neigh(label='N01_1')
    lat.add_vect(n01_1, vect=(0, 1, -1), iso=True)
    n10_1 = lat.add_neigh(label='N10_1')
    lat.add_vect(n10_1, vect=(1, 0, -1), iso=True)
    n1_10 = lat.add_neigh(label='N1_10')
    lat.add_vect(n1_10, vect=(1, -1, 0), iso=True)

    # Define inter-unitcell hoppings
    n010.add_hop(B, A, hop)
    n100.add_hop(B, A, hop)
    n110.add_hop(B, A, hop)
    n100.add_hop(C, A, hop)
    n001.add_hop(C, A, hop)
    n101.add_hop(C, A, hop)
    n010.add_hop(D, A, hop)
    n001.add_hop(D, A, hop)
    n011.add_hop(D, A, hop)
    n001.add_hop(C, B, hop)
    n010.add_hop(B, C, hop)
    n01_1.add_hop(B, C, hop)
    n100.add_hop(B, D, hop)
    n10_1.add_hop(B, D, hop)
    n001.add_hop(D, B, hop)
    n100.add_hop(C, D, hop)
    n1_10.add_hop(C, D, hop)
    n010.add_hop(D, C, hop)

    # Return object reference
    return lat

  def add_bccnn(self, pot=0., hop=-1., shape=None, bcond=None, origin=None, bvects=None, label='bccNN'):
    """Create a 3-dimensional 1-band ordered body-centered cubic lattice with only constant
    isotropic next-neighbor hopping."""

    # Make sure supercell is 3D
    assert self.dim == 3, 'a bcc lattice can only be created in a 3D system'

    # Create lattice
    lat = self.add_lat(shape=shape, bcond=bcond, origin=origin, bvects=bvects, label=label)

    # Add the two sites that are in the conventional unitcell of a bcc lattice
    sA = lat.add_site(coord=(0., 0., 0.), label='SiteA')
    sB = lat.add_site(coord=(.5, .5, .5), label='SiteB')

    # Add a potential to each of the sites
    A = sA.add_ent(pot=pot, label='A')
    B = sB.add_ent(pot=pot, label='B')

    # Define intra-unitcell hoppings
    lat.add_hop(A, B, hop, iso=True)

    # Define next neighbor hoppings
    neigh = lat.add_neigh()
    neigh.add_hop(B, A, hop)
    lat.add_vect(neigh, vect=(1, 0, 0), iso=True, perm=True)
    lat.add_vect(neigh, vect=(1, 1, 0), iso=True, perm=True)
    lat.add_vect(neigh, vect=(1, 1, 1), iso=True)

    # Return object reference
    return lat

  def add_scsnn(self, pot=0., hop1=-1., hop2=-1., shape=None, bcond=None, origin=None, bvects=None, label='sc2SNN'):
    """Create a dim-dimensional 1-band simple cubic lattice with constant
    isotropic next-neighbor and second-next-neighbor hopping, where dim is the
    dimensionality of the containing supercell."""
    raise NotImplementedError

  def add_honey(self, pot=0., hop=-1., shape=None, bcond=None, origin=None, label='Honeycomb'):
    """Create a 2-dimensional honeycomb lattice (like that of graphene) with constant
    isotropic next neighbor hopping."""

    # Make sure supercell is 2D
    assert self.dim == 2, 'a honeycomb lattice can only be created in a 2D system'

    # Create lattice
    lat = self.add_lat(shape=shape, bcond=bcond, origin=origin, label=label)
    lat.bvects[0] = [3, 0]
    lat.bvects[1] = [0, np.sqrt(3)]

    # Add the four sites that are in the conventional unitcell of a graphene lattice
    sA = lat.add_site(coord=(0., 0.), label='SiteA')
    sB = lat.add_site(coord=(1./3, 0.), label='SiteB')
    sC = lat.add_site(coord=(.5, .5) , label='SiteC')
    sD = lat.add_site(coord=(5./6, .5), label='SiteD')

    # Add a potential to each of the sites
    A = sA.add_ent(pot=pot, label='A')
    B = sB.add_ent(pot=pot, label='B')
    C = sC.add_ent(pot=pot, label='C')
    D = sD.add_ent(pot=pot, label='D')

    # Define intra-unitcell hoppings
    lat.add_hop(A, B, hop, iso=True)
    lat.add_hop(B, C, hop, iso=True)
    lat.add_hop(C, D, hop, iso=True)

    # Define neighbor hoppings
    n10 = lat.add_neigh(label='N10')
    n10.add_hop(D, A, hop)
    lat.add_vect(n10, vect=(1, 0), iso=True)
    n01 = lat.add_neigh(label='N01')
    n01.add_hop(C, B, hop)
    lat.add_vect(n01, vect=(0, 1), iso=True)
    n11 = lat.add_neigh(label='N11')
    n11.add_hop(D, A, hop)
    lat.add_vect(n11, vect=(1, 1), iso=True)

    # Return object reference
    return lat

  def add_diam(self, pot=0., hop=-1., shape=None, bcond=None, origin=None, bvects=None, label='Diamond'):
    """Create a dim-dimensional 1-band diamond lattice with only constant
    isotropic next-neighbor hopping, where dim is the dimensionality of the containing
    supercell."""

    # Make sure supercell is 3D
    assert self.dim == 3, 'a diamond lattice can only be created in a 3D system'

    # Create lattice
    lat = self.add_lat(shape=shape, bcond=bcond, origin=origin, bvects=bvects, label=label)

    # Add the eight sites to the conventional unitcell
    sA1 = lat.add_site(coord=(0., 0., 0.), label='SiteA1')
    sA2 = lat.add_site(coord=(0., .5, .5), label='SiteA2')
    sA3 = lat.add_site(coord=(.5, 0., .5), label='SiteA3')
    sA4 = lat.add_site(coord=(.5, .5, 0.), label='SiteA4')
    sB1 = lat.add_site(coord=(.25, .25, .25), label='SiteB1')
    sB2 = lat.add_site(coord=(.25, .75, .75), label='SiteB2')
    sB3 = lat.add_site(coord=(.75, .25, .75), label='SiteB3')
    sB4 = lat.add_site(coord=(.75, .75, .25), label='SiteB4')

    # Add a potential to each of the sites
    A1 = sA1.add_ent(pot=pot, label='A1')
    A2 = sA2.add_ent(pot=pot, label='A2')
    A3 = sA3.add_ent(pot=pot, label='A3')
    A4 = sA4.add_ent(pot=pot, label='A4')
    B1 = sB1.add_ent(pot=pot, label='B1')
    B2 = sB2.add_ent(pot=pot, label='B2')
    B3 = sB3.add_ent(pot=pot, label='B3')
    B4 = sB4.add_ent(pot=pot, label='B4')

    # Define neighbors
    n100 = lat.add_neigh(label='N100')
    n010 = lat.add_neigh(label='N010')
    n001 = lat.add_neigh(label='N001')
    n110 = lat.add_neigh(label='N110')
    n101 = lat.add_neigh(label='N101')
    n011 = lat.add_neigh(label='N011')

    # Define vectors
    lat.add_vect(n100, vect=(1, 0, 0), iso=True)
    lat.add_vect(n010, vect=(0, 1, 0), iso=True)
    lat.add_vect(n001, vect=(0, 0, 1), iso=True)
    lat.add_vect(n110, vect=(1, 1, 0), iso=True)
    lat.add_vect(n101, vect=(1, 0, 1), iso=True)
    lat.add_vect(n011, vect=(0, 1, 1), iso=True)

    # Define hoppings from A1
    lat.add_hop(A1, B1, hop, iso=True)
    n110.add_hop(B4, A1, hop)
    n101.add_hop(B3, A1, hop)
    n011.add_hop(B2, A1, hop)

    # Define hoppings from A2
    lat.add_hop(A2, B2, hop, iso=True)
    lat.add_hop(A2, B1, hop, iso=True)
    n100.add_hop(B4, A2, hop)
    n100.add_hop(B3, A2, hop)

    # Define hoppings from A3
    lat.add_hop(A3, B3, hop, iso=True)
    lat.add_hop(A3, B1, hop, iso=True)
    n010.add_hop(B4, A3, hop)
    n010.add_hop(B2, A3, hop)

    # Define hoppings from A4
    lat.add_hop(A4, B4, hop, iso=True)
    lat.add_hop(A4, B1, hop, iso=True)
    n001.add_hop(B3, A4, hop)
    n001.add_hop(B2, A4, hop)

    # Return object reference
    return lat



class Lattice(object):
  """Define a lattice, using a unitcell that may contain multiple sites. The
  unitcell is repeated periodically in space a specified number of times in
  each dimension.

  Future ideas:
  - Setting an origin with wrong dimensionality could be prohibited.
  - Setting bvects with wrong dimensionality or a wrong number of bvects could
    be prohibited.
  - Making changes to dimensionality could be prohibited.
  - Setting an ltype not from the interval [0, 15] could be prohibited.
  - hamilt() could set all blocks that share the same neighbor object reference
    at once (those that are not transposed and those that are transposed).
  """
  # 05/03/2011-31/03/2011

  def __init__(self, dim, shape=None, bcond=None, origin=None, bvects=None, label=None): #, ltype=0
    # Dimensionality, must be equal to that of the supercell
    dim = int(dim)
    assert dim > 0, 'dimensionality of the lattice must be positive integer'
    self.dim = dim

    # Shape (number of unit cells in each dimension)
    if shape == None:
      self.shape = (1,)*dim # Tuple of positive integers
    else:
      self.shape = shape

    # Boundary conditions
    if bcond == None:
      self.bcond = 'p'*dim
    else:
      self.bcond = bcond

    # Origin (coordinate within the supercell)
    if origin == None:
      self.origin = (0.,)*dim # Tuple of floats
    else:
      self.origin = origin

    # Basis vectors of the unit cell
    if bvects == None:
      self.bvects = np.eye(dim) # matrix with shape (dim, dim)
    else:
      self.bvects = bvects

    # Label
    if label == None:
      self.label = typename(self)
    else:
      self.label = label

    # List of sites within the unitcell (atomic basis)
    self._sites = [] # List of objects

    # Intra-cell hopping dictionary (apart from diagonal entries)
    self._hops = {}

    # Intra-cell random hopping dictionary (also diagonal entries)
    self._randhops = {}

    # List of inter-cell neighbor hoppings and dictionary of vectors to the neighbors
    self._neighs = []
    self._vects = {}
    self._transpose = set() # Containing vectors to those neighbor unitcells that will be set with the transposed hopping matrix

    # Lattice type identifier
    #self.ltype = ltype # Integer from [0, 15]

  def add_site(self, site=None, coord=None, label=None):
    """Add a site to the unitcell of the lattice, at any given coordinate."""
    if site == None:
      # Create a new Site instance
      site = Site(self.dim, coord=coord, label=label)
    else:
      # Just update the values of the given site
      ain(site.coord, coord)
      ain(site.label, label)

    # Store and return
    self._sites.append(site)
    return site

  def add_hop(self, e1, e2, hop, iso=False):
    """Add a hopping parameter between two of the sites within the unitcell.
    So, this is just to define intra-unitcell hopping. e1 and e2 are object
    references of two of the Entity instances defined on one of the sites.

    If iso is set to True, also the hopping e2-e1 will be set (isotropic case),
    resulting in a symmetric Hamiltonian matrix."""
    assert e1 in self._ents(), 'The first entity is not in the unitcell\'s entity list'
    assert e2 in self._ents(), 'The second entity is not in the unitcell\'s entity list'

    # Find indices of the entities
    ind1 = self._ents().index(e1)
    ind2 = self._ents().index(e2)

    if e1 == e2:
      # If a diagonal element is chosen, just redefine the potential
      e1.pot = hop
    else:
      # If an off-diagonal element is chosen, set it
      if isiterable(hop):
        if hop == 0. and (ind1, ind2) in self._randhops:
          del(self._randhops[ind1, ind2])
        else:
          self._randhops[ind1, ind2] = hop
        if (ind1, ind2) in self._hops:
          del(self._hops[ind1, ind2])
      else:
        if hop == 0. and (ind1, ind2) in self._hops:
          del(self._hops[ind1, ind2])
        else:
          self._hops[ind1, ind2] = hop
        if (ind1, ind2) in self._randhops:
          del(self._randhops[ind1, ind2])

      # Isotropic case
      if iso:
        if isiterable(hop):
          if hop == 0. and (ind2, ind1) in self._randhops:
            del(self._randhops[ind2, ind1])
          else:
            self._randhops[ind2, ind1] = hop
          if (ind2, ind1) in self._hops:
            del(self._hops[ind2, ind1])
        else:
          if hop == 0. and (ind2, ind1) in self._hops:
            del(self._hops[ind2, ind1])
          else:
            self._hops[ind2, ind1] = hop
          if (ind2, ind1) in self._randhops:
            del(self._randhops[ind2, ind1])

  def add_neigh(self, neigh=None, label=None):
    """Add a class of neighbor interaction between different unitcells."""
    if neigh == None:
      # Create a new Neighbor instance
      neigh = Neighbor(dim=self.dim, sites=self._sites, label=label)
    else:
      # Just update values to existing Neighbor instance
      aim(neigh._sites, self._sites)
      aim(neigh.vect, vect)
      aim(neigh.label, label)

    # Store and return
    self._neighs.append(neigh)
    return neigh

  def add_vect(self, neigh, vect=None, iso=False, perm=False, permall=False):
    """Add a vector, leading to a neighbor unitcell to which hopping shall be
    possible, and connect it to one of the previously defined Neighbor instances.
    The vector consists only of integers.

    If iso is set to True, also the neighbor of the negative vector is set, with
    the transpose of this neighbor's hopping matrix.

    If perm is set to True, the neighbors of all permutations of the given
    vector are set with the same neighbor hopping matrix. Of course, if both
    iso and perm are set to True, the neighbors of the negative vectors of all
    permutations are set with the transpose of the matrix. This case could be
    useful for bcc-like structures.

    If permall is set to True, the blocks of all permutations of the given
    vector are set with the neighbor's hopping matrix, including all negative
    values. Not the transpose, but the matrix itself is always used. USE THIS
    OPTION WITH CAUTION! It should only be used in systems with only one site
    per unitcell. Otherwise, unwanted hoppings will probably occur. This option
    overrides the options iso and perm."""
    assert neigh in self._neighs, 'the specified neighbor is not in the neighbor list'
    ind = self._neighs.index(neigh)

    # Get vector
    if vect == None:
      vect = (1,)+(0,)*(self.dim-1)

    # Connect this vector with the neighbor, respect automatic symmetry features
    # (permutations and isotropy)
    if permall:
      # Add all permutations of the given vector and pass them the object reference
      # to the Neighbor instance
      for v in signperms(vect):
        self._vects[v] = ind
    else:
      if perm:
        for v in it.permutations(vect):
          self._vects[v] = ind
        if iso:
          # Also add the neighbors of the negative vectors
          for v in it.permutations(vect):
            nv = tuple(-np.array(v))
            self._vects[nv] = ind
            self._transpose.add(nv)
      else:
        # Add only the neighbor of this vector
        self._vects[vect] = ind
        if iso:
          # Also add the neighbor of the negative vector
          negvect = tuple(-np.array(vect))
          self._vects[negvect] = ind
          self._transpose.add(negvect)

  def hamilt(self, format='lil', verbose=False, recalc=False, nhamilt=None):
    """Calculate and return hopping matrix of the lattice."""

    if not '_hamilt' in self.__dict__ or recalc:
      # Then create it

      # Check boundary condition string
      assert len(self.bcond) <= self.dim, 'bad boundary condition: %s. Number of given boundary conditions is greater than dimensionality of the system (%i)' % (bcond, dim)
      assert len(self.bcond) > 0, 'bad boundary condition: May not be empty string. At least one character (s, p or a) has to be given'
      if len(self.bcond) < self.dim:
        self.bcond += self.bcond[-1]*(self.dim-len(self.bcond))

      # Create list, containing all entities of all sites
      ents = self._ents()

      # First, create matrix for intra-unitcell hopping
      ne = len(ents)
      ns = len(self._sites)
      size = np.prod(self.shape)
      unitcellhamilt = spa.lil_matrix((ne, ne))

      # Set blockdiagonal elements with those of the site objects
      # Maybe use spa.bmat here in the future?
      lower = 0
      for s in self._sites:
        upper = lower+len(s._ents)
        unitcellhamilt[lower:upper, lower:upper] = s.hamilt(recalc=recalc)
        lower = upper

      # Set off-blockdiagonal matrix elements
      # Also incorporate this in the same call to spa.bmat?
      for (ind1, ind2), hop in self._hops.iteritems():
        unitcellhamilt[ind1, ind2] = hop

      # Now build the big Hamiltonian matrix of the whole lattice

      # Set the blockdiagonal entries (intra-unitcell hopping)
      hamilt = spa.kron(spa.eye(size, size, format='lil'), unitcellhamilt).tolil()

      # Apply random potentials if there are any defined
      hamilt = self.setrandhops(hamilt, recalc=recalc)
      #for (ind1, ind2), hop in self._randhops.iteritems():
      #  # Get indices in entity list
      #  indm = min(ind1, ind2)
      #
      #  # Set random potentials, but only every ne'th element on the specific diagonal
      #  onlydiag = spa.lil_matrix((size*ne, size*ne))
      #  diag = np.zeros((size, ne))
      #  diag[:, indm] = np.array(hop).flatten()
      #  onlydiag.setdiag(diag.flatten(), k=ind2-ind1)
      #  hamilt = hamilt+onlydiag

      # Set inter-cell hopping blocks
      if nhamilt == None:
        hamilt = hamilt+self.nhamilt(verbose=verbose)
      else:
        hamilt = hamilt+nhamilt

        #for ucind in np.ndindex(self.shape): # Unitcell index (dim-tuple)
          #np.array(ucind)+np.array(vect)
          # Use formular for the index in dependence on ucind
          # Use the same formular for the index of ucind+vect
          #pass

          #for ucind2 in np.ndindex(self.shape): # Unitcell index (dim-tuple)
            # Would be waaay to slow, and is unneccessary, as unitcells are
            # always distributed simple-cubic-like. Just be aware, we have more
            # than only next-neighbor-hopping, and we do not necessarily have
            # the case of isotropic hopping (otherwise, in that special case,
            # we could use my fast algorithm!). If in need, ask Stefan about
            # the formular.
            #pass

      # Store matrix
      object.__setattr__(self, '_hamilt', hamilt)
    else:
      # Get matrix
      hamilt = self._hamilt

    # Convert matrix if needed
    assert format in ['lil', 'dok', 'csr', 'csc', 'dia', 'coo', 'bsr', 'dense'], 'unknown format. Must be one of lil, dok, coo, dia, csr, csc, bsr or dense'
    if format != 'lil':
      hamilt = getattr(hamilt, 'to'+format)()

    # Return Hamiltonian matrix
    return hamilt

  def nhamilt(self, recalc=False, verbose=False, format='lil'):
    """Return matrix consisting only of those elements that belong to inter-cell
    hoppings between neighboring unitcells."""
    if not '_nhamilt' in self.__dict__ or recalc:
      # Then create it
      ents = self._ents()
      ne = len(ents)
      #ns = len(self._sites)
      size = np.prod(self.shape)

      # Check if a faster algorithm for this special case is available
      if len(ents) == 1 and self.constnn():
        # Use scnnmat
        if verbose:
          print 'using scnnmat.'
        firstkey = self._vects.keys()[0]
        firstvect = self._vects[firstkey]
        hop = self._neighs[firstvect].hamilt()[0, 0]
        nhamilt = scnnmat(self.shape, hop=hop, bcond=self.bcond)
      # Later, use a variant of scnnmat that can work with whole matrices in
      # the place of hop and pot (but the use of that should be very seldom,
      # because every lattice that has more than one site per unitcell almost
      # always has more than just next-neighbor hopping) (Yes, but: If I have
      # just one site per unitcell, but mutiple entities at this site (n-band
      # model), then it would be very convenient!).
      else:
        nhamilt = spa.lil_matrix((ne*size, ne*size))

        for vect, ind in self._vects.iteritems():
          neigh = self._neighs[ind]
          # vect decides where to put the blocks
          # then just put neigh.hamilt() into that block

          coords = np.array(tuple(np.ndindex(self.shape)))
          ncoords = coords+vect

          # Holding number of sign changes if anti-periodic boundary conditions are used
          cdiv = np.abs(np.divide(ncoords, self.shape)) # Integer division

          # Calculate valid coordinates (even if ncoords lies outside the lattice)
          ncoords = np.mod(ncoords, self.shape)

          # Maybe use re.finditer? Really not of any importance as long as the
          # dimensionality of the system is small, like 1D, 2D and 3D.
          #inds = [match.start() for match in re.finditer('p', self.bcond)]

          # Initialize index matrix. It defines where and with which sign the hopping
          # matrix block will be put.
          indmat = spa.lil_matrix((size, size), dtype=int)

          # Find all indices of coordinates of coords that equal each coordinate of
          # ncoords. The loop could be shorter, if the matrix block is equal in
          # multiple directions.
          p = Progress(size, 'Set hoppings for direction %s' % str(vect), verbose=verbose)
          for nind, ncoord in enumerate(ncoords):
            #dump(ncoord=ncoord)
            # Here, something a lot faster could be done, like calculating the
            # indices directly
            ind = np.flatnonzero(np.all(coords == ncoord, axis=1))

            # Better put these two small loops and if-tests outside the large loop?

            # If a dimension has a static boundary condition and cdiv is not zero,
            # do not set this block with hopping
            docont = False # "Do continue"
            for d, bc in enumerate(self.bcond):
              if bc == 's' and cdiv[nind, d] != 0:
                docont = True
                break
            if docont:
              p.step()
              continue

            # For every dimension with anti-periodic boundary condition, change the sign
            # of the block a number of times according to cdiv
            nosc = 0 # Number of sign changes
            for d, bc in enumerate(self.bcond):
              if bc == 'a':
                nosc += cdiv[nind, d]

            # Set element of the index matrix used by kron
            indmat[ind, nind] = (-1)**nosc
            p.step()

          # Get hopping matrix, transpose if needed
          neighhamilt = neigh.hamilt(format='lil', transpose=(vect in self._transpose), recalc=recalc)

          # Set respective blocks with hopping matrix
          nhamilt = nhamilt+spa.kron(indmat, neighhamilt, format='lil')

      # Store the matrix
      self._nhamilt = nhamilt
    else:
      # Get existing matrix
      nhamilt = self._nhamilt

    # Convert matrix if needed
    assert format in ['lil', 'dok', 'csr', 'csc', 'dia', 'coo', 'bsr', 'dense'], 'unknown format. Must be one of lil, dok, coo, dia, csr, csc, bsr or dense'
    if format != 'lil':
      nhamilt = getattr(nhamilt, 'to'+format)()

    # Return Hamiltonian matrix
    return nhamilt

  def constnn(self):
    """Checks whether hopping to all next neighbor unitcells was specified and if they
    are the only ones. Further, they all must lead to the same Neighbor instance."""
    # 31/03/2011
    if len(self._vects) < 1:
      return False

    # First, check if all vectors are connected to the same Neighbor instance
    # (constant hopping)
    keys = self._vects.keys()
    first = keys.pop(0)
    for key in keys:
      if self._vects[key] != self._vects[first]:
        return False

    # Then, test if all permutations of next neighbor vectors are present
    perms = signperms((1,)+(0,)*(self.dim-1))
    if len(perms) != len(self._vects):
      return False
    for vect in self._vects:
      if not vect in perms:
        return False

    # Otherwise, the neighbor vectors passed the test, return True
    return True



  def setrandhops(self, hamilt=None, recalc=False):
    """Apply random potentials if there are any defined."""
    # 31/03/2011
    ents = self._ents()
    ne = len(ents)
    ns = len(self._sites)
    size = np.prod(self.shape)

    # Get all random hoppings from all sites
    for s in self._sites:
      s.hamilt(recalc=True)
      self._randhops.update(s._randhops)

    if hamilt == None:
      hamilt = self.hamilt(recalc=recalc)
    for (ind1, ind2), hop in self._randhops.iteritems():
      # Get indices in entity list
      indm = min(ind1, ind2)

      # Set random potentials, but only every ne'th element on the specific diagonal
      onlydiag = spa.lil_matrix((size*ne, size*ne))
      diag = np.zeros((size, ne))
      diag[:, indm] = np.array(hop).flatten()
      onlydiag.setdiag(diag.flatten(), k=ind2-ind1)
      hamilt = hamilt+onlydiag
    self._hamilt = hamilt
    return hamilt

  def dimensions(self):
    """Return dimensions of the lattice. The dimensions depend on the defined
    unit cell and on the coordinates of the sites within the unitcell."""
    raise NotImplementedError

  def __setattr__(self, name, value):
    # Do it normally
    object.__setattr__(self, name, value)

    # Delete hamiltonian matrix. It has to be recreated, as parameters may have changed.
    if '_hamilt' in self.__dict__:
      del(self._hamilt)

  def _ents(self):
    """Return list of all entities of all sites."""
    ents = []
    for s in self._sites:
      ents += s._ents
    return ents

  def __repr__(self):
    return self.label



class Neighbor(object):
  """Define inter-unitcell hopping to a certain neighbor unitcell.

  Must not be used before all sites and entities of the lattice are complete.

  Future ideas:
  - Making changes to dimensionality could be prohibited.
  """
  # 06/03/2011-31/03/2011

  def __init__(self, dim, sites=None, label=None):
    # Dimensionality, must be equal to that of the supercell
    dim = int(dim)
    assert dim > 0, 'dimensionality of the lattice must be positive integer'
    self.dim = dim

    # List of sites within the unitcell
    if sites == None:
      self._sites = []
    else:
      self._sites = sites

    # List of all entities of all sites
    self._ents = []
    for s in self._sites:
      self._ents += s._ents

    # Label
    if label == None:
      self.label = typename(self)
    else:
      self.label = label

    # Inter-cell hopping dictionary (complete, also "diagonal" entries)
    self._hops = {}

  def add_hop(self, e1, e2, hop):
    """Add a hopping parameter from one entity to another within the unitcell,
    applying only between neighboring unitcells in the given direction."""
    assert e1 in self._ents, 'The first entity is not in the entity list of the unitcell'
    assert e2 in self._ents, 'The second entity is not in the entity list of the unitcell'

    # Find indices of the entities
    ind1 = self._ents.index(e1)
    ind2 = self._ents.index(e2)

    # Add the hopping
    if hop == 0. and (ind1, ind2) in self._hops:
      del(self._hops[ind1, ind2])
    else:
      self._hops[ind1, ind2] = hop

  def hamilt(self, format='lil', transpose=False, recalc=False):
    """Calculate and return hopping matrix of this neighbor interaction,
    containing all hopping parameters between the entities ("inter-cell
    hopping").

    If transpose is set to True, return the transpose of the matrix."""

    # If the matrix does not yet exist, create it
    if not '_hamilt' in self.__dict__ or recalc:
      # Then create it
      ne = len(self._ents)
      hamilt = spa.lil_matrix((ne, ne))

      # Fill matrix elements
      for (ind1, ind2), hop in self._hops.iteritems():
        hamilt[ind1, ind2] = hop

      # Store matrix
      object.__setattr__(self, '_hamilt', hamilt)
    else:
      # Get matrix
      hamilt = self._hamilt

    # Transpose matrix if needed
    if transpose:
      hamilt = hamilt.transpose()

    # Convert matrix if needed
    assert format in ['lil', 'dok', 'csr', 'csc', 'dia', 'coo', 'bsr', 'dense'], 'unknown format. Must be one of lil, dok, coo, dia, csr, csc, bsr or dense'
    if format != 'lil':
      hamilt = getattr(hamilt, 'to'+format)()

    # Return matrix
    return hamilt

  def __setattr__(self, name, value):
    # Do it normally
    object.__setattr__(self, name, value)

    # Delete hamiltonian matrix. It has to be recreated, as parameters may have changed.
    if '_hamilt' in self.__dict__:
      del(self._hamilt)

  def __repr__(self):
    return self.label



class Site(object):
  """Define a single site. May contain several entities.

  Future ideas:
  - Setting a coordinate with wrong dimensionality could be prohibited.
  - Making changes to dimensionality could be prohibited.
  """
  # 05/03/2011-30/03/2011

  def __init__(self, dim, coord=None, label=None):
    # Dimensionality, must be equal to that of the supercell
    dim = int(dim)
    assert dim > 0, 'dimensionality of the lattice must be positive integer'
    self.dim = dim

    # Coordinate within the unitcell or supercell
    if coord == None:
      self.coord = (0.,)*dim # Tuple of floats
    else:
      coord = tuple(coord)
      assert len(coord) == dim, 'bad coordinate. Length must equal dimensionality of the supercell'
      self.coord = coord

    # Label
    if label == None:
      self.label = typename(self)
    else:
      self.label = label

    # List of entities
    self._ents = [] # List of objects

    # Intra-site hopping dictionary (apart from diagonal entries/potentials)
    self._hops = {}

    # Intra-site random hoppings dictionary (including potentials)
    self._randhops = {}

  def add_ent(self, ent=None, pot=0., label=None):
    """Add an entity of some kind to the site. May represent an electron or
    hole state, a spin state, an orbital, or whatever the tight binding model
    is dealing with."""
    if ent == None:
      # Create new Entity instance
      ent = Entity(pot=pot, label=label)
    else:
      # Otherwise, use given instance and just update attributes
      ain(ent.pot, pot)
      ain(ent.label, label)

    # Store and return
    self._ents.append(ent)
    return ent

  def add_hop(self, e1, e2, hop, iso=False):
    """Add a hopping parameter between two of the entities sitting at this
    site. So, this is just to define intra-site hopping. e1 and e2 are object
    references, pointing to two of the Entity instances defined at this site.

    If iso is set to True, also the hopping e2-e1 will be set (isotropic case),
    resulting in a symmetric Hamiltonian matrix."""
    assert e1 in self._ents, 'The first entity is not in the site\'s entity list'
    assert e2 in self._ents, 'The second entity is not in the site\'s entity list'
    if e1 == e2:
      # If a diagonal element is chosen, just redefine the potential
      e1.pot = hop
    else:
      # Find indices of the two chosen entities in the entity list
      ind1 = self._ents.index(e1)
      ind2 = self._ents.index(e2)

      if isiterable(hop):
        if hop == 0. and (ind1, ind2) in self._randhops:
          del(self._randhops[ind1, din2])
        else:
          self._randhops[ind1, ind2] = hop
        if (ind1, ind2) in self._hops:
          del(self._hops[ind1, ind2])
      else:
        if hop == 0. and (ind1, ind2) in self._hops:
          del(self._hops[ind1, ind2])
        else:
          self._hops[ind1, ind2] = hop
        if (ind1, ind2) in self._randhops:
          del(self._randhops[ind1, ind2])

      # Isotropic hopping
      if iso:
        if isiterable(hop):
          if hop == 0. and (ind2, ind1) in self._randhops:
            del(self._randhops[ind2, ind1])
          else:
            self._randhops[ind2, ind1] = hop
          if (ind2, ind1) in self._hops:
            del(self._hops[ind2, ind1])
        else:
          if hop == 0. and (ind2, ind1) in self._hops:
            del(self._hops[ind2, ind1])
          else:
            self._hops[ind2, ind1] = hop
          if (ind2, ind1) in self._randhops:
            del(self._randhops[ind2, ind1])

  def hamilt(self, format='lil', recalc=False):
    """Calculate and return hopping matrix of the site, containing all hopping
    parameters between the entities ("intra-site hopping") (including
    potentials in form of the diagonal entries).

    If getcoord is set to True, also return self.coord (tuple).
    If gettypes is set to True, also return self._etypes (list)."""

    if not '_hamilt' in self.__dict__ or recalc:
      # Then create it
      ne = len(self._ents)
      hamilt = spa.lil_matrix((ne, ne))

      # Fill the diagonal entries with the potentials
      pots = []
      for eind, e in enumerate(self._ents):
        if isiterable(e.pot):
          # Add the list of random potentials to _randhops
          self._randhops[eind, eind] = np.array(e.pot).flatten()
          pots.append(0.)
        else:
          pots.append(e.pot)
      hamilt.setdiag(pots)

      # Fill off-diagonal elements
      for (ind1, ind2), hop in self._hops.iteritems():
        hamilt[ind1, ind2] = hop

      # Store matrix
      object.__setattr__(self, '_hamilt', hamilt)
    else:
      # Get matrix
      hamilt = self._hamilt

    # Convert matrix if needed
    assert format in ['lil', 'dok', 'csr', 'csc', 'dia', 'coo', 'bsr', 'dense'], 'unknown format. Must be one of lil, dok, coo, dia, csr, csc, bsr or dense'
    if format != 'lil':
      hamilt = getattr(self._hamilt, 'to'+format)()
    else:
      hamilt = self._hamilt

    # Return Hamiltonian matrix
    return hamilt

  def __setattr__(self, name, value):
    # Do it normally
    object.__setattr__(self, name, value)

    # Delete hamiltonian matrix. It has to be recreated, as parameters may have changed.
    if '_hamilt' in self.__dict__:
      del(self._hamilt)

  def __repr__(self):
    return self.label
    #return 'Site('+', '.join([str(key)+'='+str(value) for key, value in self.__dict__.iteritems()])+')'



class Entity(object):
  """Define an entity, characterized by some effective potential."""
  # 05/03/2011-30/03/2011

  def __init__(self, pot=0., label=None): #, etype=0
    # Potential
    self.pot = pot # Float

    # Label
    if label == None:
      self.label = typename(self)
    else:
      self.label = label

    # Entity type identifier
    #self.etype = etype # Integer from [0, 15]

  def __repr__(self):
    #if self.label not in (typename(self), ''):
    return self.label
    #else:
    #  return self.__class__.__name__+'('+', '.join([key+'='+repr(value) for key, value in self.__dict__.iteritems()])+')'



def signperms(inp):
  """Return a list of all possible permutations of a given tuple of values,
  including all possible sign flips of the values."""
  # 06/03/2011
  inp = tuple(inp)
  dim = len(inp)

  # Get all possible permutations of input
  perm = np.array(list(it.permutations(inp)))

  # Get all possible sign changes
  signlist = [(-1, 1)]*dim
  signperm = np.array(list(it.product(*signlist)))

  # Calculate all possible permutations including sign changes
  allperm = list((signperm*perm[:, None]).reshape(-1, dim))

  # Make a list of tuples out of it
  for ind in xrange(len(allperm)):
    allperm[ind] = tuple(allperm[ind])

  # Return list of tuples, sorting out double entries
  return list(set(allperm))



def ain(target, value):
  """Assign value to target only if value is not None. Otherwise, leave target unchanged."""
  # 22/03/2011
  if value != None:
    target = value


class xdin(object):
  """Class that offers generator abilities for loading data."""
  # 04/04/2011-10/04/2011

  def __init__(self, *args, **kwargs):
    # Handle special keyword arguments
    if 'dgroup' in kwargs:
      self.dgroup = kwargs.pop('dgroup')
    else:
      self.dgroup = 'data' # Default value
    if 'extension' in kwargs:
      self.extension = kwargs.pop('extension')
    else:
      self.extension = '.h5' # Default value
    if 'filenames' in kwargs:
      self.filenames = kwargs.pop('filenames')
    else:
      self.filenames = [] # Default value

    self.args = args
    self.kwargs = kwargs

  def __iter__(self):
    for filename in self.filenames:
      # Open HDF5 file
      f = hdf.File(filename, 'r')

      # Open data group
      if not self.dgroup in f:
        raise KeyError, 'no data group in HDF5 file %s' % filename
        #self.din.append(struct())
        #continue
      g = f[self.dgroup]

      # If only argument is 'all', load all data
      if len(self.args) == 1 and len(self.kwargs) == 0 and self.args[0] == 'all':
        self.args = g.keys()

      # Load data
      s = struct()
      for arg in self.args:
        if arg in g:
          s[arg] = loadhdf(g, arg)
        else:
          raise NameError, 'no dataset named %s in group %s of file %s' % (arg, self.dgroup, filename)
      for kwkey, kwvalue in self.kwargs.iteritems():
        if kwvalue in g:
          s[kwkey] = loadhdf(g, kwvalue)
        else:
          raise NameError, 'no dataset named %s in group %s of file %s' % (kwvalue, self.dgroup, filename)

      # Close HDF5 file
      f.close()

      # Yield data
      yield s

  def __len__(self):
    return len(self.filenames)

  def __getitem__(self, key):
    # Open HDF5 file
    f = hdf.File(self.filenames[key], 'r')

    # Open data group
    if not self.dgroup in f:
      raise KeyError, 'no data group in HDF5 file %s' % filename
      #self.din.append(struct())
      #continue
    g = f[self.dgroup]

    # If only argument is 'all', load all data
    if len(self.args) == 1 and len(self.kwargs) == 0 and self.args[0] == 'all':
      self.args = g.keys()

    # Load data
    s = struct()
    for arg in self.args:
      if arg in g:
        s[arg] = loadhdf(g, arg)
      else:
        raise NameError, 'no dataset named %s in group %s of file %s' % (arg, self.dgroup, filename)
    for kwkey, kwvalue in self.kwargs.iteritems():
      if kwvalue in g:
        s[kwkey] = loadhdf(g, kwvalue)
      else:
        raise NameError, 'no dataset named %s in group %s of file %s' % (kwvalue, self.dgroup, filename)

    # Close HDF5 file
    f.close()

    # Yield data
    return s

class xpin(object):
  """Class that offers generator abilities to load parameter sets from a bunch
  of files."""
  # 04/04/2011-10/04/2011

  def __init__(self, filenames=[], pgroup='param', extension='.h5'):
    self.filenames = filenames
    self.pgroup = pgroup
    self.extension = extension

  def __iter__(self):
    for filename in self.filenames:
      # Open HDF5 file
      f = hdf.File(filename, 'r')

      # Load parameter set of the file, if available
      if self.pgroup in f:
        param = loadhdf(f, self.pgroup)
      else:
        param = struct()

      # Close HDF5 file
      f.close()

      # Return parameter set
      yield param

  def __len__(self):
    return len(self.filenames)

  def __getitem__(self, key):
    if key == 0:
      # Open HDF5 file
      f = hdf.File(self.filenames[0], 'r')

      # Load parameter set of the file, if available
      if self.pgroup in f:
        param = loadhdf(f, self.pgroup)
      else:
        param = struct()

      # Close HDF5 file
      f.close()

      # Return parameter set
      return param
    else:
      raise NotImplementedError
      # OK, wouldn't be hard to allow arbitrary index as long as
      # self.filenames is no generator but a normal list...

class xcin(object):
  """Class that offers generator abilities to load comments from a bunch of files."""
  # 04/04/2011-10/04/2011

  def __init__(self, filenames=[], cgroup='comment', extension='.h5'):
    self.filenames = filenames
    self.cgroup = cgroup
    self.extension = extension

  def __iter__(self):
    for filename in self.filenames:
      # Open HDF5 file
      f = hdf.File(filename, 'r')

      # Load comments of the file, if available
      comment = struct()
      if self.cgroup in f:
        for key in f[self.cgroup]:
          comment[key] = loadhdf(f[self.cgroup], key)

      # Close HDF5 file
      f.close()

      # Return comment
      yield comment

  def __len__(self):
    return len(self.filenames)

  def __getitem__(self, key):
    if key == 0:
      # Open HDF5 file
      f = hdf.File(self.filenames[0], 'r')

      # Load comment of the file, if available
      comment = struct()
      if self.cgroup in f:
        for key in f[self.cgroup]:
          comment[key] = loadhdf(f[self.cgroup], key)

      # Close HDF5 file
      f.close()

      # Return comment
      return comment
    else:
      raise NotImplementedError
      # OK, wouldn't be hard to allow arbitrary index as long as
      # self.filenames is no generator but a normal list...

#class xfin(object):
#  """Class that functions as a generator for returning all filenames specified
#  in the positional command line arguments. Make use of glob.iglob (iterator)
#  to expand given filename patterns to actual filenames. If the file is not
#  found in the first place, try to append the given extension. If still not
#  found, raise an IOError."""
#  # 06/04/2011
#
#  def __init__(self, patterns, extension='.h5'):
#    self.patterns = patterns
#    self.extension = extension
#
#  def __iter__(self):
#    for pattern in self.patterns:
#
#      for filename in glob.iglob(pattern):
#        # Check filename
#        if not os.path.isfile(filename):
#          if os.path.isfile(filename+extension):
#            filename += extension
#          else:
#            raise IOError, 'file not found: %s' % filename
#
#        # Return filename
#        yield filename
#
#  def __len__(self):
#    # I do not know any better way now.
#    # At least, this way no huge memory amount is needed.
#    # But the loop will of course take some time.
#    num = 0
#    for filename in self:
#      num += 1
#    return num


def kpmv(mat, states=[0], trunc=100, nes=20000000, verbose=False):
  """Execute KPM. This function uses a vectorization approach.
  This function is for diagonal expectation values only. Variations of this
  function have still to be written to cover the other cases (non-diagonal
  expectation values and traces)."""
  # 19/04/2011

  # mat should be a sparse matrix, ideally in the CSR format (for fast matrix-
  # vector multiplication). Is must already be rescaled, so that its
  # eigenspectrum lies within the interval [-1, 1]
  ne = mat.shape[0]
  ns = len(states)

  # Divide the list of states into small bunches and calculate the moments
  # bunch for bunch (because of finite physical memory of the machine)
  nsv = nes/ne # maximum number of states that will be treated vectorized
  nb = (ns-1)/nsv+1 # number of bunches
  obw = (ns-1)/nb+1 # optimized bunch size, so that each bunch is roughly the same size
  if verbose:
    print 'at this matrix size, execute at most %i KPM algorithms parallelly' % nsv
    print 'use %i KPM iterations, each carrying out %i KPM algorithms at once' % (nb, obw)

  mu = np.zeros((trunc, ns), dtype=float)
  for ind in xrange(nb):
    ind1 = ind*obw
    ind2 = min((ind+1)*obw, ns)
    bw = ind2-ind1

    # Initialization
    p = Progress(1, text='Initialize iteration %i/%i' % (ind+1, nb), verbose=verbose)
    phi0 = np.zeros((ne, bw), dtype=float)
    for ind, state in enumerate(states[ind1:ind2]): # Can this loop be avoided? One would need some kind of special eye function...
      phi0[state, ind] = 1.
    mu[0, ind1:ind2] = np.sum(phi0*phi0, axis=0)
    mu0 = mu[0, ind1:ind2]
    phi1 = mat*phi0
    mu[1, ind1:ind2] = np.sum(phi1*phi0, axis=0)
    mu1 = mu[1, ind1:ind2]
    #dump(mu0s=mu0.shape, mus=mu.shape, mu1s=mu1.shape)
    p.step()

    # Iteration
    p = Progress((trunc-1)/2, text='Calculate moments', verbose=verbose)
    for n in xrange(1, trunc/2): # This is the critical for-loop that cannot be avoided
      phi2 = mat*2*phi1-phi0
      mu[2*n, ind1:ind2] = 2*np.sum(phi1*phi1, axis=0)-mu0
      mu[2*n+1, ind1:ind2] = 2*np.sum(phi2*phi1, axis=0)-mu1
      phi0, phi1 = phi1, phi2
      p.step()
    if trunc % 2 == 1: # If trunc is odd, calculate last moment
      phi2 = mat*2*phi1-phi0
      mu[trunc-1, ind1:ind2] = 2*np.sum(phi1*phi1, axis=0)-mu0
      p.step()

  # Return results
  return mu

def kpm(mat, states=[0], trunc=100, verbose=False):
  """Execute KPM. Encapsulate the core procedure into this function to be able
  to transfer it to compiler code (Cython/C/C++/Fortran)."""
  # 27/04/2011

  # mat should be a sparse matrix, ideally in the CSR format (for fast matrix-
  # vector multiplication). Is must already be rescaled, so that its
  # eigenspectrum lies within the interval [-1, 1]
  enum = mat.shape[0] # total number of entities
  snum = len(states)

  mus = np.zeros((trunc, snum), dtype=float) # holding all the moments of all states
  p = Progress((trunc-1)/2*snum, text='Calculate moments', verbose=verbose)
  for sind, state in enumerate(states):
    # Execute single KPM for each chosen state (start vector). Do not use
    # vectorization, avoiding slicing operations

    # Initialization
    p = Progress(1, text='Initialize iteration', verbose=verbose)
    phi0 = np.zeros(enum, dtype=float)
    phi0[state] = 1.
    mu = np.zeros(trunc, dtype=float)
    mu[0] = np.dot(phi0, phi0); mu0 = mu[0]
    phi1 = mat*phi0
    mu[1] = np.dot(phi1, phi0); mu1 = mu[1]
    p.step()

    # Iteration
    for n in xrange(1, trunc/2): # This is the critical for-loop that cannot be avoided
      phi2 = mat*2*phi1-phi0
      mu[2*n] = 2*np.dot(phi1, phi1)-mu0
      mu[2*n+1] = 2*np.dot(phi2, phi1)-mu1
      phi0, phi1 = phi1, phi2
      p.step()
    if trunc % 2 == 1: # If trunc is odd, calculate last moment
      phi2 = mat*2*phi1-phi0
      mu[trunc-1] = 2*np.dot(phi1, phi1)-mu0
      p.step()

    # Store moments of this state
    mus[:, sind] = mu

  # Return results
  return mus

def kpmc(mat, states=[0], trunc=100, verbose=False):
  """Execute KPM. The inner loop of the algorithm is ported to Cython.
  Advantage: Can show a progress bar."""
  # 28/04/2011
  import tbc

  # mat should be a sparse matrix, ideally in the CSR format (for fast matrix-
  # vector multiplication). Is must already be rescaled, so that its
  # eigenspectrum lies within the interval [-1, 1]
  mu = np.zeros((trunc, len(states)), dtype=float) # holding all the moments of all states
  p = Progress(len(states), text='Calculate moments', verbose=verbose) #(trunc-1)/2*
  for sind, state in enumerate(states):
    m = np.zeros(trunc, dtype=float)
    tbc.kpminner(mat.data, mat.indices, mat.indptr, mat.shape[0], state, trunc, m)
    mu[:, sind] = m
    p.step()

  # Return results
  return mu

def kpms(mat, states=[0], limit=8000, step=100, tol=.01, verbose=False):
  """Execute KPM. The inner loop of the algorithm is ported to Cython, together
  with the construction of the LDOS, only for one site at a time. A convergence
  criterion is used, stopping the iteration. Can show a progress bar over the sites."""
  # 09/05/2011
  import tbc

  # mat should be a sparse matrix, ideally in the CSR format (for fast matrix-
  # vector multiplication). It must already be rescaled, so that its
  # eigenspectrum lies within the interval [-1, 1]

  #assert len(states) == 1 # Easier for now
  #assert step == 0 # Easier for now

  #mu = np.zeros((trunc, len(states)), dtype=float) # holding all the moments of all states

  #energ = np.zeros((len(states), limit*2), dtype=float)
  energ = np.zeros(limit*2, dtype=float)
  dens = np.zeros((len(states), limit*2), dtype=float)
  trunc = np.zeros(len(states), dtype=int)
  p = Progress(len(states), text='Calculate moments', verbose=verbose) #(trunc-1)/2*
  for sind, state in enumerate(states):
    energ, dens[sind, :], mu, trunc[sind] = tbc.kpmconv(mat.data, mat.indices, mat.indptr, mat.shape[0], state=state, limit=limit, step=step, tol=tol)
    p.step()

  # Return results
  return energ, dens, trunc

def kpmc2(mat, states=[0], trunc=100, verbose=False):
  """Execute KPM. Both loops of the algorithm are ported to Cython."""
  # 28/04/2011
  raise NotImplementedError, 'There must still be some error...'
  import tbc

  # mat should be a sparse matrix, ideally in the CSR format (for fast matrix-
  # vector multiplication). Is must already be rescaled, so that its
  # eigenspectrum lies within the interval [-1, 1]
  mu = np.zeros(trunc*len(states), dtype=float) # holding all the moments of all states
  tbc.kpmouter(mat.data, mat.indices, mat.indptr, mat.shape[0], np.array(states, dtype=np.int32), len(states), trunc, mu)
  mu = mu.reshape((len(states), trunc)).transpose()

  # Return results
  return mu

def csr_matvec(mat, vect):
  """Multiply CSR matrix with vector."""
  # 21/04/2011
  indptr = mat.indptr
  indices = mat.indices
  data = mat.data
  m, n = mat.shape # number of rows and columns
  assert vect.shape == (n,)
  res = np.zeros_like(vect)
  for i in xrange(m):
    rowdata = data[indptr[i]:indptr[i+1]]
    rowindices = indices[indptr[i]:indptr[i+1]]
    vectdata = vect[rowindices]
    res[i] = np.sum(rowdata*vectdata)
  return res

def csr_matdmat(mat, dmat):
  """Multiply CSR matrix with dense matrix."""
  # 21/04/2011
  m = mat.shape[0]
  n = mat.shape[1]
  o = dmat.shape[1]
  assert dmat.shape == (n, o)
  res = np.zeros_like(dmat)
  for j in xrange(o):
    for i in xrange(m):
      res[i, j] = np.sum(mat.data[mat.indptr[i]:mat.indptr[i+1]]*dmat[mat.indices[mat.indptr[i]:mat.indptr[i+1]], j])
  return res

class MultiHistogram:
  """Class that offers the possibility to fill a histogram with values consecutively.
  The data values may be scalars or multidimensional arrays whose shape is
  given by shape. Then, for each element an indipendent histogram is produced."""
  # 03/06/2011-04/06/2011
  # See /usr/bin/epd/lib/python2.7/site-packages/numpy/lib/function_base.py
  # for inspiration.

  def __init__(self, bins=10, range=None, shape=None):
    """Initialize instance."""
    # 03/06/2011-04/06/2011

    # Define bin array
    if np.iterable(bins):
      bins = np.asarray(bins)
      if np.any(np.diff(bins) < 0):
	raise AttributeError, 'bins must increase monotonically'
      self._bins = bins
      self._nbins = len(bins)-1
    else:
      if range is None:
	mn, mx = 0., 0.
      else:
	mn, mx = range
      if mn > mx:
	raise AttributeError, 'max must be larger than min in range parameter'
      if mn == mx:
	mn -= .5
	mx += .5
      self._bins = np.linspace(mn, mx, bins+1)
      self._nbins = bins

    # Define histogram and value shape
    if shape is not None:
      if not np.iterable(shape):
	shape = (shape,)
      if np.any(np.array(shape) < 1):
	raise AttributeError, 'shape tuple may only contain positive integers'
      self._hist = np.zeros(shape+(self._nbins,), dtype=int)
    else:
      self._hist = np.zeros((self._nbins,), dtype=int)
    self._shape = shape

  def add(self, value):
    """Add a value to the histogram. The value may be a scalar or a
    multidimensional array."""
    # 03/06/2011-04/06/2011

    indices = np.searchsorted(self._bins, value, side='right')-1
    if typename(value) == 'ndarray' or np.asanyarray(value).shape > 1:
      value = np.asarray(value)
      if self._shape is None:
	raise ValueError, 'expected scalar value'
      if value.shape != self._shape:
	raise ValueError, 'expected array of shape %s' % str(self._shape)
      for ndind in np.ndindex(self._shape):
	# The rightmost bin should not be half-open (include upper range)
	if indices[ndind] == self._nbins and value[ndind] == self._bins[-1]:
	  indices[ndind] = self._nbins-1

	# Count value, ignoring values that lie outside range
	if indices[ndind] >= 0 and indices[ndind] < self._nbins:
	  self._hist[ndind+(indices[ndind],)] += 1

    elif np.iterable(value):
      if self._shape is None:
	raise ValueError, 'expected scalar value'
      if len(self._shape) != 1:
	raise ValueError, 'Value has to be of shape %s' % str(self._shape)
      if len(value) != self._shape[0]:
	raise ValueError, 'Value has the wrong length: Expected %i' % self._shape[0]

      for ind in xrange(len(value)):
	# The rightmost bin should not be half-open (include upper range)
	if indices[ind] == self._nbins and value[ind] == self._bins[-1]:
	  indices[ind] = self._nbins-1

	# Count value, ignoring values that lie outside range
	if indices[ind] >= 0 and indices[ind] < self._nbins:
	  self._hist[ind, indices[ind]] += 1
    else:
      if self._shape is not None:
	raise ValueError, 'expected data with shape %s, but got scalar value.' % str(self._shape)

      # The rightmost bin should not be half-open (include upper range)
      if indices == self._nbins and value == self._bins[-1]:
	indices = self._nbins-1

      # Count value, ignoring values that lie outside range
      if indices >= 0 and indices < self._nbins:
	self._hist[indices] += 1

  def __call__(self, normed=False, mean=False):
    """Return histogram."""
    # 03/06/2011-05/06/2011
    if normed:
      db = np.array(np.diff(self._bins))
      if self._shape is None:
        if np.sum(self._hist) == 0.:
          #raise ZeroDivisionError, 'cannot return empty normed histogram.'
          return np.asarray(self._hist, dtype=float)
        else:
          return self._hist/np.sum(self._hist*db, dtype=float)
      else:
        normedhist = np.zeros(self._hist.shape, dtype=float)
        for ndind in np.ndindex(self._shape):
          #dump(hist=self._hist[ndind], ndind=ndind)
          if np.sum(self._hist[ndind]) == 0.:
            #raise ZeroDivisionError, 'cannot return empty normed histogram for data index %s' % str(ndind)
            normedhist[ndind] = np.asarray(self._hist[ndind], dtype=float)
          else:
            normedhist[ndind] = self._hist[ndind]/np.sum(self._hist[ndind]*db, dtype=float)
        return normedhist
    elif mean:
      raise NotImplementedError
      if self._shape is None:
        return self._hist/np.mean(self._hist, axis=-1)
    else:
      return self._hist

  def num(self):
    """return number of collected values. If multidimensional values are used
    (shape != None), an array with the same shape is returned, containing the
    number of collected values for each histogram separately."""
    # 04/06/2011
    return np.sum(self._hist, axis=-1)

  def bins(self, centers=False):
    """Return histogram bins. If centers is set to True, return the centers of
    each bin interval. If centers is set to False, return the interval edges."""
    # 04/06/2011
    if centers:
      return self._bins[:-1]+np.diff(self._bins)/2
    else:
      return self._bins




class Model:
  """Apply a model function on a set of numerical data and fit it to the
  data points."""
  # 06/06/2011
  # former mytools.Model

  _func = None # model function object
  _est = None # Estimate of parameters
  _strrep = None # String representation of the model function. Must have "%.2f" and similar constructions of number pnum
  _pnum = None # Number of parameters of the model
  _param = None # Resulting parameter set
  _xmin = None # Data minimum and maximum values
  _xmax = None
  _ymin = None
  _ymax = None
  _sumls = None # Resulting sum of least squares
  _nfev = None # Number of function calls
  _mesg = None # Message from leastsq
  _ier = None # Status code of the result

  def __init__(self, func, est=None, strrep=None, pnum=None):
    self._func = func
    self._strrep = strrep
    if est != None:
      if not isiterable(est):
        est = (est,)
      self._est = tuple(est)
      self._pnum = len(est)
    else:
      if pnum == None:
        raise IOError, 'number of parameters ambiguous. Set at least one of \'est\' or \'pnum\''
      assert pnum > 0, 'number of parameters must be greater than zero'
      self._pnum = pnum
      e = []
      for i in xrange(pnum):
        e.append(0.)
      self._est = tuple(e)

  def res(self, param, x, y):
    """Get residuals of the model function."""
    return y-self._func(x, param)

  def func(self, x, param=None):
    x = np.array(x)
    if param == None:
      if self._param == None:
        raise IOError, 'no parameter set given'
      return self._func(x, param)
    else:
      if len(param) != self._pnum:
        raise IOError, 'wrong number of parameters'
      return self._func(x, param)

  def __str__(self):
    if self._param == None:
      raise IOError, 'no parameter set given'
    return self._strrep % self._param

  def pnum(self):
    return self._pnum

  def est(self):
    return self._est

  def param(self):
    return self._param

  def sumls(self):
    return self._sumls

  def nfev(self):
    return self._nfev

  def mesg(self):
    return self._mesg

  def ier(self):
    return self._ier

  def leastsq(self, x, y):
    x = np.array(x).flatten()
    y = np.array(y).flatten()
    assert len(x) == len(y), 'x and y data have to have equal length'

    param, cov, infodict, self._mesg, self._ier = opti.leastsq(self.res, self._est, args=(x, y), full_output=True, maxfev=10000000) #full_output=True, maxfev=10000

    if not isiterable(param):
      param = (param,)
    self._param = tuple(param)
    self._xmin, self._xmax = min(x), max(x)
    self._ymin, self._ymax = min(y), max(y)
    self._nfev = infodict['nfev']

    # Calculate resulting sum of least squares
    sumls = 0.
    for i in xrange(len(x)):
      myx, myy = x[i], y[i]
      sumls += self.res(param, myx, myy)**2
    self._sumls = sumls

    return self._param, self._sumls, self._nfev

  def plot(self, param=None, xnum=50, xmin=None, xmax=None, fmt='r--'):
    if xmin != None:
      self._xmin = xmin
    if xmax != None:
      self._xmax = xmax
    x = np.linspace(self._xmin, self._xmax, xnum)
    if param == None:
      if self._param == None:
        raise IOError, 'no parameter set given'
      param = self._param
    if len(param) != self._pnum:
      raise IOError, 'wrong number of parameters'
    y = self._func(x, param)
    import matplotlib.pyplot as plt
    return plt.plot(x, y, fmt)

  def text(self, x=None, y=None, color='red'):
    if x == None:
        x = self._xmin
    if y == None:
        y = self._ymax
    import matplotlib.pyplot as plt
    return plt.text(x, y, self.__str__()+'   sum_err = %e' % self.sumls(), color=color)





#=================================================#
# Classes that define basic properties of scripts #
#=================================================#

class BaseProc(object):
  """Define basic properties that all processor objects will share."""
  # 27/01/2011-02/06/2011

  # Define basic class properties (may be overwritten by child classes)
  version = '02/06/2011'    # Version of this processor class
  usage = '%prog [options]' # A string, usually of the form "scriptname [options] arguments", explaining how this processor should be called in shell mode
  epilog = ''               # Help text showed beneath the option list
  prog = ''                 # Name of this processor instance
  funcmode = True           # Whether this processor instance is called in function mode or in shell mode
  argtype = None            # Data type of positional arguments in shell mode. If None, the arguments contain filenames. Otherwise, the positional command line arguments (strings) will be casted to the specified type
  nif = 0                   # Number of required input filenames (if in shellmode and argtype == None). If set to None, all remaining filenames are input filenames (and at least 1 is required).
  niof = 0                  # Number of required combined input-output filenames (if in shellmode and argtype == None). If set to None, all remaining filenames are combined input-output filenames (and at least 1 is required).
  nof = 0                   # Number of required output filenames (if in shellmode and argtype == None). If set to None, all remaining filenames are output filenames (and at least 1 is required).
  # --> Note that only one of the attributes nif, niof and nof may be set to None.

  def __init__(self):
    # Initialize execution time measurement
    self.start = time.time()                        # Starting time of execution
    self.width = 80                                 # Standard terminal width

    # Initialize input and output data structures
    self.fin = []                                   # Input filenames (list of strings)
    self.finout = []                                # Combined input-output filenames (list of strings)
    self.fout = []                                  # Output filenames (list of strings)
    self.din = []                                   # List of input data (list or generator of struct objects)
    self.dinout = []                                # List of combined input-output data (list or generator of struct objects)
    self.dout = struct()                            # Output data (list of struct or struct object)
    self.pin = []                                   # List of input parameter sets (list or generator of struct objects)
    self.pinout = []                                # List of combined input-output parameter sets (list or generator of struct objects)
    self.pout = struct()                            # Output parameter set (list of struct or struct object)
    self.cin = []                                   # Comments of input files (list or generator of struct objects)
    self.cinout = []                                # Comments of combined input-output files (list or generator of struct objects)
    self.cout = struct()                            # User-defined comments (struct)

    # Initialize option parser
    self.prog = self.__class__.__name__[1:].lower() # Store name of this processor class
    self.argv = sys.argv[1:]                        # Store command line arguments, without the name of the python script. Will be passed to the option parser to filter out the options
    self.op = opt.OptionParser(version=' ')         # Instanciate option parser
    self.opts = []                                  # Will contain the options that are returned by the option parser (in both cases, shell mode and function mode)
    self.args = []                                  # Will contain positional arguments that are returned by the option parser (in both cases, shell mode and function mode)

    # Check class properties
    assert self.nof == None or self.nof >= 0, 'number of output filenames must be either None or positive integer (including zero), but %s given' % str(self.nof)

    # Define general options
    og = opt.OptionGroup(self.op, 'General options')
    og.add_option('--log', dest='log', default='', help='append command line to the specified text file')
    og.add_option('-v', '--verbose', dest='verbose', default=False, action='store_true', help='activate verbose mode')
    og.add_option('--ext', dest='ext', default='.h5', type=str, help='set filename extension. This extension will automatically be added to given filenames (or patterns) if they do not already end in it')
    og.add_option('--comments', dest='comments', default=False, action='store_true', help='also return comments (only in function mode)')
    self.op.add_option_group(og)

  def __call__(self, *args, **kwargs):
    # Initialize values again at every new function call
    self.__init__()

    # Get width of the terminal window
    # Source: optparse module
    # 31/05/2011
    try:
      self.width = int(os.environ['COLUMNS'])
    except (KeyError, ValueError):
      # Assume standard width
      self.width = 80

    # Check number of different kinds of filenames
    assert self.nif == None or self.nif >= 0, 'number of input filenames must be non-negative integer or None'
    assert self.niof == None or self.niof >= 0, 'number of combined input-output filenames must be non-negative integer or None'
    assert self.nof == None or self.nof >= 0, 'number of output filenames must be non-negative integer or None'
    assert self.nnf() < 2, 'only one of nif, niof and nof may be None'

    # Prevent the option parser from calling sys.exit
    if self.funcmode:
      self.op.exit = self.noexit

    # Empty the argument list in function mode (IS THIS THE RIGHT DECISION???)
    # May be superfluous
    if self.funcmode:
      self.argv = []

    # Append options from function arguments
    for kwarg in kwargs:
      # If help option is specified, ignore
      if kwarg in ['h', 'help', 'version']:
        continue

      # If a keyword argument is set to None, ignore
      if kwargs[kwarg] == None:
        continue

      # If option argument is boolean, reason that option does not require an
      # argument. Otherwise, append argument value
      if isinstance(kwargs[kwarg], bool):
        # Depending on default value, append bool option (without a value) or
        # not. For now, just assume the default value is always False. So, only
        # append the option if the value is True. Theoretically, the default
        # value would have to be retrieved from the option parser object.
        if kwargs[kwarg] == True:
          # Distinguish between short and long options
          if len(kwarg) == 1:
            self.argv.append('-'+kwarg)
          else:
            self.argv.append('--'+kwarg)
      else:
        # Distinguish between short and long options
        if len(kwarg) == 1:
          self.argv.append('-'+kwarg)
        else:
          self.argv.append('--'+kwarg)

        self.argv.append(str(kwargs[kwarg]))

    """# Get input data
    if self.funcmode:
      # Get input data from positional arguments
      self.i = self.args
      self.argv = []
    else:
      # Get input data and options from command line
      self.prog = basename(sys.argv[0], '.py') # Overwrite prog with script name, even if it is the same as the class name
      self.argv = sys.argv[1:]"""

    # Append information about default value to option help strings, if not
    # already done
    # Cycle through all options in all option groups
    self.help_default(self.op)
    for og in self.op.option_groups:
      self.help_default(og)

    # Move help and version option to general option group
    self.op.option_groups[0].option_list.append(self.op.option_list.pop(0))
    self.op.option_groups[0].option_list.append(self.op.option_list.pop(0))

    # Show help if in shell mode, and argtype == None, and no positional
    # arguments are given, and number of required filenames (nif+niof+nof) is
    # greater than zero.
    if self.shellmode and self.argtype == None and len(self.argv) == 0 and self.nrf() > 0:
      self.argv.append('-h')

    # Parse command line
    self.op.prog = self.prog
    self.op.version = self.version
    self.op.usage = self.usage
    self.op.epilog = '\n'.join([s.strip() for s in self.epilog.split('\n')]) # How can line breaks be preserved? Maybe find the responsible mothod of optparse.OptionParser
    self.op.description = '\n'.join([s.strip() for s in self.__doc__.split('\n')]) # How can line breaks be preserved? Maybe find the responsible mothod of optparse.OptionParser
    self.opts, posargs = self.op.parse_args(self.argv)

    # Store function arguments or command line arguments, depending on function mode
    #self.kwargs = kwargs # Options not necessarily needed anymore, but store them as well
    if self.funcmode:
      self.args = args
    else:
      self.args = posargs

    # Log
    self.log()

  def noexit(self, status=0, msg=None):
    """Method to overwrite optparse.OptionParser().exit, so that it does not
    try to exit the script any more via sys.exit(status)."""
    # 28/01/2011
    #if msg:
    #    sys.stderr.write(msg)
    pass

  def log(self):
    """If the log options is not None, append the command line to the specified text file.
    The log option itself is removed from the command line before saving it.
    The command line is not appended to the text file if the very same line already exists.
    Return True if command has successfully been written to the log file, or False if not."""
    # 10/01/2011-28/01/2011
    # former mytools.log from 15/04/2010-27/05/2010
    if self.opts.log and not self.funcmode:
      commandlist = [self.prog]+self.argv

      # Filter out occurences of the log option itself
      for i in xrange(len(commandlist)-1):
        if not i < len(commandlist):
          break
        if commandlist[i] == '--log':
          del commandlist[i]
          if i < len(commandlist):
            del commandlist[i]
      command = ' '.join(commandlist)

      # Does this very command line already exist in the file?
      if os.path.exists(self.opts.log):
        f = open(self.opts.log, 'r')
        if not command in [i.replace('\n', '') for i in f.readlines()]:
          # Append command to text file
          f = open(self.opts.log, 'a')
          f.write(command+'\n')
          f.close()
          return True
      else:
        # Write command to new text file
        f = open(self.opts.log, 'w')
        f.write(command+'\n')
        f.close()
        return True
    else:
      return False

  def load(self, *args, **kwargs):
    """Load data from HDF5 file or from function arguments."""
    # 02/02/2011-02/06/2011

    # Handle special keyword arguments
    if 'dgroup' in kwargs:
      dgroup = kwargs.pop('dgroup')
    else:
      dgroup = 'data' # Default value
    if 'pgroup' in kwargs:
      pgroup = kwargs.pop('pgroup')
    else:
      pgroup = 'param' # Default value
    if 'cgroup' in kwargs:
      cgroup = kwargs.pop('cgroup')
    else:
      cgroup = 'comment' # Default value
    if 'extension' in kwargs:
      extension = kwargs.pop('extension')
    elif 'ext' in self.opts.__dict__:
      extension = self.opts.ext
    else:
      extension = '.h5' # Default value
    if 'funcmode' in kwargs:
      funcmode = kwargs.pop('funcmode')
    elif 'shellmode' in kwargs:
      funcmode = not kwargs.pop('shellmode')
    else:
      funcmode = self.funcmode # Default value
    if 'iterate' in kwargs:
      iterate = kwargs.pop('iterate')
    else:
      iterate = True # Default value

    """# Use glob to find all files matching a given filename pattern, even on
    # Windows machines
    # 03/04/2011
    newposargs = []
    for ind, posarg in enumerate(posargs[:]):
      globresult = glob.glob(posarg)
      if len(globresult) > 0:
        newposargs += globresult
      else:
        newposargs.append(posarg)
    posargs = newposargs"""

    if not funcmode and self.argtype == None:
      # args contains filenames, load input data from files

      # Retrieve filenames from positional arguments
      # Use globbing (especially important on Windows, because there the shell does not glob itself)
      filenames = []
      for arg in self.args:
        if not arg.endswith(extension):
          arg += extension
        globfiles = glob.glob(arg)
        if len(globfiles) == 0:
          # At least expand '[]' and '{}', but not '*' or '?'?
          filenames.append(arg)
        else:
          filenames += globfiles
      assert len(filenames) >= self.nrf(), 'too few filenames given. Only %i given, but expected at least %i' % (len(filenames), self.nrf())
      #dump(nif=self.nif, niof=self.niof, nof=self.nof)
      if self.nif == None:
        if self.niof+self.nof == 0:
          self.fin = filenames
          self.finout = []
          self.fout = []
        else:
          self.fin = filenames[:-(self.niof+self.nof)]
          self.finout = filenames[-(self.niof+self.nof):-self.nof]
          self.fout = filenames[-self.nof:]
      else:
        self.fin = filenames[:self.nif]
        if self.niof == None:
          if self.nof == 0:
            self.finout = filenames[self.nif:]
            self.fout = []
          else:
            self.finout = filenames[self.nif:-self.nof]
            self.fout = filenames[-self.nof:]
        else:
          self.finout = filenames[self.nif:(self.nif+self.niof)]
          if self.nof == None:
            self.fout = filenames[(self.nif+self.niof):]
          else:
            self.fout = filenames[(self.nif+self.niof):(self.nif+self.niof+self.nof)]
            assert len(filenames) == self.nif+self.niof+self.nof, 'too many filenames given: %i. Only expecting %i, from which %i are input filenames, %i are combined input-output filenames and %i are output filenames' % (len(filenames), self.nif+self.niof+self.nof, self.nif, self.niof, self.nof)
      del filenames

      if iterate:
        # Return generator objects instead of lists, loading data from the
        # files one after another. Concerns data, comment and param
        kwargs.update(filenames=self.fin, dgroup=dgroup, extension=extension)
        self.din = xdin(*args, **kwargs)
        kwargs['filenames'] = self.finout
        self.dinout = xdin(*args, **kwargs)

        self.pin = xpin(filenames=self.fin, pgroup=pgroup, extension=extension)
        self.pinout = xpin(filenames=self.finout, pgroup=pgroup, extension=extension)

        self.cin = xcin(filenames=self.fin, cgroup=cgroup, extension=extension)
        self.cinout = xcin(filenames=self.finout, cgroup=cgroup, extension=extension)

        # Already use the generator object xpin to cycle through all input
        # files, load the parameter sets and calculate the intersection of
        # them, store the result in pout. Note that nothing will be done about
        # the parameter sets in pinout, as they do not need to be changed and
        # just are saved and overwritten again in the end (example: hamilt)
        self.pout = None
        for param in self.pin:
          if typename(self.pout) == 'NoneType':
            # Just put the first parameter set into pout
            self.pout = param
          else:
            # Then, calculate the intersection of all other parameter sets with pout
            self.pout = self.pout.intersection(param)
        if typename(self.pout) == 'NoneType':
          self.pout = struct()

      else:
        raise NotImplementedError # Do I still need this? Anyway, finout etc. would have to be respected

        # Use lists to store input data, input parameters and input comments
        for filename in self.fin:
          # Open HDF5 file
          f = hdf.File(filename, 'r')

          # Always load parameter set of the file, if available
          if pgroup in f:
            param = struct(loadhdf(f, pgroup))
          else:
            param = struct()
          self.pin.append(param)

          # Always load comment of the file, if available
          comment = struct()
          if cgroup in f:
            for key in f[cgroup]:
              comment[key] = loadhdf(f[cgroup], key)
          self.cin.append(comment)

          # Load data
          if not dgroup in f:
            #raise KeyError, 'no data group in HDF5 file %s' % filename
            self.din.append(struct())
            continue
          g = f[dgroup]

          # If only argument is 'all', load all data
          if len(args) == 1 and len(kwargs) == 0 and args[0] == 'all':
            args = g.keys()

          # Load data
          s = struct()
          for arg in args:
            if arg in g:
              s[arg] = loadhdf(g, arg)
            else:
              raise NameError, 'no dataset named %s in group %s of file %s' % (arg, dgroup, filename)
          for kwarg in kwargs:
            if kwargs[kwarg] in g:
              s[kwarg] = loadhdf(g, kwargs[kwarg])
            else:
              raise NameError, 'no dataset named %s in group %s of file %s' % (kwargs[kwarg], dgroup, filename)

          # Store data and close file
          self.din.append(s)
          f.close()

        # Already merge input parameter sets to form output parameter set
        if len(self.pin) > 0:
          self.pout = self.pin[0].intersection(*self.pin[1:])
        else:
          self.pout = struct()

    else:
      # function mode, args itself contains input data
      if len(self.args) == 1 and typename(self.args[0]) in ['xpin', 'xdin', 'xcin']:
	# generator found
	self.din = self.args[0]
      else:
	for inputindex, inputobj in enumerate(self.args):
	  if isinstance(inputobj, struct) or isinstance(inputobj, dict):
	    s = struct()
	    for arg in args:
	      if arg in inputobj:
		s[arg] = inputobj[arg]
	      else:
		raise NameError, 'no field named %s in input argument %i' % (arg, inputindex+1)
	    for kwarg in kwargs:
	      if kwargs[kwarg] in inputobj:
		s[kwarg] = inputobj[kwargs[kwarg]]
	      else:
		raise NameError, 'no field named %s in input argument %i' % (kwargs[kwarg], inputindex+1)
	    self.din.append(s)

	  # This is not good if function arguments are arrays that are also iterable
	  #elif isiterable(inputobj):
	  #  if len(args) > 0:
	  #    inputobj = list(inputobj)
	  #    s = struct()
	  #    for arg in args:
	  #      s[arg] = inputobj.pop(0)
	  #    for kwarg in kwargs:
	  #      s[kwarg] = inputobj.pop(0)
	  #    self.din.append(s)
	  #  else:
	  #    self.din.append(inputobj)"""

	  else:
	    if len(args) > 0:
	      s = struct()
	      s[args[0]] = inputobj
	      self.din.append(s)
	    else:
	      self.din.append(inputobj) # But script definition must be able to handle this!

  def save(self, *args, **kwargs):
    """Save data to hdf5 file or return it (depending on function mode)."""
    # 02/02/2011-02/06/2011

    # Handle special keyword arguments
    if 'dgroup' in kwargs:
      dgroup = kwargs.pop('dgroup')
    else:
      dgroup = 'data' # Default value
    if 'cgroup' in kwargs:
      cgroup = kwargs.pop('cgroup')
    else:
      cgroup = 'comment' # Default value
    if 'pgroup' in kwargs:
      pgroup = kwargs.pop('pgroup')
    else:
      pgroup = 'param' # Default value
    if 'mode' in kwargs: # I do not know if this option should even exist, as it would be nonsense (even dangerous) to overwrite an existent file, cropping all it's data
      mode = kwargs.pop('mode')
    else:
      mode = 'a' # Default value
    assert mode in ['a', 'w'], 'unknown mode %s, only a (append) or w (write) allowed' % mode
    if 'struct' in kwargs:
      stru = kwargs.pop('struct')
    else:
      stru = False # Default value
    assert isinstance(stru, bool), 'expecting boolean value for struct keyword argument'
    if 'extension' in kwargs:
      extension = kwargs.pop['extension']
    elif 'ext' in self.opts.__dict__:
      extension = self.opts.ext
    else:
      extension = '.h5' # Default value
    if 'funcmode' in kwargs:
      funcmode = kwargs.pop('funcmode') # Overwrite function mode
    elif 'shellmode' in kwargs:
      funcmode = not kwargs.pop('shellmode')
    else:
      funcmode = self.funcmode # Default value
    if 'prog' in kwargs:
      prog = kwargs.pop('prog')
    else:
      prog = self.prog # Default value
    if 'comments' in kwargs:
      comments = kwargs.pop('comments')
    else:
      comments = self.opts.comments # Default value
    assert isinstance(stru, bool), 'expecting boolean value for struct keyword argument'

    # If no special data was selected using arguments, select all available data
    if len(args)+len(kwargs) == 0:
      args = self.dout.keys()

    if funcmode:
      if stru:
        # Just return self.dout as struct object
        return self.dout

      # Return selected data as tuple
      result = []
      for arg in args:
        if arg in self.dout:
          result.append(self.dout[arg])
        else:
          raise NameError, 'no field named %s in output data' % arg
      for kwarg in kwargs:
        if kwargs[kwarg] in self.dout:
          result.append(self.dout[kwargs[kwarg]])
        else:
          raise NameError, 'no field named %s in output data' % kwargs[kwarg]

      # Maybe return also comments as last value
      if comments:
	result.append(self.cout)

      if len(result) > 1:
        return tuple(result)
      elif len(result) > 0:
        return result[0]
      else:
        return None

    else:
      if self.argtype == None and self.nof == 1:
        # self.args contains filenames

        #assert len(self.args) > 0, 'too few positional command line arguments. Unable to save data.'
        #filename = self.args[-1]

        if typename(self.dinout) == 'struct':
          self.dinout = [self.dinout]
        assert len(self.dinout) == len(self.pinout) == len(self.finout), 'wrong number of combined input-output datasets or input-output parameter sets given. %i I/O files given, but only %i I/O datasets and %i I/O parameter sets given' % (len(self.finout), len(self.dinout), len(self.pinout))
        for filename, data, param in zip(self.finout, self.dinout, self.pinout):
          # Open hdf5 file
          if not filename.endswith(extension):
            filename += extension
          f = hdf.File(filename, mode)

          # Save data
          g = f.require_group(dgroup)
          for arg in args:
            if arg in data:
              savehdf(g, **{arg: data[arg]})
            else:
              raise NameError, 'no field named %s in output data' % arg
          for kwarg in kwargs:
            if kwargs[kwarg] in data:
              savehdf(g, **{kwarg: data[kwargs[kwarg]]})
            else:
              raise NameError, 'no field named %s in output data' % kwargs[kwarg]

          # Save parameter set
          if pgroup in f:
            del(f[pgroup])
          g = f.create_group(pgroup)
          savehdf(g, **param)

          # Save comment
          g = f.require_group(cgroup)
          if self.prog in g:
            del(g[self.prog]) # Overwrite existing comment
          savehdf(g, **{self.prog: self.comment(**self.cout)})

          # Close hdf5 file
          f.close()

        if typename(self.dout) == 'struct':
          self.dout = [self.dout]
        #dump(fin=self.fin, fout=self.fout, finout=self.finout, nif=self.nif, niof=self.niof, nof=self.nof)
        assert len(self.dout) == len(self.fout), 'wrong number of output datasets given. %i output files given, but only %i output datasets given' % (len(self.fout), len(self.dout))
        for filename, data in zip(self.fout, self.dout):
          # Open hdf5 file
          if not filename.endswith(extension):
            filename += extension
          f = hdf.File(filename, mode)

          # Save data
          g = f.require_group(dgroup)
          for arg in args:
            if arg in data:
              savehdf(g, **{arg: data[arg]})
            else:
              raise NameError, 'no field named %s in output data' % arg
          for kwarg in kwargs:
            if kwargs[kwarg] in data:
              savehdf(g, **{kwarg: data[kwargs[kwarg]]})
            else:
              raise NameError, 'no field named %s in output data' % kwargs[kwarg]

          # Save parameter set
          if pgroup in f:
            del(f[pgroup])
          g = f.create_group(pgroup)
          savehdf(g, **self.pout)

          # Save comment
          g = f.require_group(cgroup)
          if self.prog in g:
            del(g[self.prog]) # Overwrite existing comment
          savehdf(g, **{prog: self.comment(**self.cout)})

          # Close hdf5 file
          f.close()

      else:
        # print data to stdout (string representation)
        for arg in args:
          if arg in self.dout:
            print self.dout[arg]
          else:
            raise NameError, 'no field named %s in output data' % arg
        for kwarg in kwargs:
          if kwargs[kwarg] in self.dout:
            print self.dout[kwargs[kwarg]]
          else:
            raise NameError, 'no field named %s in output data' % kwargs[kwarg]

  def comment(self, **kwargs):
    """Return comment structure with some information about the execution of this
    script."""
    # 31/01/2011
    s = struct()

    # Date
    s.date=time.ctime()

    # Number of input files
    if not self.funcmode:
      if len(self.din) > 0:
        s.inputfiles = len(self.din)

    # Time elapsed
    s.elapsed = time.time()-self.start

    # Platform
    s.system, s.node, s.release, s.version, s.machine, s.processor = pf.uname()

    # Number of processor cores of this machine's CPU
    s.npc = npc()

    # Add user-defined comments
    for kwarg in kwargs:
      #assert typename(kwargs[kwarg]) == 'str', 'only strings are accepted as comments. %s does not contain a string' % kwarg
      s[kwarg] = kwargs[kwarg]

    # Return comment structure
    return s

  def __setattr__(self, name, value):
    # 09/02/2011
    if name == 'shellmode':
      self.funcmode = not value
    else:
      # Otherwise, just behave normally
      self.__dict__[name] = value

  def __getattr__(self, name):
    # 09/02/2011
    if name == 'shellmode':
      return not self.funcmode
    else:
      # Otherwise, just behave normally
      return self.__dict__[name]

  def help_default(self, op):
    """Automatically append information about the default value to the help
    string of the given optparse.OptionParser or optparse.OptionGroup object."""
    # 11/02/2011
    for o in op.option_list:
      if not '%default' in o.help:
        if o.action == 'store':
          if str(o.default) != '':
            # Then append the information to the help string
            if not o.help[-1] in '.!':
              o.help += '.'
            if o.help[-1] != ' ':
              o.help += ' '
            o.help += 'Default: %default'

  def nrf(self):
    """Return number of required filenames, i.e. the sum of nif, niof and nof,
    counting None as 1."""
    result = 0
    if self.nif == None:
      result += 1
    else:
      result += self.nif
    if self.niof == None:
      result += 1
    else:
      result += self.niof
    if self.nof == None:
      result += 1
    else:
      result += self.nof
    return result

  def nnf(self):
    """Return number of the values nif, niof and nof being None."""
    result = 0
    if self.nif == None:
      result += 1
    if self.niof == None:
      result += 1
    if self.nof == None:
      result += 1
    return result



class PlotProc(BaseProc):
  """Define properties for plotting scripts."""
  # 09/01/2011-21/02/2011
  version = '21/02/2011'
  nif = None
  niof = 0
  nof = 0
  import matplotlib.pyplot as plt

  def __init__(self):
    BaseProc.__init__(self)

    # Define options
    og = opt.OptionGroup(self.op, 'Plot options', 'Options to configure the figure.')
    og.add_option('-s', '--show', default=False, action='store_true', dest='show', help='show plot')
    og.add_option('--title', dest='title', type=str, default='', help='set title of the figure')
    og.add_option('--xlabel', dest='xlabel', type=str, default='', help='set x-axis label of the figure')
    og.add_option('--ylabel', dest='ylabel', type=str, default='', help='set y-axis label of the figure')
    og.add_option('--zlabel', dest='zlabel', type=str, default='', help='set z-axis label of the figure') # Or only in subclass 3dPlotProc?
    self.op.add_option_group(og)

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check command line arguments
    #assert

    # Create figure
    #mpl.figure(dpi=)

    # Other things that are done in EVERY plot script...

  def savefig(self):
    """Save figure to file."""
    # 17/01/2011
    pass



class ModelProc(BaseProc):
  """Define properties that all model defining scripts share."""
  # 31/03/2011-06/04/2011
  usage = '%prog [options] filenames'
  nif = 0
  niof = 0
  nof = 1

  def __init__(self):
    BaseProc.__init__(self)

    # Define model options
    og = opt.OptionGroup(self.op, 'Model options', 'Options to define the tight binding model.')
    og.add_option('-b', '--bcond', dest='bcond', type=str, default='p', help='set boundary conditions. Must be a string consisting only of the characters "s" (static), "p" (periodic) and "a" (anti-periodic). The length of the string must not be greater than the number of dimensions (length of shape).')
    og.add_option('-o', '--hop', dest='hop', type=float, default=-1., help='set hopping parameter')
    og.add_option('-p', '--pot', dest='pot', default='0.', help='set potential energy. For some models (i.e. alloys), multiple comma-separated values may be accepted')
    og.add_option('-r', '--reals', dest='reals', type=str, default='0', help='set desired realization indices. Multiple ranges may be given, e.g. ":10,14,20:40:2" would be a valid definition of indices, resulting in the creation of 21 realizations of the system')
    og.add_option('-s', '--shape', dest='shape', type=str, default='10,10,10', help='set shape of the lattice (number of unitcells in each dimension, separated by a comma)')
    self.op.add_option_group(og)

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check model options
    self.opts.shape = tuple(opt2list(self.opts.shape))
    self.dim = len(self.opts.shape)
    self.size = np.prod(self.opts.shape)
    for value in self.opts.shape:
      assert value > 0, 'lattice shape must consist of positive integers'
    self.opts.reals = opt2ranges(self.opts.reals)
    assert min(self.opts.reals) >= 0, 'negative realization index is not allowed'
    self.opts.pot = np.array(opt2list(self.opts.pot, dtype=float))

  def saveparam(self, param, pgroup='param', cgroup='comment', extension='.h5', mode='a', filename=None):
    """Save parameter set defined by this script to HDF5 file, if in
    shell mode. If in function mode, just return the parameter set."""
    # 31/01/2011-07/02/2011

    # If in function mode, just return parameter set
    if self.funcmode:
      return param

    # If not in function mode, save parameter set to HDF5 file
    if filename == None:
      assert len(self.args) > 0, 'too few positional command line arguments. Unable to save data.'
      filename = self.args[-1]

    # Open hdf5 file
    if not filename.endswith(extension):
      filename += extension
    assert mode in ['a', 'w'], 'unknown file open mode: %s. Expecting either a or w' % mode
    f = hdf.File(filename, mode=mode)

    # Delete old parameter group and create a new one
    d = dict()
    d[pgroup] = param
    savehdf(f, **d)

    # Save comment
    g = f.require_group(cgroup)
    if self.prog in g:
      del(g[self.prog]) # Overwrite existing comment
    d = {}
    d[self.prog] = self.comment(**self.cout)
    savehdf(g, **d)

    # Close HDF5 file
    f.close()

  #def loadparam(self, pgroup='param', extension='.h5'):
    """Load parameter set from HDF5 file. Store it into self.din (shell mode)
    or return it as structure object (function mode)."""
    # 07/02/2011

  #  # Retreive filenames from positional arguments
  #  assert len(self.args) > 0, 'too few positional command line arguments. Unable to save data.'
  #  filenames = self.args[:-1]
  #
  #  for filename in filenames:
  #    # Open HDF5 file
  #    if not filename.endswith(extension):
  #      filename += extension
  #    f = hdf.File(filename, 'r')
  #
  #    # Load parameter set
  #    if not pgroup in f:
  #      raise NameError, 'no group called %s in file %s' % (pgroup, filename)
  #    self.pin.append(tb.loadhdf(f, pgroup))
  #
  #    # Close HDF5 file
  #    f.close()
  #
  #  # Return or store parameter set
  #  if self.funcmode:
  #    return param
  #  else:
  #    #self.pin =
  #    pass




class ModelProcBackup(BaseProc):
  """Define properties that all model defining scripts share."""
  # 27/01/2011
  usage = '%prog [options] filenames'

  def __init__(self):
    BaseProc.__init__(self)

    # Define model options
    og = opt.OptionGroup(self.op, 'Model options', 'Options to define the tight binding model.')
    og.add_option('-d', '--dims', default='100', dest='dims', help='define lattice dimensions. Use comma to separate different dimensions. The number of comma-separated values gives the dimensionality of the system, while each single number represents the number of lattice sites within that dimension.')
    og.add_option('-t', '--hopping-parameter', default=1., type=float, dest='hop', help='set constant hopping parameter. Only next-neighbour hopping supported so far')
    og.add_option('-p', '--potential-energy', dest='pot', default='0.', help='set potential energy. For alloys, multiple comma-separated values may be given')
    og.add_option('-b', '--bc', '--boundary-condition', default='p', dest='bc', help='set boundary condition. Values: p (periodic), s (static), a (anti-periodic).\nEach dimension can have its own boundary condition, specified by a comma-separated list of characters (e.g. "p,s", "p,a", "p,s,a", "p,p,s").\nIf the list is shorter than the dimensionality of the system, the rest of the dimensions get the same boundary condition as the last one given in the string. If the string is longer than the dimensionality of the system, an exception is raised.\nIf more than one character is given in a certain dimension, this means that multiple systems are created that only differ in the boundary condition in this specific dimension (e.g. "p,pa,s" will create two systems, one with the boundary condition "p,p,s" and one with "p,a,s"). To use this feature, the number of positional arguments must equal the number of boundary condition combinations that are specified in this way.')
    og.add_option('-n', '--configuration-number', type=int, dest='confs', default=1, help='set number of configurations for this system. If more than one configuration is needed, the file name must contain a certain number of number signs (#) which will be substituted by ascending numbers')
    #op.add_option('-b', '--basis', help='define basis of the lattice')
    self.op.add_option_group(og)

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check and process command line arguments
    self.opts.dims = opt2list(self.opts.dims)
    for d in self.opts.dims:
      assert d > 0, 'Bad system dimensions: %s. All dimensions have to be positive non-zero integer.' % str(self.opts.dims)
    self.dim = len(self.opts.dims) # Store dimensionality of the system
    self.size = np.prod(self.opts.dims) # Store lattice size

    self.opts.pot = opt2list(self.opts.pot, dtype=float)

    for b in self.opts.bc.split(','):
      for c in b:
        assert c in ['p', 's', 'a'], 'Bad boundary condition: %s. Unknown character %s.' % (self.opts.bc, c)
    assert self.opts.bc.split(',')[0] != '', 'Bad boundary condition: %s. Boundary condition of first dimension must not be empty.' % self.opts.bc
    assert len(self.opts.bc.split(',')) <= self.dim, 'Bad boundary condition: %s. More boundary conditions than dimensions given.' % self.opts.bc

    assert self.opts.confs > 0, 'Bad number of configurations: %i. Has to be at least 1.' % self.opts.confs
    if self.opts.confs > 1:
      for arg in self.args:
        assert arg.find('#') != -1, 'Filename error: %s. Not enough hash signs (#) to save the specified number of configurations.' % arg
        assert arg.count('#') >= len(str(self.opts.confs-1)), 'Filename error: %s. Not enough hash signs (#). %i hash signs are needed for the given number of configurations.' % (arg, len(str(self.opts.confs-1)))

    # Process boundary conditions
    # Expand array. Example: p,ps,a --> p,p,a + p,s,a
    condarray = self.opts.bc.split(',')
    maxlen = max([len(b) for b in condarray])
    self.bconds = []
    for i in xrange(maxlen):
      newcond = []
      for j in xrange(len(condarray)):
        if i >= len(condarray[j]):
          if len(condarray[j]) == 0:
            newcond.append('p')
          else:
            newcond.append(condarray[j][-1])
        else:
          newcond.append(condarray[j][i])
      self.bconds.append(newcond)

    # Are there any boundary conditions empty?
    for i in xrange(len(self.bconds)):
      for j in xrange(len(self.bconds[i])):
        if self.bconds[i][j] == '':
          self.bconds[i][j] = self.bconds[i][j-1]

    # Are there fewer boundary conditions than dimensions?
    for i in xrange(len(self.bconds)):
      for j in xrange(len(self.bconds[i]), self.dim):
        self.bconds[i].append(self.bconds[i][j-1])

    # Have enough filenames been specified?
    if self.shellmode:
      assert len(self.bconds) == len(self.args), 'Filename error: Wrong number of filenames given. Exactly %i filenames are needed for your choice of boundary conditions.' % len(self.bconds)

  def saveparam(self, param, pgroup='param', cgroup='comment', extension='.h5', mode='a', filename=None):
    """Save parameter set defined by this script to HDF5 file, if in
    shell mode. If in function mode, just return the parameter set."""
    # 31/01/2011-07/02/2011

    # If in function mode, just return parameter set
    if self.funcmode:
      return param

    # If not in function mode, save parameter set to HDF5 file
    if filename == None:
      assert len(self.args) > 0, 'too few positional command line arguments. Unable to save data.'
      filename = self.args[-1]

    # Open hdf5 file
    if not filename.endswith(extension):
      filename += extension
    assert mode in ['a', 'w'], 'unknown file open mode: %s. Expecting either a or w' % mode
    f = hdf.File(filename, mode=mode)

    # Delete old parameter group and create a new one
    d = dict()
    d[pgroup] = param
    savehdf(f, **d)

    # Save comment
    g = f.require_group(cgroup)
    if self.prog in g:
      del(g[self.prog]) # Overwrite existing comment
    d = {}
    d[self.prog] = self.comment(**self.cout)
    savehdf(g, **d)

    # Close HDF5 file
    f.close()

  def loadparam(self, pgroup='param', extension='.h5'):
    """Load parameter set from HDF5 file. Store it into self.din (shell mode)
    or return it as structure object (function mode)."""
    # 07/02/2011

    # Retreive filenames from positional arguments
    assert len(self.args) > 0, 'too few positional command line arguments. Unable to save data.'
    filenames = self.args[:-1]

    for filename in filenames:
      # Open HDF5 file
      if not filename.endswith(extension):
        filename += extension
      f = hdf.File(filename, 'r')

      # Load parameter set
      if not pgroup in f:
        raise NameError, 'no group called %s in file %s' % (pgroup, filename)
      self.pin.append(tb.loadhdf(f, pgroup))

      # Close HDF5 file
      f.close()

    # Return or store parameter set
    if self.funcmode:
      return param
    else:
      #self.pin =
      pass



class CalcProc(BaseProc):
  """Define properties that all calculating scripts have in common."""
  # 27/01/2011
  version = '28/01/2011'
  usage = '%prog [options] filenames'
  nif = None
  niof = 0
  nof = 1

  def __init__(self):
    BaseProc.__init__(self)





#=====================================================#
# Class definitions that correspond to actual scripts #
#=====================================================#

class _Abc(BaseProc):
  """Just a little test class."""
  # 09/01/2011
  version = '02/06/2011'
  epilog = 'Dies ist der Epilog.'
  usage = '%prog [options] arguments'
  argtype = str

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    #self.op.group
    #self.op.add_option

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Load data
    #self.load()

    # Main script
    print 'ABC, die Katze lief im Schnee.'
    dump(funcmode=self.funcmode, shellmode=self.shellmode, version=self.version, prog=self.prog, argv=self.argv, opts=self.opts, args=self.args, argtype=self.argtype, nif=self.nif, niof=self.niof, nof=self.nof, width=self.width)

    # Save data
    return self.save()



class _Cheb(BaseProc):
  """Calculate Chebyshev polynomial of given order of first or second kind
  using iterative formula. Either display the result (command line mode) or
  return the resulting scipy.poly1d objects (function mode)."""
  # 17/01/2011-08/04/2011
  version = '30/01/2011'
  epilog = """Future ideas:
  - ability to insert and return values (scalars, vectors, matrices, arrays)
  - instance remembers polynomials that were already calculated in a previous call"""
  nif = 0
  niof = 0
  nof = 0

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-k', '--kind', dest='kind', default=1, type=int, help='set first or second kind (1 or 2)')
    self.op.add_option('-o', '--order', dest='order', default='0', help='set order (positive integer or zero). Ranges may be given by two or three numbers, separated by a colon (:), where the third number gives the step witdh. Multiple ranges can be specified in this way, separated by comma (,). All resulting numbers are then sorted, each number occurs only once')
    self.op.add_option('-s', '--symbol', dest='symbol', default='x', help='set symbol')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    assert len(self.args) == 0, 'no positional arguments expected'
    assert self.opts.kind in [1, 2], 'Bad kind: Only first or second kind of Chebyshev polynomials exist. Enter either 1 or 2.'
    self.opts.order = opt2ranges(self.opts.order)
    if len(self.opts.order) == 0:
      return None
    assert len(self.opts.symbol) > 0, 'symbol may not be empty string'

    # Calculate
    x = np.poly1d([1L, 0L])
    if self.opts.kind == 1:
      T = []
      T.append(np.poly1d([1.]))   # T[0]
      T.append(x)                 # T[1]
      for m in xrange(1, self.opts.order[-1]):
        T.append(2*x*T[m]-T[m-1]) # T[m+1]

      # Change symbol
      for m in xrange(len(T)):
        T[m].__dict__['variable'] = self.opts.symbol

      # Return polynomials
      if self.funcmode:
        if len(self.opts.order) > 1:
          return tuple([T[m] for m in self.opts.order])
        elif len(self.opts.order) > 0:
          return T[self.opts.order[0]]
        else:
          return None
      else:
        for m in self.opts.order:
          print T[m]
    elif self.opts.kind == 2:
      U = []
      U.append(np.poly1d([1L]))   # U[0]
      U.append(2*x)               # U[1]
      for m in xrange(1, self.opts.order[-1]):
        U.append(2*x*U[m]-U[m-1]) # U[m+1]

      # Change symbol
      for m in xrange(len(U)):
        U[m].__dict__['variable'] = self.opts.symbol

      # Return polynomials
      if self.funcmode:
        if len(self.opts.order) > 1:
          return tuple([U[m] for m in self.opts.order])
        elif len(self.opts.order) > 0:
          return U[self.opts.order[0]]
        else:
          return None
      else:
        for m in self.opts.order:
          print U[m]



class _Hund(BaseProc):
  """Apply Hund's rules to determine the term symbol of the ground state of a
  given electronic configuration of an atom or ion."""
  # 03/02/2011
  version = '09/02/2011'
  argtype = str
  epilog = """Future ideas:
  * Could also return the name/symbol and the charge of the element/ion.
  * Could return not only the ground state term symbol, but also all excited
    states (quite more efford...)

  Known issues: For at least one element, namely Gadolinium (Gd, Z=64), the ground
  state term symbol is not determined correctly. It should be 9D2o, but this
  script yields 9D5o (electron configuration: [Xe] 4f7 5d 6s2)."""

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    # --> Only return total angular momentum J
    # --> Only return spin angular momentum S
    # --> Only return orbital angular momentum L
    self.op.add_option('-S', dest='S', default=False, action='store_true', help='return spin angular momentum')
    self.op.add_option('-L', dest='L', default=False, action='store_true', help='return orbital angular momentum')
    self.op.add_option('-J', dest='J', default=False, action='store_true', help='return total angular momentum')
    self.op.add_option('-P', dest='P', default=False, action='store_true', help='return parity')
    self.op.add_option('-t', dest='t', default=False, action='store_true', help='return term symbol (string)')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options

    # Load data
    self.load()

    # Process input data
    orbletters = 'spdfghiklmnoqrtuv' # Letter representation of the orbital quantum number l
    confs = ' '.join(self.din).split(' ')
    self.dout.conf = ' '.join(confs)
    #configs = []
    self.dout.J, self.dout.L, self.dout.S, self.dout.P = 0., 0, 0., 1
    for conf in confs:
      conflist = sepnumstr(conf)
      assert len(conflist) > 1 and len(conflist) < 4, 'bad electron configuration: %s' % conf
      assert not isinstance(conflist[0], str), 'bad electron configuration: %s' % conf
      assert isinstance(conflist[1], str), 'bad electron configuration: %s' % conf
      assert len(conflist[1]) == 1, 'bad electron configuration: %s' % conf
      if len(conflist) < 3:
        conflist.append(1)
      n, letter, enum = conflist
      l = orbletters.index(letter)
      assert l < n, 'bad electron configuration: %s. orbital angular momentum l must be smaller than principal quantum number n' % conf
      assert enum >= 0, 'number of electrons must be positive integer or zero in term symbol %s' % conf
      fullnum = 2*(2*l+1) # Number of electrons the orbital can hold
      assert enum <= fullnum, 'bad electron configuration: %s. too many electrons for orbital %i%s' % (conf, n, letter)

      # Fill orbitals according to Hund's rules
      states = np.array([1]*enum+[0]*(fullnum-enum), dtype=bool).reshape((2, 2*l+1)).T[::-1]
      mlmat = np.array([np.arange(-l, l+1), np.arange(-l, l+1)]).T

      # Calculate spin, orbital und total angular momentums of this shell
      S = (np.sum(states[:, 0])-np.sum(states[:, 1]))/2.
      L = int(np.sum(states*mlmat))
      if enum < fullnum/2:
        J = abs(L-S)
      else:
        J = L+S
      P = (-1)**(np.sum(states)*l)

      # Add values of this orbital to the total values
      self.dout.S += S
      self.dout.L += L
      self.dout.J += J
      self.dout.P *= P

    # Make string representations
    self.dout.Lchar = orbletters[self.dout.L].upper()
    if self.dout.S == int(self.dout.S):
      self.dout.Sstr = str(int(self.dout.S))
    else:
      self.dout.Sstr = str(int(2*self.dout.S))+'/2'
    if self.dout.L == int(self.dout.L):
      self.dout.Lstr = str(int(self.dout.L))
    else:
      self.dout.Lstr = str(int(2*self.dout.L))+'/2'
    if self.dout.J == int(self.dout.J):
      self.dout.Jstr = str(int(self.dout.J))
    else:
      self.dout.Jstr = str(int(2*self.dout.J))+'/2'
    if self.dout.P == 1:
      # even parity
      self.dout.Pstr = ''
    else:
      # odd parity
      self.dout.Pstr = 'o'
    self.dout.S2 = 2*self.dout.S+1
    if self.dout.S2 == int(self.dout.S2):
      self.dout.S2str = str(int(self.dout.S2))
    else:
      self.dout.S2str = str(int(2*self.dout.S2))+'/2'
    self.dout.termsymbol = self.dout.S2str+' '*len(self.dout.Lchar)+self.dout.Pstr+'\n'
    self.dout.termsymbol += ' '*len(self.dout.S2str)+self.dout.Lchar+'\n'
    self.dout.termsymbol += ' '*(len(self.dout.S2str)+len(self.dout.Lchar))+self.dout.Jstr

    # Return results
    if self.funcmode:
      if self.opts.S:
        return self.save('S')
      elif self.opts.L:
        return self.save('L')
      elif self.opts.J:
        return self.save('J')
      elif self.opts.P:
        return self.save('P')
      elif self.opts.t:
        return self.save('termsymbol')
      else:
        return self.save(struct=True)

    else:
      returning = []
      if self.opts.S:
        returning.append('Sstr')
      if self.opts.L:
        returning.append('Lstr')
      if self.opts.J:
        returning.append('Jstr')
      if self.opts.P:
        returning.append('Pstr')
      if self.opts.t:
        returning.append('termsymbol')
      if len(returning) == 0:
        returning.append('termsymbol')
      return self.save(*returning)



class _Anderson(ModelProc):
  """Define 1-band simple-cubic tight binding system with site-diagonal
  disorder and constant isotropic next-neighbor hopping, using a continuous
  probability distribution."""
  # 29/03/2011
  # former anderson.py from 21/01/2010-03/09/2010
  version = '06/04/2011'
  usage = '%prog [options] filename'

  def __init__(self):
    ModelProc.__init__(self)

    # Set options
    self.op.add_option('-c', '--scale', dest='scale', type=float, default=1., help='set scale of the continuous probability distribution, e.g. the width of a uniform distribution')
    self.op.add_option('-d', '--dist', dest='dist', type=str, default='uniform', help='set disorder distribution. One of "uniform", "cauchy" or "normal"')
    self.op.add_option('-l', '--loc', dest='loc', type=float, default=0., help='set location of the probability distribution, i.e. the energy around which the disordered potentials scatter')

  def __call__(self, *args, **kwargs):
    ModelProc.__call__(self, *args, **kwargs)

    # Check options
    assert self.opts.scale >= 0., 'scale parameter must be non-negative float'
    if self.shellmode:
      assert len(self.args) == 1, 'exactly one positional command line argument expected, containing the filename to save the desired realization(s) of the disordered system'

    # Choose probability distribution
    if 'uniform'.startswith(self.opts.dist.lower()) or 'box'.startswith(self.opts.dist.lower()):
      distribution = lambda: st.uniform.rvs(size=self.size, scale=self.opts.scale, loc=self.opts.loc-self.opts.scale/2)
      self.opts.dist = 'uniform'
    elif 'cauchy'.startswith(self.opts.dist.lower()) or 'lorentzian'.startswith(self.opts.dist.lower()):
      distribution = lambda: st.cauchy.rvs(size=self.size, scale=self.opts.scale/2, loc=self.opts.loc)
      self.opts.dist = 'cauchy'
    elif 'normal'.startswith(self.opts.dist.lower()) or 'gaussian'.startswith(self.opts.dist.lower()):
      distribution = lambda: st.norm.rvs(size=self.size, scale=self.opts.scale/np.sqrt(12), loc=self.opts.loc)
      self.opts.dist = 'normal'
    else:
      raise ValueError, 'unknown distribution: %s' % self.opts.dist

    # Cycle through realizations
    if self.funcmode:
      supercells = []
    # Define crystal
    nreals = len(self.opts.reals)
    p = Progress(nreals, text='create %i realizations' % nreals, verbose=(nreals > 1 and self.opts.verbose))
    for rind, r in enumerate(self.opts.reals):
      # Define crystal
      sc = SuperCell(self.dim)
      lat = sc.add_scnn(pot=distribution(), hop=self.opts.hop, shape=self.opts.shape, bcond=self.opts.bcond)

      # Get filename, replace hash signs (#) by realization index
      if self.shellmode:
        filename = self.args[0]
        string = ''
        for j in xrange(len(str(r)), filename.count('#')):
          string += '0'
        string += str(r)
        while filename.count('#') > 0:
          left = filename.index('#')
          right = left+1
          filename = filename[:left]+string[0]+filename[right:]
          string = string[1:]

        # Append extension
        extension = '.h5'
        if not filename.endswith(extension):
          filename += extension

        # Store link to the first realization. Only the first realization gets no hlink.
        if rind == 0:
          filename0 = filename
        else:
          sc.hlink = filename0

      if self.shellmode:
        self.saveparam(struct(supercell=sc, dist=self.opts.dist, scale=self.opts.scale, loc=self.opts.loc, shape=self.opts.shape), filename=filename)
      else:
        supercells.append(sc)

      p.step()

    if self.funcmode:
      if len(supercells) == 1:
        return supercells[0]
      else:
        return tuple(supercells)




class _Alloy(ModelProc):
  """Define multi-component alloy (compositional disorder).
  Use 1-band tight binding model, simple cubic, next-neighbours."""
  # 04/04/2011
  # former tb._Alloy from 09/01/2011-14/02/2011
  # former alloy.py from 01/02/2010-14/06/2010
  version = '06/04/2011'
  usage = '%prog [options] filename'

  def __init__(self):
    ModelProc.__init__(self)

    # Set options
    self.op.add_option('-x', '--mixing-ratio', dest='mix', default='', help='set mixing ratio of B material in A material. If the alloy has more than 2 components, multiple comma-separated values may be specified')

  def __call__(self, *args, **kwargs):
    ModelProc.__call__(self, *args, **kwargs)

    # Check options
    if self.shellmode:
      assert len(self.args) == 1, 'exactly one positional command line argument expected, containing the filename to save the desired realization(s) of the disordered system'
    if self.opts.mix == '':
      self.opts.mix = ()
    else:
      self.opts.mix = tuple(opt2list(self.opts.mix, dtype=float))
    assert len(self.opts.mix) == len(self.opts.pot)-1, 'Wrong number of mixing ratios: %i. As %i potential energies were defined, the number of mixing ratios has to be %i.' % (len(self.opts.mix), len(self.opts.pot), len(self.opts.pot)-1)
    assert sum(self.opts.mix) <= 1., 'Bad mixing ratios: %s. The sum of all mixing ratios may not exceed 1.' % self.opts.mix
    for x in self.opts.mix:
      assert x >= 0. and x <= 1., 'Bad mixing ratio: %f. Each mixing ratio must be between 0.0 and 1.0.' % x

    # Make probability distribution
    def distribution():
      mix = (1.-sum(self.opts.mix),)+self.opts.mix
      ind = range(len(self.opts.pot))
      inds = st.rv_discrete(values=(ind, mix)).rvs(size=self.size)
      return self.opts.pot[inds]

    # Cycle through realizations
    if self.funcmode:
      supercells = []
    # Define crystal
    nreals = len(self.opts.reals)
    p = Progress(nreals, text='create %i realizations' % nreals, verbose=(nreals > 1 and self.opts.verbose))
    for rind, r in enumerate(self.opts.reals):
      # Define crystal
      sc = SuperCell(self.dim)
      lat = sc.add_scnn(pot=distribution(), hop=self.opts.hop, shape=self.opts.shape, bcond=self.opts.bcond)

      # Get filename, replace hash signs (#) by realization index
      if self.shellmode:
        filename = self.args[0]
        string = ''
        for j in xrange(len(str(r)), filename.count('#')):
          string += '0'
        string += str(r)
        while filename.count('#') > 0:
          left = filename.index('#')
          right = left+1
          filename = filename[:left]+string[0]+filename[right:]
          string = string[1:]

        # Append extension
        extension = '.h5'
        if not filename.endswith(extension):
          filename += extension

        # Store link to the first realization. Only the first realization gets no hlink.
        if rind == 0:
          filename0 = filename
        else:
          sc.hlink = filename0

      if self.shellmode:
        self.saveparam(struct(supercell=sc, pot=self.opts.pot, mix=list(self.opts.mix), shape=self.opts.shape), filename=filename)
      else:
        supercells.append(sc)

      p.step()

    if self.funcmode:
      if len(supercells) == 1:
        return supercells[0]
      else:
        return tuple(supercells)



class _AlloyBackup(ModelProcBackup):
  """Define multi-component alloy (compositional disorder).
  Use 1-band tight binding model, simple cubic, next-neighbours."""
  # 09/01/2011
  # former alloy.py from 01/02/2010-14/06/2010
  version = '14/02/2011'

  def __init__(self):
    ModelProcBackup.__init__(self)

    # Set options
    self.op.add_option('-x', '--mixing-ratio', dest='mix', default='', help='set mixing ratio of B material in A material. If the alloy has more than 2 components, multiple comma-separated values may be specified')

  def __call__(self, *args, **kwargs):
    ModelProcBackup.__call__(self, *args, **kwargs)

    # Check options
    if self.opts.mix == '':
      self.opts.mix = []
    else:
      self.opts.mix = opt2list(self.opts.mix, dtype=float)
    assert len(self.opts.mix) == len(self.opts.pot)-1, 'Wrong number of mixing ratios: %i. As %i potential energies were defined, the number of mixing ratios has to be %i.' % (len(self.opts.mix), len(self.opts.pot), len(self.opts.pot)-1)
    assert sum(self.opts.mix) <= 1., 'Bad mixing ratios: %s. The sum of all mixing ratios may not exceed 1.' % self.opts.mix
    for x in self.opts.mix:
      assert x >= 0. and x <= 1., 'Bad mixing ratio: %f. Each mixing ratio must be between 0.0 and 1.0.' % x

    # Define grid
    grid = np.ones(self.opts.dims, dtype=np.ubyte)

    # Generate coordinate list out of the grid
    clist = np.zeros((self.size, self.dim))
    for index, ndindex in it.izip(xrange(self.size), np.ndindex(grid.shape)):
      clist[index] = ndindex
    ne = len(clist) # Total number of entities/states/orbitals

    # Generate orbital-species list
    olist = np.zeros((self.size), dtype=np.ubyte) # Only one orbital species in this model

    # Generate multiple configurations of the system with multiple combinations of boundary conditions
    params = []
    for i in xrange(self.opts.confs): #self.opts.offset,
      # Generate random atom species list
      alist = np.zeros((self.size), dtype=np.ubyte)
      sample = np.random.random_sample((self.size))
      for j in xrange(len(self.opts.mix)):
        if j == 0:
          alist[sample < self.opts.mix[j]] = j+1
        else:
          lowersum = sum(self.opts.mix[:j])
          uppersum = sum(self.opts.mix[:(j+1)])
          alist[np.logical_and(sample > lowersum, sample < uppersum)] = j+1

      # Cycle through the boundary condition combinations
      for j in xrange(len(self.bconds)):
        bcond = self.bconds[j]

        # Substitute hash signs (#) with number of this configuration
        if self.shellmode:
          filename = self.args[j]
          string = ''
          for j in xrange(len(str(i)), filename.count('#')):
            string += '0'
          string += str(i)
          while filename.count('#') > 0:
            left = filename.index('#')
            right = left+1
            filename = filename[:left]+string[0]+filename[right:]
            string = string[1:]

        # Generate parameter table (now stored as a structure)
        # Format:
        #   0: dcon: Distance condition
        #   1: acon: Atom species condition
        #   2: ocon: Orbital condition
        #   3: value: Desired parameter value
        ptable = []
        ptable.append(struct(dcon=1., acon=None, ocon=None, value=-self.opts.hop)) # Next neighbour hopping
        for k in xrange(len(self.opts.pot)):
          ptable.append(struct(dcon=0., acon=com(k), ocon=None, value=self.opts.pot[k])) # Site potentials

        # Build parameter set
        param = struct(dim   =self.dim,
                       size  =self.size,
                       dims  =self.opts.dims,
                       mix   =self.opts.mix,
                       bcond =bcond,
                       ptable=ptable,
                       hop   =self.opts.hop,
                       pot   =self.opts.pot,
                       clist =clist,
                       alist =alist,
                       olist =olist,
                       ne    =ne,
                       brav  ='sc',
                       neigh ='NN')

        # Save configuration to npz-file
        if self.shellmode:
          self.saveparam(param, filename=filename)
        else:
          params.append(param)

    if self.funcmode:
      if len(params) == 1:
        return params[0]
      else:
        return tuple(params)



class _Supercell(BaseProc):
  """Display information about the supercell defined in the parameter set of
  the given file."""
  # 04/04/2011
  version = '10/04/2011'
  usage = '%prog [options] filename'
  argtype = None
  nif = 1
  niof = 0
  nof = 0

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-l', '--lat', dest='lat', default=-1, type=int, help='display information about a specific lattice with the specified index')
    self.op.add_option('-s', '--site', dest='site', default=-1, type=int, help='display information about a specific site with the specified index')
    self.op.add_option('-e', '--ent', dest='ent', default=-1, type=int, help='display information about a specific entity with the specified index')
    self.op.add_option('-n', '--neigh', dest='neigh', default=-1, type=int, help='display information about a specific neighbor with the specified index')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    assert len(self.args) < 2, 'only one filename may be given'

    if len(self.args) == 0:
      return

    # Load parameter set
    self.load(shellmode=True)
    for param in self.pin:
      sc = param.supercell

      if self.opts.lat > -1:
        lat = sc._lats[self.opts.lat]
        if self.opts.site > -1:
          site = lat._sites[self.opts.site]
          if self.opts.ent > -1:
            ent = site._ents[self.opts.ent]
            if self.funcmode:
              return ent
            else:
              # Display information about the entity
              edict = ent.__dict__.copy()
              eqlist(**edict)
          else:
            if self.funcmode:
              return site
            else:
              # Display information about the site
              sdict = site.__dict__.copy()
              eqlist(**sdict)
        elif self.opts.neigh > -1:
          neigh = lat._neighs[self.opts.site]
          if self.funcmode:
            return neigh
          else:
            # Display information about the neighbor
            ndict = neigh.__dict__.copy()
            eqlist(**ndict)
        else:
          if self.funcmode:
            return lat
          else:
            # Display information about the lattice
            ldict = lat.__dict__.copy()
            eqlist(**ldict)
      elif self.opts.site > -1:
        site = sc._sites[self.opts.site]
        if self.funcmode:
          return site
        else:
          # Display information about the site
          sdict = site.__dict__.copy()
          eqlist(**sdict)
      else:
        if self.funcmode:
          # Just return the supercell of the file
          return sc
        else:
          # Display information about the supercell
          scdict = sc.__dict__.copy()
          eqlist(**scdict)






class _Param(BaseProc):
  """Display parameter set of the specified HDF5 file. If multiple HDF5 files are
  specified, return only those parameters that are common to all parameter sets."""
  # 07/02/2011
  version = '10/04/2011'
  usage = '%prog [options] filenames'
  argtype = None # Positional arguments represent filenames of data files
  nif = None
  niof = 0
  nof = 0

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-m', '--maxshape', dest='maxshape', default=15, type=int, help='set the maximum shape of arrays that will still be printed. For bigger arrays, with at least on dimension greater than this value, only the shape of the array will be indicated')
    self.op.add_option('-n', '--name', dest='name', default='', help='set name of a specific parameter to return. Multiple names may be specified, separated by a comma')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    assert self.opts.maxshape >= 0, 'bad maxshape value: %i. Must be positive integer or zero' % self.opts.maxshape
    names = opt2list(self.opts.name, dtype=str)

    # Load parameter sets from files, even in function mode
    self.load(shellmode=True)

    # Check name option
    for name in names:
      if not name in self.pout:
        raise NameError, 'no parameter named %s in parameter set' % name

    # Default: Show all parameters
    if len(names) == 0:
      names = self.pout.keys()

    # Select parameters
    for p in self.pout.keys():
      if not p in names:
        del(self.pout[p])

    # Display or return parameter sets
    if self.shellmode:
      eqlist(maxshape=self.opts.maxshape, **self.pout)
    else:
      if len(names) < 2 and self.opts.name:
        return self.pout[names[0]]
      else:
        return self.pout



class _Comment(BaseProc):
  """Display comments of a HDF5 data file."""
  # 12/02/2011
  version = '10/04/2011'
  usage = '%prog [options] filename'
  argtype = None
  nif = 1
  niof = 0
  nof = 0

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-n', '--name', dest='name', default='', help='set name of a specific comment of the file. Multiple names may be given, separated by a comma')
    self.op.add_option('-f', '--filter', dest='filt', default='', help='filter out only specific information from comments. Multiple strings may be given, separated by a comma')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    assert len(self.args) == 1, 'bad number of positional arguments: Exactly one filename expected'
    names = opt2list(self.opts.name, dtype=str)
    filt = opt2list(self.opts.filt, dtype=str)

    # Load comments from file, even in function mode
    self.load(shellmode=True)

    for comments in self.cin:
      # Check name option
      for name in names:
        if not name in comments:
          raise NameError, 'no comment named %s in file %s' % (name, self.args[0])

      # Default: Show all comments
      if len(names) == 0:
        names = comments.keys()

      # Select comments
      for c in comments.keys():
        if not c in names:
          del(comments[c])

      # Apply filter to each comment
      for c in comments.keys():
        # Default: Filter out nothing
        if len(filt) == 0:
          continue

        # Filter out fields
        for s in comments[c].keys():
          if not s in filt:
            del(comments[c][s])

      # Delete empty comments?

      # Display or return comments
      if self.shellmode:
        if len(names) < 2 and self.opts.name:
          eqlist(**comments[names[0]])
        else:
          eqlist(**comments)
      else:
        if len(names) < 2 and self.opts.name:
          return comments[names[0]]
        else:
          return comments



class _Store(BaseProc):
  """Store a certain value to HDF5 files."""
  # 06/06/2011
  version = '06/06/2011'
  usage = '%prog [options] filename'
  nif = 0
  niof = 0
  nof = None

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-n', '--name', dest='name', type=str, default='value', help='set name of the value to store in the file.')
    self.op.add_option('-a', '--value', dest='value', type=str, default='\'None\'', help='set value to store in the file. Note that it will be interpreted using eval.') #Note that it will be interpreted as string as long as no type has been defined using the type option.
    self.op.add_option('-g', '--group', dest='group', type=str, default='param', help='set name of the desired HDF5 group to store the value in')
    self.op.add_option('-m', '--mode', dest='mode', type=str, default='a', help='set mode to open the HDF5 file')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    assert self.opts.mode in ['r', 'r+', 'w', 'w-', 'a'], 'bad file opening mode. Must be one of r, r+, w, w- or a.'

    # Load accessible filenames
    self.load(shellmode=True)

    # Cycle through existing files
    for filename in self.fout:
      # Open HDF5 file
      f = hdf.File(filename, self.opts.mode)


      if self.opts.group == '':
        savehdf(f, **{self.opts.name: eval(self.opts.value)})
      else:
        g = f.require_group(self.opts.group)
        savehdf(g, **{self.opts.name: eval(self.opts.value)})

      # Save comment
      g = f.require_group('comment')
      if self.prog in g:
        del(g[self.prog]) # Overwrite existing comment
      savehdf(g, **{self.prog: self.comment(**self.cout)})

      # Close HDF5 file
      f.close()





class _Data(BaseProc):
  """Display or return data from a HDF5 data file."""
  # 12/02/2011
  version = '10/04/2011'
  usage = '%prog [options] filename'
  argtype = None
  nif = 1
  niof = 0
  nof = 0
  epilog = """Future visions:
  - Slice option, to view only a certain slice of a bigger array"""

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-m', '--maxshape', dest='maxshape', default=15, type=int, help='set the maximum shape of arrays that will still be printed. For bigger arrays, with at least on dimension greater than this option value, only the shape will be indicated')
    self.op.add_option('-n', '--name', dest='name', default='', help='set name of a specific data field from the file. Multiple field names may be given, separated by a comma')
    self.op.add_option('-d', '--dense', dest='dense', default=False, action='store_true', help='display sparse matrices as dense matrices')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    assert len(self.args) == 1, 'bad number of positional arguments: Exactly one filename expected'
    names = opt2list(self.opts.name, dtype=str)

    # Load all data from file, even in function mode
    self.load('all', shellmode=True)
    for data in self.din:
      # Check name option
      for name in names:
        if not name in data:
          raise NameError, 'no data field named %s in file %s' % (name, self.args[0])

      # Default: Show all data
      if len(names) == 0:
        names = data.keys()

      # Select data
      for d in data.keys():
        if not d in names:
          del(data[d])

      # Display or return data
      if self.shellmode:
        eqlist(maxshape=self.opts.maxshape, dense=self.opts.dense, **data)
      else:
        if len(names) < 2 and self.opts.name:
          return data[names[0]]
        else:
          return data



class _Hamilt(CalcProc):
  """Create hamiltonian matrix, as specified by the supercell data structure
  located in the param group of the given HDF5 file.

  Does nothing else than requesting the matrix from each file, resulting in the
  automatic creation of the matrix if it was not already created earlier. If
  the attribute "hlink" does exist within the supercell data structure, the
  supercell is loaded from the linked file and the hamiltonian matrix of that
  file is requested."""
  # 03/04/2011
  # former tb._Hamilt from 10/02/2011-25/02/2011
  # former mh.py from 02/10/2009-10/08/2010
  version = '10/04/2011'
  usage = '%prog [options] filenames'
  argtype = None
  nif = 0
  niof = None
  nof = 0

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-r', '--recalc', dest='recalc', default=False, action='store_true', help='recalculate the hamiltonian matrix, even if it is already present')
    self.op.add_option('-s', '--single', dest='single', default=False, action='store_true', help='special verbose mode where the progress of every single file is shown')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    pgroup = 'param'
    cgroup = 'comment'
    scdset = 'supercell'

    # Load parameter sets
    self.load()
    if self.shellmode:
      params = self.pinout
    else:
      params = self.din

    # Check options
    if self.opts.single:
      self.opts.verbose = False
    elif self.opts.verbose and len(self.pin) == 1:
      self.opts.verbose = False
      self.opts.single = True

    p = Progress(len(params), text='create hamiltonian matrices', verbose=self.opts.verbose)
    for ind, param in enumerate(params):
      assert 'supercell' in param, 'no supercell definition found in parameter set %i' % (ind+1)
      sc = param.supercell
      if self.shellmode:
        filename = self.finout[ind]
      relpath = os.path.split(filename)[0]
      if self.opts.single:
        if self.shellmode:
          print '--> file %s:' % filename
        else:
          print '--> file %i:' % (ind+1)

      if self.shellmode and 'hlink' in sc.__dict__:
        linkfile = os.path.join(relpath, sc.hlink)
        if self.opts.single:
          print 'follow link to file "%s"' % linkfile
        # Load supercell from the file specified in hlink and require nhamilt from it
        if os.path.isfile(linkfile):
          f = hdf.File(linkfile, 'r+')
          if pgroup in f:
            if scdset in f[pgroup]:
              lsc = loadhdf(f[pgroup], scdset)
              if not '_hamilt' in lsc.__dict__:
                if self.opts.single:
                  print 'file %s:' % linkfile
                lsc.hamilt(verbose=self.opts.single)
                savehdf(f[pgroup], key=scdset, data=lsc)

                # Save comment
                g = f.require_group(cgroup)
                if self.prog in g:
                  del(g[self.prog]) # Overwrite existing comment
                savehdf(g, **{self.prog: self.comment(**self.cout)})

                if self.opts.single:
                  print 'hamiltonian matrix created and saved.'
              else:
                if self.opts.single:
                  print 'hamiltonian matrix already present.'
            else:
              raise NameError, 'HDF5 file %s does not contain a dataset named %s in the group %s', (linkfile, scdset, pgroup)
          else:
            raise NameError, 'no group named %s found in HDF5 file %s' % (pgroup, linkfile)
          f.close()

        # Save comment to this file as well
        f = hdf.File(filename, 'a')
        g = f.require_group(cgroup)
        if self.prog in g:
          del(g[self.prog]) # Overwrite existing comment
        savehdf(g, **{self.prog: self.comment(**self.cout)})
      else:
        # Require hamiltonian from supercell object
        if not '_hamilt' in sc.__dict__ or self.opts.recalc:
          # Create hamiltonian matrix
          sc.hamilt(verbose=self.opts.single, recalc=self.opts.recalc)

          # Open file
          f = hdf.File(filename, 'a')
          savehdf(f[pgroup], key=scdset, data=sc)

          # Save comment
          g = f.require_group(cgroup)
          if self.prog in g:
            del(g[self.prog]) # Overwrite existing comment
          savehdf(g, **{self.prog: self.comment(**self.cout)})

          # Close file
          f.close()

          if self.opts.single:
            print 'hamiltonian matrix created and saved.'
        else:
          if self.opts.single:
            print 'hamiltonian matrix already present.'
      p.step()

    # Save comment
    self.save()



class _HamiltBackup(CalcProc):
  """Create hamiltonian matrix, as specified by the parameter set of the system.
  Save the matrix in a sparse format into the same file the parameter set was loaded
  from."""
  # 10/02/2011
  # former mh.py from 02/10/2009-10/08/2010
  version = '25/02/2011'
  usage = '%prog [options] filenames'
  argtype = None
  nof = 1
  epilog = """Possible future features:
  - Support anisotropic hopping. Not only distance, but also direction needed.
  ptable would have to be extended by a vector information.
  - Extra distance matrices for periodic boundary conditions do not have to be
  as large as the main distance matrix. Required size depends on neighbor
  correlation of maximum distance. Would improve performance considerably.
  - Specify multiple filenames
  """

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-d', '--decimals', dest='decimals', type=int, default=1, help='number of decimals used to specify the correlation distances. The corresponding distances between two lattice sites will be rounded to this number of decimals and then checked for equality')
    self.op.add_option('-b', '--blockwidth', dest='mbw', type=int, default=1000, help='set maximum block width')
    self.op.add_option('-f', '--format', dest='format', type=str, default='csc', help='set output format')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    # Check options
    assert self.opts.decimals >= 0, 'bad number of decimals: %i. Has to be positive integer or zero' % self.opts.decimals
    assert self.opts.mbw > 0, 'bad maximum block width: %i. Must be positive integer' % self.opts.mbw
    assert len(self.args) == 1, 'bad number of positional arguments: Exactly one argument expected (containing filename or parameter set)'

    # Load parameter set
    self.load()
    if self.shellmode:
      param = self.pin[0]
    else:
      param = self.din[0]

    # Fast mode for special cases
    if 'brav' in param and 'neigh' in param:
      if param.brav == 'sc' and param.neigh == 'NN':
        # Activate fast mode
        # Build potential array
        if isiterable(param.pot):
          pot = np.array(pot)
          assert len(pot.shape) == 1
          asorts = set(param.alist)
          assert len(pot) == len(asorts)

          #for p in pot:

          plist = np.ones((param.size))*pot
          #plist[
        else:
          plist = np.ones((param.size))*pot

    #else:

    # Declare Hamiltonian matrix
    self.dout.hamilt = spa.lil_matrix((param.ne, param.ne))

    # Divide the matrix into small blocks and calculate the matrix elements
    # blockwise
    nb = (param.ne-1)/self.opts.mbw+1 # Number of blocks in each direction (x and y). Total number of blocks is nb**2
    obw = (param.ne-1)/nb+1 # Optimized block width, so that each block is roughly the same size
    p = Progress(nb**2, verbose=self.opts.verbose)
    for i, j in np.ndindex((nb, nb)):
      # Select slice
      i1 = i*obw
      i2 = min((i+1)*obw, param.ne)
      j1 = j*obw
      j2 = min((j+1)*obw, param.ne)

      # Choose data
      clist1 = param.clist[i1:i2]
      clist2 = param.clist[j1:j2]
      alist1 = param.alist[i1:i2]
      alist2 = param.alist[j1:j2]
      olist1 = param.olist[i1:i2]
      olist2 = param.olist[j1:j2]

      # Set slice of the Hamiltonian matrix
      self.dout.hamilt[i1:i2, j1:j2] = self.setblock(clist1, clist2, alist1, alist2, olist1, olist2, param.ptable, param.bcond, param.dims, self.opts.decimals)

      # Display progress
      if self.opts.verbose:
        p.step()

    # Convert matrix to CSC format
    self.dout.hamilt = getattr(self.dout.hamilt, 'to'+self.opts.format)()

    # Add user-defined comments
    self.cout.mbw = self.opts.mbw # Maximum block width
    self.cout.obw = obw           # Optimized block width
    self.cout.nb = nb             # Number of blocks in one dimension (total number of blocks: nb**2)

    # Save or return matrix
    return self.save('hamilt')

  def setblock(self, clist1, clist2, alist1, alist2, olist1, olist2, ptable, bcond, dims, decimals=1):
    """Set matrix with values and by conditions given in ptable, based on data
    in clist1/2, alist1/2 and olist1/2, respecting boundary conditions given by
    bcond.

    clist1 is an array with shape n x d, clist2 with shape m x d, where d is the
    dimensionality of the underlying lattice. alist1 and olist1 are 1d-arrays of
    length n, alist2 and olist2 of length m. Then, the returned matrix will have
    the shape n x m.

    How it works: The combination value of every element of alist1 and alist2 or
    olist1 and olist2 must match the value given in ptable[i].acon or
    ptable[i].ocon, and the Euclidian distance between every d-dimensional
    coordinate of clist1 and clist2 must equal ptable[i].dcon (with precision
    set by decimals). Only on these conditions, the respective matrix element is
    set to ptable[i].value.

    Different boundary conditions may be given for each dimension, specified
    through the d-tuple bcond. Periodic boundary conditions are respected, as
    long as ptable[i].dcon is not larger than the underlying lattice itself
    (dimensions of lattice is given by dims). Antiperiodic boundary conditions
    will correctly affect a change of the sign of the respective matrix element."""
    # 12/02/2011-24/02/2011

    assert len(clist1) == len(alist1) == len(olist1) , 'all first lists have to be of equal length'
    assert len(clist2) == len(alist2) == len(olist2) , 'all second lists have to be of equal length'
    assert len(clist1.shape) == len(clist2.shape) == 2, 'clist1/2 have to be 2d-arrays with shape n x d'
    assert len(alist1.shape) == len(alist2.shape) == len(olist1.shape) == len(olist2.shape) == 1, 'alist1/2 and olist1/2 must be 1d-arrays of length n'
    assert clist1.shape[1] == clist2.shape[1] == len(bcond), 'dimensionality of coordinates in clist1/2 and number of boundary conditions must be equal and conform to dimensionality d of the lattice'
    assert typename(decimals) == 'int' and decimals >= 0, 'decimals must be positive integer or zero, but got %i instead' % decimals

    # Number of coordinates
    m, n = len(clist1), len(clist2)

    # Initialize the sign matrix that will only change if antiperiodic boundary
    # conditions are defined in at least one dimension
    sign = np.ones((m, n))

    # Determine number of cubes in each dimension
    nc = [] # Will hold number of cubes for each dimension
    for bc in bcond:
      if bc in 'pa':
        nc.append(3)
      else:
        nc.append(1)
    nc = tuple(nc)

    # Determine relative positions of cubes
    cubepos = [] # Containing tuples with length of dimensionality of system, with the relative positions of the cubes
    for ndind in np.ndindex(nc):
      # What we want in (anti)periodic dimensions is (-1, 0, 1), in static (0)
      ndind = list(ndind)
      for dim in xrange(len(ndind)):
        if nc[dim] == 3:
          ndind[dim] -= 1
      cubepos.append(ndind)

    # Find the right sign for each cube
    csign = np.ones(nc)
    for dind, bc in enumerate(bcond):
      if bc == 'a':
        for ndind in np.ndindex(nc[:dind]):
          mind = ndind+(1,) # Middle index
          for l in [0, 2]:
            bind = ndind+(l,) # Border index
            csign[bind] = -csign[mind]

    # Store cube information in a comprehensive way
    cubes = []
    for ind, cp in enumerate(cubepos):
      cubes.append(struct(pos=cp, sign=csign.flat[ind]))

    # Calculate distance matrices
    dmat = dist(clist1, clist2+np.array(dims)*cubes[0].pos, decimals=self.opts.decimals)
    sign[:, :] = cubes[0].sign
    for cube in cubes[1:]:
      dmat2 = dist(clist1, clist2+np.array(dims)*cube.pos, decimals=self.opts.decimals)
      dmat = np.minimum(dmat, dmat2)
      sign[dmat2 <= dmat] = cube.sign

    # Calculate combination matrices
    amat = com(alist1, alist2)
    omat = com(olist1, olist2)

    # Initialize matrix to return
    mat = spa.dok_matrix((m, n))

    # Check all entries in the parameter table
    for p in ptable:
      # If a condition is set to None, the parameter does not depend on this
      # condition, thus the condition will always be satisfied
      if p.dcon == None:
        dcon = True
      else:
        dcon = dmat == p.dcon
      if p.acon == None:
        acon = True
      else:
        acon = amat == p.acon
      if p.ocon == None:
        ocon = True
      else:
        ocon = omat == p.ocon

      # Only set matrix element if all three conditions are satisfied
      con = np.logical_and(dcon, np.logical_and(acon, ocon))
      icon, jcon = con.nonzero() # Get index arrays of matrix elements with value True
      #icon, jcon = tuple(icon), tuple(jcon) # Make tuples out of index arrays
      #dump(si=sign[icon, jcon])
      svalue = [p.value]*sign[icon, jcon]
      condict = dict(zip(zip(icon, jcon), svalue))

      # In the case of diagonal disorder, the parameter is not a single value,
      # but a 1d-array of values. Act accordingly
      if p.dcon == 0. and typename(p.value) in ['ndarray', 'list', 'tuple']:
        for i, j, v in zip(icon, jcon, p.value):
          mat[i, j] = v
      else:
        # Set matrix the normal way, with single parameter p.value
        mat.update(condict)

        # Respect the sign
        #mat = mat.multiply(spa.dok_matrix(sign))

    # Return this matrix block
    return mat



class _Hermit(BaseProc):
  """Test whether Hamiltonian matrix is hermitian. In shell mode, load
  Hamiltonian matrix from the specified file and display result. In funcion
  mode, take Hamiltonian matrix from funcion argument and return the result as
  boolean value. Both dense and sparse matrices are supported."""
  # 13/02/2011
  # replaces former ts.py from 16/10/2009-15/06/2010
  version = '10/04/2011'
  usage = '%prog [options] filename'
  nif = None
  niof = 0
  nof = 0
  #epilog = """Future visions:"""

  def __init__(self):
    BaseProc.__init__(self)

    # Set options

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options

    # Load matrix
    self.load()
    if self.shellmode:
      params = self.pin
    else:
      params = self.din

    # Check all matrices
    nothermit = 0
    p = Progress(len(self.pin), text='Check matrices', verbose=self.opts.verbose)
    for param in params:
      if self.shellmode:
        mat = param.supercell.hamilt()
      else:
        mat = param

      # Compare matrix with its conjugate transpose
      if typename(mat) in ['ndarray', 'matrix']:
        # Dense matrix given
        if not np.all(mat.transpose().conjugate() == mat):
          nothermit += 1
      else:
        # Convert the given sparse matrix to dok-format before comparison
        if not mat.transpose().conjugate().todok() == mat.todok():
          nothermit += 1
      p.step()
    self.dout.hermit = (nothermit == 0)

    # Display or return result
    return self.save('hermit')



class _Eigen(CalcProc):
  """Solve an ordinary eigenvalue problem for a complex Hermitian or real symmetric matrix.
  Use a direct diagonalization algorithm (scipy.linalg.eigh)."""
  # 27/01/2011
  # former scripts e and eev
  version = '10/04/2011'
  epilog = """Future visions:
  - Option to calculate only some of the eigenvalues/eigenvectors, using
  scipy.sparse.linalg.eig/eigh (Lanczos method)"""
  argtype = None
  nif = 0
  niof = None
  nof = 0

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('--vects', dest='vects', default=False, action='store_true', help='Calculate and return eigenvectors as well. Otherwise, only eigenvalues are calculated')
    self.op.add_option('-r', '--recalc', dest='recalc', default=False, action='store_true', help='recalculate and overwrite existing data. Otherwise, files where eigenvalues/eigenvectors already exist, stay untouched')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    # Check options

    dgroup = 'data'
    cgroup = 'comment'

    # Load data
    self.load()
    if self.shellmode:
      params = self.pinout
    else:
      params = self.dinout

    p = Progress(len(self.finout), text='solve eigenvalue problems', verbose=self.opts.verbose)
    for param, filename in it.izip(params, self.finout):
      if self.shellmode:
        mat = param.supercell.hamilt()
      else:
        mat = param

      if not typename(mat) in ['ndarray', 'matrix']:
        mat = mat.todense()

      # Recalculate and overwrite existing data?
      f = hdf.File(filename, 'r+')
      g = f.require_group(dgroup)
      if not self.opts.recalc and ('eigvals' in g and (not self.opts.vects or 'eigvects' in g)):
        f.close()
        p.step()
        continue
      f.close()

      # Solve eigenvalue problem
      if self.opts.vects:
        eigvals, eigvects = la.eigh(mat, overwrite_a=True)
      else:
        eigvals = la.eigh(mat, overwrite_a=True, eigvals_only=True)

      # Open HDF5 file
      f = hdf.File(filename, 'a')

      # Save data
      g = f.require_group(dgroup)
      savehdf(g, eigvals=eigvals)
      if self.opts.vects:
        savehdf(g, eigvects=eigvects)

      # Save comment
      g = f.require_group(cgroup)
      if self.prog in g:
        del(g[self.prog]) # Overwrite existing comment
      savehdf(g, **{self.prog: self.comment(**self.cout)})

      # Close HDF5 file
      f.close()
      p.step()



class _Delete(BaseProc):
  """Delete data from HDF5 files. Only affects datasets and groups in the group "/data"."""
  # 13/02/2011
  version = '10/04/2011'
  usage = '%prog [options] filename'
  argtype = None
  nif = 0
  niof = None
  nof = 0
  epilog = """Future visions:
  - In verbose mode, a message could be given, stating how many data fields have
  been deleted or how much memory has been cleared"""

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-n', '--name', dest='name', default='', help='set dataset to delete. Multiple dataset names may be given, separated by a comma')
    self.op.add_option('-f', '--force', dest='force', default=False, action='store_true', help='silently ignore those files in which a specified dataset does not exist. Do not exit with error message, just continue with next file')
    self.op.add_option('-s', '--single', dest='single', default=False, action='store_true', help='special verbose mode where a message is displayed whenever something is deleted from a file')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Check options
    names = opt2list(self.opts.name, dtype=str)
    if self.opts.single:
      self.opts.verbose = False

    # Load data (at least the filenames)
    self.load()

    maxfilenamelen = max([len(basename(s, '.h5')) for s in self.args])
    p = Progress(len(self.finout), text='delete data', verbose=self.opts.verbose)
    for filename in self.finout:
      # Open HDF5 file
      f = hdf.File(filename)

      # Open data group
      dgroup = 'data'
      if not self.opts.force and not dgroup in f:
        raise NameError, 'no group with name "data" found in HDF5 file %s' % filename
      g = f[dgroup]

      # Check name option
      for name in names:
        if not self.opts.force and not name in g:
          raise NameError, 'no data field named %s in file %s' % (name, filename)

      # Delete data
      for name in names:
        if name in g:
          del(g[name])
          if self.opts.single:
            print expandstr(filename, maxfilenamelen)+' : Deleted '+name

      # Close HDF5 file
      f.close()
      p.step()




class _List(BaseProc):
  """List names of data fields of a HDF5 data file."""
  # 13/02/2011
  version = '10/04/2011'
  usage = '%prog [options] filenames'
  argtype = None
  nif = None
  niof = 0
  nof = 0

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-l', '--long', dest='long', default=False, action='store_true', help='use a long listing format, providing additional information for each dataset')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Load data
    self.load()

    # How many filenames were given?
    if len(self.fin) == 1:
      # Open HDF5 file
      filename = self.fin[0]
      f = hdf.File(filename)

      # Open data group
      dgroup = 'data'
      if not dgroup in f:
        #raise NameError, 'no data fields in HDF5 file %s' % filename
        return False
      g = f[dgroup]

      # Get all field names
      self.dout.name = g.keys()

      # Get additional information
      self.dout.date = []
      self.dout.mem = []
      self.dout.dtype = []
      self.dout.shape = []
      for key in g.keys():
        # Get date when this dataset was created
        if 'DATE' in g[key].attrs:
          self.dout.date.append(g[key].attrs['DATE'])
        else:
          self.dout.date.append('')

        # Get memory size
        if typename(g[key]) == 'Dataset':
          if typename(g[key].value) in ['ndarray', 'matrix']:
            self.dout.mem.append(g[key].value.nbytes)
          else:
            self.dout.mem.append(None)
        elif typename(g[key]) == 'Group':
          if 'TYPE' in g[key].attrs and g[key].attrs['TYPE'] in ['CSR_MATRIX', 'CSC_MATRIX']:
            self.dout.mem.append(g[key]['data'].value.nbytes+g[key]['indices'].value.nbytes+g[key]['indptr'].value.nbytes+g[key]['shape'].value.nbytes)
          else:
            self.dout.mem.append(None)
        else:
          self.dout.mem.append(None)

        # Get data type
        if 'TYPE' in g[key].attrs:
          self.dout.dtype.append(g[key].attrs['TYPE'].lower())
        else:
          if typename(g[key]) == 'Dataset':
            self.dout.dtype.append(typename(g[key].value))
          else:
            self.dout.dtype.append(None)

        # Get shape
        if typename(g[key]) == 'Dataset':
          if 'TYPE' in g[key].attrs and g[key].attrs['TYPE'] in ['LIST', 'TUPLE']:
            self.dout.shape.append((len(g[key].value),))
          elif typename(g[key].value) in ['ndarray', 'matrix']:
            self.dout.shape.append(g[key].value.shape)
          else:
            self.dout.shape.append(None)
        elif typename(g[key]) == 'Group':
          if 'TYPE' in g[key].attrs and g[key].attrs['TYPE'] in ['LIST', 'TUPLE']:
            self.dout.shape.append((len(g[key]),))
          elif 'TYPE' in g[key].attrs and g[key].attrs['TYPE'] in ['CSR_MATRIX', 'CSC_MATRIX']:
            self.dout.shape.append(tuple(g[key]['shape'].value))
          else:
            self.dout.shape.append(None)
        else:
          self.dout.shape.append(None)

      # Display or return list of datasets
      if self.shellmode:
        if self.opts.long:
          if len(self.dout.name) > 0:
            maxnamelen = max([len(s) for s in self.dout.name])
          else:
            maxnamelen = 0
          if len(self.dout.date) > 0:
            maxdatelen = max([len(s) for s in self.dout.date])
          else:
            maxdatelen = 0
          if len(self.dout.mem) > 0:
            maxmemlen = max([len(humanbytes(i)) if i != None else 0 for i in self.dout.mem])
          else:
            maxmemlen = 0
          if len(self.dout.dtype) > 0:
            maxtypelen = max([len(s) for s in self.dout.dtype])
          else:
            maxtypelen = 0
          if len(self.dout.shape) > 0:
            maxshapelen = max([len(str(t)) for t in self.dout.shape])
          else:
            maxshapelen = 0
          for n, d, m, t, s in zip(self.dout.name, self.dout.date, self.dout.mem, self.dout.dtype, self.dout.shape):
            if d == None:
              d = ''
            if m == None:
              m = ''
            else:
              m = humanbytes(m)
            if t == None:
              t = ''
            if s == None:
              s = ''
            print expandstr(n, maxnamelen)+'  '+expandstr(t, maxtypelen)+'  '+expandstr(s, maxshapelen)+'  '+expandstr(m, maxmemlen, flip=True)+'  '+expandstr(d, maxdatelen)
        else:
          if len(self.dout.name) > 0:
            printcols(self.dout.name)
      else:
        if self.opts.long:
          return self.dout
        else:
          return self.dout.name

      # Close HDF5 file
      f.close()
    else:
      # Multiple filenames given
      assert not self.opts.long, 'long format option not available for multiple files'

      # Find the dataset names that are common to all files (intersection of filename sets)
      namesets = []
      for filename in self.fin:
        # Open HDF5 file
        f = hdf.File(filename)

        # Open data group
        dgroup = 'data'
        if not dgroup in f:
          continue
        g = f[dgroup]

        # Get all field names
        namesets.append(set(g.keys()))

        # Close HDF5 file
        f.close()
      if len(namesets) > 1:
        self.dout.name = list(namesets[0].intersection(*namesets[1:]))
      else:
        self.dout.name = list(namesets[0])

      # Display or return list of datasets
      if self.shellmode:
        if len(self.dout.name) > 0:
          printcols(self.dout.name)
      else:
        return self.dout.name





class _Gados(CalcProc):
  """Calculate typical (GDOS) and total density of states (ADOS), i.e. the
  geometrical and the arithmetical mean of several local density of states
  (LDOS) of different sites in the site-occupations basis and different
  realizations of disorder (given by input files).

  This script serves as a meta-script to automatically calculate both GDOS and
  ADOS. It calls the scripts gdos and ados in function mode. Most parameters
  are just passed to those functions."""
  # 30/05/2011
  version = '02/06/2011'
  epilog = """Open questions:
  --> Use different tolerance values for the convergence criterions?
  """

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-l', '--limit', dest='limit', default='1000', type=str, help='set maximum truncation number. If given a float (including a decimal point), it is interpreted as the fraction of the system size. If given a ratio (including a slash), the expression is evaluated and also interpreted as the fraction of the system size. With the last variant, you can specify things like "2000/125000", meaning that at a system size of 125000, the truncation limit would be set to 2000, and at other system sizes accordingly, keeping this ratio constant.')
    self.op.add_option('-t', '--tol', dest='tol', default=.01, type=float, help='set tolerance for convergence criterions.')
    self.op.add_option('-p', '--step', dest='step', default=0, type=int, help='set step size. Every this times of KPM iterations, the moments are checked for the convergence criterion. 0 means that no convergence criterion will be used, i.e. a constant number of moments is used, specified by --limit.')
    self.op.add_option('-s', '--states', dest='states', type=int, default=0, help='set number of random states (of the site-occupation basis). If set to zero, use convergence criterion (maximum number will be the number of eigenstates).')
    self.op.add_option('-r', '--reals', dest='reals', default=False, action='store_true', help='use abort criterion for number of realizations')
    self.op.add_option('-e', '--erange', dest='erange', type=str, default='', help='set energy range. Must consist of one or two values, separated by a comma')
    self.op.add_option('-n', '--nenerg', dest='nenerg', type=int, default=0, help='set energy discretization (number of energy intervals). If set to zero, take limit*2')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)
    import tbc

    # Load data
    self.load(iterate=True) # iterate=True is important now, because otherwise "*params" would have to be passed to gdos and ados instead of "params"
    if self.shellmode:
      params = self.pin
    else:
      params = self.din
    nents = params[0].supercell.hamilt().shape[0]

    # Calculate GDOS
    if self.opts.verbose:
      print 'calculate GDOS:'
    self.dout.gdos_dens, self.dout.gdos_energ, self.cout = gdos(
      params,
      limit=self.opts.limit,
      tol=self.opts.tol,
      step=self.opts.step,
      states=self.opts.states,
      reals=self.opts.reals,
      erange=self.opts.erange,
      nenerg=self.opts.nenerg,
      verbose=self.opts.verbose,
      comments=True)

    # Save GDOS
    self.save('gdos_dens', 'gdos_energ', prog='gdos')

    # Empty data output structure
    self.dout = struct()

    # Calculate ADOS
    if self.opts.verbose:
      print 'calculate ADOS:'
    self.dout.ados_dens, self.dout.ados_energ, self.dout.ados_ldens, self.dout.ados_ldist, self.dout.ados_lnum, self.cout = ados(
      params,
      limit=self.opts.limit,
      tol=self.opts.tol,
      step=self.opts.step,
      states=self.opts.states,
      reals=self.opts.reals,
      erange=self.opts.erange,
      nenerg=self.opts.nenerg,
      verbose=self.opts.verbose,
      comments=True)

    # Save ADOS
    self.save(prog='ados')





class _Gdos(CalcProc):
  """Calculate typical density of states (GDOS). Take the geometric average
  over multiple realizations of disorder (given input files) and states of the
  site-occupation basis."""
  # 17/05/2011
  version = '20/05/2011'
  epilog = """Open questions:
  --> Use the same tolerance for all convergence criterions?

  Future visions:
  --> offer other methods, like taking existing LDOS data as input
  """

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-l', '--limit', dest='limit', default='1000', type=str, help='set maximum truncation number. If given a float (including a decimal point), it is interpreted as the fraction of the system size. If given a ratio (including a slash), the expression is evaluated and also interpreted as the fraction of the system size. With the last variant, you can specify things like "2000/125000", meaning that at a system size of 125000, the truncation limit would be set to 2000, and at other system sizes accordingly, keeping this ratio constant.')
    self.op.add_option('-t', '--tol', dest='tol', default=.01, type=float, help='set tolerance for convergence criterions.')
    self.op.add_option('-p', '--step', dest='step', default=0, type=int, help='set step size. Every this times of KPM iterations, the moments are checked for the convergence criterion. 0 means that no convergence criterion will be used, i.e. a constant number of moments is used, specified by --limit.')
    self.op.add_option('-s', '--states', dest='states', type=int, default=0, help='set number of random states (of the site-occupation basis). If set to zero, use convergence criterion (maximum number will be the number of eigenstates).')
    self.op.add_option('-r', '--reals', dest='reals', default=False, action='store_true', help='use abort criterion for number of realizations')
    self.op.add_option('-e', '--erange', dest='erange', type=str, default='', help='set energy range. Must consist of one or two values, separated by a comma')
    self.op.add_option('-n', '--nenerg', dest='nenerg', type=int, default=0, help='set energy discretization (number of energy intervals). If set to zero, take limit*2')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)
    import tbc

    # Check options
    erange = opt2list(self.opts.erange, dtype=float)
    assert self.opts.erange != '', 'energy range must be specified'
    assert self.opts.step >= 0, 'bad step width: %i. Must be non-negative integer' % self.opts.step
    assert self.opts.tol > 0., 'bad tolerance: %i. Must be positive float' % self.opts.tol

    # Load data
    self.load(iterate=True)
    if self.shellmode:
      params = self.pin
    else:
      params = self.din
    nents = params[0].supercell.hamilt().shape[0]

    # Interprete state option
    assert self.opts.states < nents, 'bad number of states: %i. Dimension of hamiltonian is only %i.' % (self.opts.states, nents)
    assert self.opts.states >= 0, 'bad number of states: %i. Must be non-negative integer.' % self.opts.states
    if self.opts.states == 0:
      states = list(rd.permutation(nents))
      nstates = nents
    else:
      states = list(rd.permutation(nents)[:self.opts.states])
      states.sort()
      nstates = len(states)

    # Interprete limit option
    if '/' in self.opts.limit:
      self.opts.limit = int(float(eval(self.opts.limit+'.'))*nents)
    elif '.' in self.opts.limit:
      self.opts.limit = int(float(self.opts.limit)*nents)
    else:
      self.opts.limit = int(self.opts.limit)
    assert self.opts.limit > 0, 'bad truncation limit: %i. Must be positive integer' % self.opts.limit
    if self.opts.limit % 2 == 1:
      self.opts.limit += 1 # Make it even

    # Set energy discretization (number of energy intervals for reconstructing each LDOS)
    if self.opts.nenerg == 0:
      self.opts.nenerg = self.opts.limit*2

    # Define energy range
    assert len(erange) < 3, 'bad energy range: May only consist of a maximum of two floats, separated by a comma, leaving no whitespace'
    if len(erange) > 1:
      # Get energy range
      emin, emax = erange
    elif len(erange) > 0:
      # Assume symmetric energy range
      if erange[0] < 0:
        emin = erange[0]
        emax = -emin
      else:
        emax = erange[0]
        emin = -emax
    else:
      raise ValueError, 'energy range must be specified'
      ## Calculate highest and lowest eigenvalues using Lanczos algorithm
      #p = Progress(1, 'Use Lanczos to find energy range', verbose=self.opts.verbose)
      #some_eigvals = sla.eigen_symmetric(hamilt, k=10, which='BE', return_eigenvectors=False)
      #emin = min(some_eigvals)
      #emin -= abs(.1*emin) # Just add an extra 10 % to make sure not eigenvalue lies outside the interval [-1, 1]
      #emax = max(some_eigvals)
      #emax += abs(.1*emax) # Just add an extra 10 % to make sure not eigenvalue lies outside the interval [-1, 1]
      #p.step()

    # Iterate over realizations
    denssum_r, denssum_r_old = None, None
    nstates_used = []
    num = 0
    rnum = 0
    snums = []
    sind = 0
    rind = 0
    delta = 0.
    delta_r = 0.
    m = Monitor(floatf='%.3f', verbose=self.opts.verbose, order=['r', 'del_r', 's', 'del_s', 'smean', 'smin', 'smax'])
    for rind, param in enumerate(params):
      m.step(r=rind)

      # Load matrix
      mat = param.supercell.hamilt(format='csr')

      # Rescale matrix
      eps = np.pi/self.opts.limit #trunc # At least for the Jackson kernel, pi/trunc is an excellent choice.
      a = (emax-emin)/(2-eps)
      b = (emax+emin)/2
      eye = spa.eye(*mat.shape, format='csr')
      resc = (mat-eye*b)/a # Rescaled matrix

      if self.opts.reals and denssum_r != None:
        denssum_r_old = denssum_r.copy()

      # Iterate over states
      denssum, denssum_old = None, None
      snum = 0
      for sind, state in enumerate(states):
        m.step(s=sind)

        if self.opts.states == 0 and denssum != None:
          denssum_old = denssum.copy()

        # Call KPM algorithm
        energ, dens, mu, trunc = tbc.kpm_ldos(resc.data,
                                              resc.indices,
                                              resc.indptr,
                                              nents,
                                              state=state,
                                              limit=self.opts.limit,
                                              step=self.opts.step,
                                              tol=self.opts.tol,
                                              nenerg=self.opts.nenerg)

        dens = np.log(dens/a) # Don't forget re-rescaling factor

        # Add up summands
        if denssum == None:
          denssum = dens
        else:
          denssum += dens

        num += 1
        snum += 1

        # Check convergence criterion
        if self.opts.states == 0 and denssum_old != None:
          delta = np.abs(1-np.exp((denssum_old+dens)/snum-denssum_old/(snum-1))) # delta.shape == (nenerg,)
          #delta = np.abs(denssum_old/(snum-1)-denssum_old/snum-dens/snum) # This would be for arithmetic mean # delta.shape == (nenerg,)
          m.step(del_s=max(delta))
          if np.all(delta < self.opts.tol):
          #if np.mean(delta) < self.opts.tol:
            break

      # Store number of states used
      nstates_used.append(sind+1)

      if denssum_r == None:
        denssum_r = denssum
      else:
        denssum_r += denssum

      rnum += 1
      snums.append(snum)
      m.step(smean=int(np.round(np.mean(snums))), smin=min(snums), smax=max(snums))

      # Check convergence criterion
      if self.opts.reals and denssum_r_old != None:
        nstates_sum = sum(nstates_used)
        nstates_sum_old = sum(nstates_used[:-1])
        delta_r = np.abs(1-np.exp((denssum_r_old+denssum)/num-denssum_r_old/(num-snum))) # delta_r.shape == (nenerg,)
        m.step(del_r=max(delta_r))
        if np.all(delta_r < self.opts.tol):
        #if np.mean(delta_r) < self.opts.tol:
          break

    m.end()
    # Store number of realizations used
    #nreals_used = rind+1 # Now substituted by rnum

    # Calculate GDOS and save data, don't forget re-rescaling of the energy axis
    self.dout.gdos_energ = a*energ+b
    self.dout.gdos_dens  = np.exp(denssum_r/num)

    # Save comments
    self.cout.limit  = self.opts.limit
    self.cout.erange = self.opts.erange
    self.cout.states = self.opts.states
    self.cout.nenerg = self.opts.nenerg
    self.cout.tol    = self.opts.tol
    self.cout.step   = self.opts.step
    self.cout.num    = num
    self.cout.rnum   = rnum
    self.cout.snums  = snums
    self.cout.num    = num

    # Save data
    return self.save()




class _Ados(CalcProc):
  """Calculate total density of states (GDOS). Calculate
  the arithmetic average over multiple realizations of
  disorder (given input files) and states of the site-
  occupation basis."""
  # 29/05/2011
  version = '30/05/2011'
  epilog = """Open questions:
  --> Use the same tolerance for all convergence
      criterions?

  Future visions:
  --> offer other methods, like accept existing LDOS data
      as input, and use random-phase vectors and stochastic
      evaluation
  """

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-l', '--limit', dest='limit', default='1000', type=str, help='set maximum truncation number. If given a float (including a decimal point), it is interpreted as the fraction of the system size. If given a ratio (including a slash), the expression is evaluated and also interpreted as the fraction of the system size. With the last variant, you can specify things like "2000/125000", meaning that at a system size of 125000, the truncation limit would be set to 2000, and at other system sizes accordingly, keeping this ratio constant.')
    self.op.add_option('-t', '--tol', dest='tol', default=.01, type=float, help='set tolerance for convergence criterions.')
    self.op.add_option('-p', '--step', dest='step', default=0, type=int, help='set step size. Every this times of KPM iterations, the moments are checked for the convergence criterion. 0 means that no convergence criterion will be used, i.e. a constant number of moments is used, specified by --limit.')
    self.op.add_option('-s', '--states', dest='states', type=int, default=0, help='set number of random states (of the site-occupation basis). If set to zero, use convergence criterion (maximum number will be the number of eigenstates).')
    self.op.add_option('-r', '--reals', dest='reals', default=False, action='store_true', help='use abort criterion for number of realizations')
    self.op.add_option('-e', '--erange', dest='erange', type=str, default='', help='set energy range. Must consist of one or two values, separated by a comma')
    self.op.add_option('-n', '--nenerg', dest='nenerg', type=int, default=0, help='set energy discretization (number of energy intervals). If set to zero, take limit*2')
    self.op.add_option('-b', '--bins', dest='bins', type=int, default=10000, help='set number of histogram bins for local distribution')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)
    import tbc

    # Check options
    erange = opt2list(self.opts.erange, dtype=float)
    assert self.opts.erange != '', 'energy range must be specified'
    assert self.opts.step >= 0, 'bad step width: %i. Must be non-negative integer' % self.opts.step
    assert self.opts.tol > 0., 'bad tolerance: %i. Must be positive float' % self.opts.tol
    assert self.opts.bins > 0, 'bad number of bins: %i. Must be positive integer' % self.opts.bins

    # Load data
    self.load(iterate=True)
    if self.shellmode:
      params = self.pin
    else:
      params = self.din
    nents = params[0].supercell.hamilt().shape[0]
    #dump(nents=nents, limit=self.opts.limit)

    # Interprete state option
    assert self.opts.states < nents, 'bad number of states: %i. Dimension of hamiltonian is only %i.' % (self.opts.states, nents)
    assert self.opts.states >= 0, 'bad number of states: %i. Must be non-negative integer.' % self.opts.states
    if self.opts.states == 0:
      states = list(rd.permutation(nents))
      nstates = nents
    else:
      states = list(rd.permutation(nents)[:self.opts.states])
      states.sort()
      nstates = len(states)

    # Interprete limit option
    if '/' in self.opts.limit:
      self.opts.limit = int(float(eval(self.opts.limit+'.'))*nents)
    elif '.' in self.opts.limit:
      self.opts.limit = int(float(self.opts.limit)*nents)
    else:
      self.opts.limit = int(self.opts.limit)
    assert self.opts.limit > 0, 'bad truncation limit: %i. Must be positive integer' % self.opts.limit
    if self.opts.limit % 2 == 1:
      self.opts.limit += 1 # Make it even

    # Set energy discretization (number of energy intervals for reconstructing each LDOS)
    if self.opts.nenerg == 0:
      self.opts.nenerg = self.opts.limit*2

    # Define energy range
    assert len(erange) < 3, 'bad energy range: May only consist of a maximum of two floats, separated by a comma, leaving no whitespace'
    if len(erange) > 1:
      # Get energy range
      emin, emax = erange
    elif len(erange) > 0:
      # Assume symmetric energy range
      if erange[0] < 0:
        emin = erange[0]
        emax = -emin
      else:
        emax = erange[0]
        emin = -emax
    else:
      raise ValueError, 'energy range must be specified'

    # Iterate over realizations
    denssum_r, denssum_r_old = None, None
    nstates_used = []
    num = 0
    rnum = 0
    snums = []
    sind = 0
    rind = 0
    delta = 0.
    delta_r = 0.
    hist = MultiHistogram(bins=self.opts.bins, range=(0, 1), shape=self.opts.nenerg)
    m = Monitor(floatf='%.3f', verbose=self.opts.verbose, order=['r', 'del_r', 's', 'del_s', 'smean', 'smin', 'smax'])
    for rind, param in enumerate(params):
      m.step(r=rind)

      # Load matrix
      mat = param.supercell.hamilt(format='csr')

      # Rescale matrix
      eps = np.pi/self.opts.limit #trunc # At least for the Jackson kernel, pi/trunc is an excellent choice.
      a = (emax-emin)/(2-eps)
      b = (emax+emin)/2
      eye = spa.eye(*mat.shape, format='csr')
      resc = (mat-eye*b)/a # Rescaled matrix

      if self.opts.reals and denssum_r != None:
        denssum_r_old = denssum_r.copy()

      # Iterate over states
      denssum, denssum_old = None, None
      snum = 0
      for sind, state in enumerate(states):
        m.step(s=sind)

        if self.opts.states == 0 and denssum != None:
          denssum_old = denssum.copy()

        # Call KPM algorithm
        energ, dens, mu, trunc = tbc.kpm_ldos(resc.data,
                                              resc.indices,
                                              resc.indptr,
                                              nents,
                                              state=state,
                                              limit=self.opts.limit,
                                              step=self.opts.step,
                                              tol=self.opts.tol,
                                              nenerg=self.opts.nenerg)

        # Add LDOS values to histograms
        #m.step(nd=min(dens), xd=max(dens))
        hist.add(dens)

	#print np.sum(np.diff(energ)*dens[:-1])
	#raise
        dens /= a # Don't forget re-rescaling factor
	#print dens, hist.bins()
	#raise

        # Add up summands
        if denssum == None:
          denssum = dens
        else:
          denssum += dens

	# Count
        num += 1
        snum += 1

        # Check convergence criterion
        if self.opts.states == 0 and denssum_old != None:
          delta = np.abs(1-(denssum_old+dens)/snum*(snum-1)/denssum_old) # delta.shape == (nenerg,)
          m.step(del_s=max(delta))
          if np.all(delta < self.opts.tol):
          #if np.mean(delta) < self.opts.tol:
            break

      # Store number of states used
      nstates_used.append(sind+1)

      if denssum_r == None:
        denssum_r = denssum
      else:
        denssum_r += denssum

      rnum += 1
      snums.append(snum)
      m.step(smean=int(np.round(np.mean(snums))), smin=min(snums), smax=max(snums))

      # Check convergence criterion
      if self.opts.reals and denssum_r_old != None:
        nstates_sum = sum(nstates_used)
        nstates_sum_old = sum(nstates_used[:-1])
        delta_r = np.abs(1-(denssum_r_old+denssum)/num*(num-snum)/denssum_r_old) # delta_r.shape == (nenerg,)
        m.step(del_r=max(delta_r))
        if np.all(delta_r < self.opts.tol):
        #if np.mean(delta_r) < self.opts.tol:
          break
    m.end()

    # Calculate GDOS and save data
    self.dout.ados_dens  = denssum_r/num
    self.dout.ados_energ = a*energ+b # don't forget re-rescaling of the energy axis
    self.dout.ados_ldens = hist.bins(centers=True)
    self.dout.ados_ldist = hist(normed=True)
    self.dout.ados_lnum  = hist.num()

    # Save comments
    self.cout.limit  = self.opts.limit
    self.cout.erange = self.opts.erange
    self.cout.states = self.opts.states
    self.cout.nenerg = self.opts.nenerg
    self.cout.tol    = self.opts.tol
    self.cout.step   = self.opts.step
    self.cout.num    = num
    self.cout.rnum   = rnum
    self.cout.snums  = snums
    self.cout.num    = num

    # Save data
    return self.save()





class _Dos(CalcProc):
  """Calculate density of states (DOS). Load eigenvalues from one or more data
  files. Save DOS and bin edges to another data file. In function mode, do
  the same, where the function arguments contain the energy values, and the DOS
  and the bin edges are returned."""
  # 13/02/2011-10/05/2011
  version = '04/05/2011'
  epilog = """Future visions:
  - Offer statistical evaluation method for total DOS using KPM"""

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-m', '--mode', '--method', dest='mode', type=str, default='kpm', help='set calculation method (mode)')
    self.op.add_option('-b', '--bins', dest='bins', default=50, type=int, help='set number of energy bins (in hist mode)')
    self.op.add_option('-e', '--erange', dest='erange', type=str, default='', help='set energy range (in KPM mode). Must consist of two values, separated by a comma')
    #self.op.add_option('-t', '--trunc', dest='trunc', type=int, default=100, help='set truncation number (in KPM mode)')
    self.op.add_option('-k', '--kernel', dest='kernel', default='jackson', help='select kernel (in KPM mode)')
    self.op.add_option('-s', '--site', dest='site', type=str, default='', help='select lattice site(s) of which to obtain the local density of states. If the parameter begins with the letter "r", followed by a positive integer, the given number of random sites are elected. If the parameter is "all", all sites of the system are chosen.')
    self.op.add_option('-l', '--limit', dest='limit', default=8000, type=int, help='set maximum truncation number')
    self.op.add_option('-p', '--step', dest='step', default=100, type=int, help='set step width. After this times of KPM iterations, the LDOS is created and checked for the convergence criterion. The default value 0 means that no abort criterion is being used.')
    self.op.add_option('-t', '--tol', dest='tol', default=.01, type=float, help='set tolerance for the convergence criterion.')
    self.op.add_option('-r', '--ratio', dest='ratio', default=.05, type=float, help='set ratio between truncation number and number of eigenstates of the system. In this way, the truncation number is defined.')

    self.op.add_option('--single', dest='single', default=False, action='store_true', help='special verbose mode where the progress of each single realization is shown')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    # Check options
    assert self.opts.bins > 0, 'bad number of bins: %i. Must be positive integer' % self.opts.bins
    assert self.opts.erange != '', 'energy range must be specified'
    #assert self.opts.trunc > 0, 'bad truncation number: %i. Must be positive integer' % self.opts.trunc

    if self.opts.mode.lower() in ('hist', 'h'):
      # Load data
      self.load('eigvals')
      alleigvals = np.hstack((d.eigvals for d in self.din))

      # Make histogram
      self.dout.dos_hist, self.dout.dos_bins = np.histogram(alleigvals, bins=self.opts.bins)

    elif self.opts.mode.lower() in ('kpm', 'k'):
      # Calculate total and typical DOS by calculating the mean and geometrical
      # mean value over the LDOS of all given realizations of a system. The
      # LDOS is calculated for each realization by means of the KPM.
      # 03/04/2011

      # Load data
      self.load(iterate=True)
      if self.shellmode:
        params = self.pin
      else:
        params = self.din
      #ne = params[0].supercell.hamilt().shape[0]

      if len(params) < 2 and self.opts.verbose:
        self.opts.single = True
      if self.opts.single:
        self.opts.verbose = False

      # Calculate LDOS at some of the lattice sites of each realization
      p = Progress(len(params), text='calculate LDOS', verbose=self.opts.verbose)
      arithsum = np.zeros(2*self.opts.limit) # Will hold the summation value of the arithmetic mean
      typsum = np.zeros(2*self.opts.limit) # Will hold the summation value of the geometric mean
      num = 0 # Will hold the total number of LDOS considered and averaged over
      energ = None
      trunc = None
      for ind, param in enumerate(params):
        assert 'supercell' in param, 'no supercell definition found in parameter set %i' % (ind+1)
        d, e, siteindex, tr   = ldos( param.supercell.hamilt(),
                                      m='kpm',
                                      s=self.opts.site,
                                      k=self.opts.kernel,
                                      e=self.opts.erange,
                                      #t=self.opts.trunc,
                                      l=self.opts.limit,
                                      p=self.opts.step,
                                      t=self.opts.tol,
                                      v=self.opts.single) # d.shape == (tt, snum), e.shape == (tt.)
        arithsum += np.sum(d, axis=0)
        typsum += np.sum(np.log(d), axis=0)
        num += d.shape[0]
        if energ == None:
          energ = e
        if trunc == None:
          trunc = np.zeros(len(params)*len(tr), dtype=int)
        trunc[(ind*len(tr)):((ind+1)*len(tr))] = tr
        p.step()

      # Calculate total and typical DOS, average over realizations and over sites
      self.dout.dos_energ = energ
      self.dout.dos_dens = arithsum/num #np.mean(np.mean(dens, axis=-1), axis=0)
      self.dout.dos_typ_dens = np.exp(typsum/num) #st.gmean(st.gmean(dens, axis=-1), axis=0)
      self.dout.dos_ratio = self.dout.dos_typ_dens/self.dout.dos_dens
      self.dout.dos_trunc = trunc
      #self.cout.trunc = self.opts.trunc
      self.cout.kernel = self.opts.kernel
      self.cout.erange = self.opts.erange
      self.cout.site = self.opts.site

    elif self.opts.mode.lower() in ('ldos', 'l'):
      # Calculate total DOS by summing the LDOS values over all lattice sites
      # This is of course not the best way to calculate the total DOS

      # Load data
      self.load('ldos_density', 'ldos_energy')
      assert len(self.args) == 1, 'only one input filename supported'
      density = self.din[0].ldos_dens
      energy = self.din[0].ldos_energ

      # Calculate DOS
      self.dout.dos_energ = energy
      self.dout.dos_dens = np.mean(density, axis=0)

    else:
      self.op.error('Unknown method to calculate DOS: %s' % self.opts.mode)

    # Save data
    return self.save()





class _Ldos(CalcProc):
  """Calculate local density of states (DOS)."""
  # 20/02/2011-10/05/2011
  version = '04/05/2011'
  epilog = """Future improvements:
  - Use fast dicrete cosine transform (DCT, "divide-and-conquer" algorithm,
    scipy.fftpack.dct), or at least FFT
  - Use flexible abort criterion, allowing either fixed truncation number or certain
    accuracy. Is this even possible?
  - Escape iteration loop on key pressed (ESC)?
  - (instead of specifying site indices, offer possibility to specify coordinates?)
  """
  nif = 1 # As for now, only one input file allowed

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-m', '--mode', '--method', dest='method', type=str, default='kpm', help='set calculation method (mode)')
    self.op.add_option('-e', '--erange', dest='erange', type=str, default='', help='set energy range. Must consist of two values, separated by a comma')
    #self.op.add_option('-t', '--trunc', dest='trunc', type=int, default=100, help='set truncation number')
    self.op.add_option('-s', '--site', dest='site', type=str, default='', help='select lattice site index (or indices) of which to obtain the local density of states. If the parameter begins with the letter "r", followed by a positive integer, the given number of random sites are elected.')
    self.op.add_option('-k', '--kernel', dest='kernel', default='jackson', help='select kernel')
    self.op.add_option('-n', '--nes', dest='nes', default=20000000, type=int, help='set maximum value of the product of number of entities (ne) and number of start vectors (ns). This value has to be adjusted to the available physical memory (RAM) of the machine.')
    self.op.add_option('-l', '--limit', dest='limit', default=8000, type=int, help='set maximum truncation number')
    self.op.add_option('-p', '--step', dest='step', default=100, type=int, help='set step width. After this times of KPM iterations, the LDOS is created and checked for the convergence criterion. The default value 0 means that no abort criterion is being used.')
    self.op.add_option('-t', '--tol', dest='tol', default=.01, type=float, help='set tolerance, defining the convergence criterion.')
    self.op.add_option('-r', '--ratio', dest='ratio', default=.05, type=float, help='set ratio between truncation number and number of eigenstates of the system. In this way, the truncation number is defined.')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    # Check options
    erange = opt2list(self.opts.erange, dtype=float)
    assert self.opts.limit > 0, 'bad truncation limit: %i. Must be positive integer' % self.opts.limit
    assert self.opts.step >= 0, 'bad step width: %i. Must be non-negative integer' % self.opts.step
    assert self.opts.tol > 0., 'bad tolerance: %i. Must be positive float' % self.opts.tol
    #assert self.opts.trunc > 0, 'bad truncation number: %i. Must be positive integer' % self.opts.trunc
    kernel = eval(self.opts.kernel)

    if self.opts.method.lower() in ('kpm', 'k'):
      # Load data
      self.load()
      if self.shellmode:
        hamilt = self.pin[0].supercell.hamilt()
      else:
        hamilt = self.din[0]
      ne = hamilt.shape[0] # Number of entities/states. In 1-band models: Number of lattice sites

      # Find sites
      if self.opts.site.startswith('r'):
        ns = int(self.opts.site[1:])
        assert ns > 0, 'number of randomly chosen sites must be positive integer'
        sites = list(rd.permutation(ne)[:ns])
        sites.sort()
      elif self.opts.site == 'all':
        sites = range(ne)
      elif isiterable(self.opts.site):
        sites = list(self.opts.site)
      else:
        sites = opt2ranges(self.opts.site, upper=ne)
      assert len(sites) > 0, 'no site given'
      assert max(sites) < ne, 'bad site index: %i. Only %i sites exist in system' % (max(sites), ne)
      ns = len(sites)

      # Store lattice site positions
      self.dout.ldos_siteindex = np.array(sites)

      # Define energy range
      assert len(erange) < 3, 'bad energy range: May only consist of a maximum of two floats, separated by a comma, leaving no whitespace'
      if len(erange) > 1:
        # Get energy range
        emin, emax = erange
      elif len(erange) > 0:
        # Assume symmetric energy range
        if erange[0] < 0:
          emin = erange[0]
          emax = -emin
        else:
          emax = erange[0]
          emin = -emax
      else:
        # Calculate highest and lowest eigenvalues using Lanczos algorithm
        p = Progress(1, 'Use Lanczos to find energy range', verbose=self.opts.verbose)
        some_eigvals = sla.eigen_symmetric(hamilt, k=10, which='BE', return_eigenvectors=False)
        emin = min(some_eigvals)
        emin -= abs(.1*emin) # Just add an extra 10 % to make sure not eigenvalue lies outside the interval [-1, 1]
        emax = max(some_eigvals)
        emax += abs(.1*emax) # Just add an extra 10 % to make sure not eigenvalue lies outside the interval [-1, 1]
        p.step()

      # Rescale Hamiltonian
      p = Progress(1, 'Rescale Hamiltonian', verbose=self.opts.verbose)
      eps = np.pi/self.opts.limit #trunc # At least for the Jackson kernel, pi/trunc is an excellent choice.
      a = (emax-emin)/(2-eps)
      b = (emax+emin)/2
      eye = spa.eye(*hamilt.shape, format='csc')
      rescham = (hamilt-eye*b)/a # Rescaled Hamiltonian
      p.step()

      # Execute KPM core algorithm
      energ, dens, trunc = kpms(  mat=rescham,
                                  states=sites, #np.ascontiguousarray(sites, dtype=np.uint)
                                  limit=self.opts.limit,
                                  step=self.opts.step,
                                  tol=self.opts.tol,
                                  verbose=self.opts.verbose)

      #dump(trunc=trunc)
      if self.opts.verbose and self.opts.step != 0 and self.opts.limit in trunc:
        print 'Warning: At least one KPM run reached the iteration limit (%i). Maybe you should increase the iteration limit.' % self.opts.limit

      # Apply kernel
      #p = Progress(1, text='Apply kernel', verbose=self.opts.verbose)
      #mu = kernel(mu) # devide by ne if you want to normalize the LDOS to the total volume of the system rather than to the unitcell
      #p.step()

      # Reconstruct function
      #p = Progress(1, text='Reconstruct LDOS', verbose=self.opts.verbose)
      #tt = 2*self.opts.trunc
      #k = np.arange(tt)[:, None]
      #n = np.arange(1, self.opts.trunc)
      #x = np.cos(np.pi*(2*k+1)/2/tt)
      #dens = (mu[0, :]+2*np.dot(np.cos(np.pi*n*(2*k+1)/2/tt), mu[1:]))/np.pi/np.sqrt(1-x**2) # dens.shape == (tt, snum) # Huge memory waste!!!
      #p.step()

      # Rescale discretized energy axis back to original scale
      p = Progress(1, text='Rescale energy back to original range', verbose=self.opts.verbose)
      self.dout.ldos_energ = np.ravel(a*energ+b) # ldos_energ.shape == (limit*2,)
      self.dout.ldos_dens  = dens/a              # ldos_dens.shape  == (snum, limit*2) # Do not forget to divide by a to ensure proper scaling (normalize)
      self.dout.ldos_trunc = trunc               # ldos_trunc.shape == (limit*2,)
      p.step()

      # Add special comments about rescaling process and truncation number etc.
      self.cout.a     = a
      self.cout.b     = b
      #self.cout.trunc = self.opts.trunc
      self.cout.limit = self.opts.limit
      self.cout.step  = self.opts.step
      self.cout.tol   = self.opts.tol
    else:
      self.op.error('Unknown method to calculate LDOS: %s' % self.opts.method)

    # Save data
    return self.save()



class LdosBackup(CalcProc):
  """Calculate local density of states (DOS)."""
  # 20/02/2011
  version = '05/04/2011'
  epilog = """Future improvements:
  - Use fast dicrete cosine transform (DCT, "divide-and-conquer" algorithm,
    scipy.fftpack.dct), or at least FFT
  - Use flexible abort criterion, allowing either fixed truncation number or certain
    accuracy. Is this even possible?
  - Abort loop on key pressed?
  - instead of specifying site indices, offer possibility to specify coordinates?"""
  nif = 1

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-m', '--mode', '--method', dest='method', type=str, default='kpm', help='set calculation method (mode)')
    self.op.add_option('-e', '--erange', dest='erange', type=str, default='', help='set energy range. Must consist of two values, separated by a comma')
    self.op.add_option('-t', '--trunc', dest='trunc', type=int, default=100, help='set truncation number')
    self.op.add_option('-s', '--site', dest='site', type=str, default='', help='select lattice site index (or indices) of which to obtain the local density of states. If the parameter begins with the letter "r", followed by a positive integer, the given number of random sites are elected.')
    self.op.add_option('-k', '--kernel', dest='kernel', default='jackson', help='select kernel')

  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    # Check options
    erange = opt2list(self.opts.erange, dtype=float)
    assert self.opts.trunc > 0, 'bad truncation number: %i. Must be positive integer' % self.opts.trunc
    kernel = eval(self.opts.kernel)

    if self.opts.method.lower() in ('kpm', 'k'):
      # Load data
      self.load()
      if self.shellmode:
        hamilt = self.pin[0].supercell.hamilt()
      else:
        hamilt = self.din[0]
      ne = hamilt.shape[0] # Number of entities/states. In 1-band models: Number of lattice sites

      #if self.opts.site == '':
      #  sites = range(ne) # Really???
      #else:
      if self.opts.site.startswith('r'):
        ns = int(self.opts.site[1:])
        assert ns > 0, 'number of randomly chosen sites must be positive integer'
        sites = list(rd.permutation(ne)[:ns])
        sites.sort()
      else:
        sites = opt2ranges(self.opts.site, upper=ne)
      assert len(sites) > 0, 'no site given'
      assert max(sites) < ne, 'bad site index: %i. Only %i sites exist in system' % (max(sites), ne)
      ns = len(sites)

      # Store lattice site positions
      self.dout.ldos_siteindex = np.array(sites)

      # Define energy range
      assert len(erange) < 3, 'bad energy range: May only consist of a maximum of two floats, separated by a comma, leaving no whitespace'
      if len(erange) > 1:
        # Get energy range
        emin, emax = erange
      elif len(erange) > 0:
        # Assume symmetric energy range
        if erange[0] < 0:
          emin = erange[0]
          emax = -emin
        else:
          emax = erange[0]
          emin = -emax
      else:
        # Calculate highest and lowest eigenvalues using Lanczos algorithm
        p = Progress(1, 'Use Lanczos to find energy range', verbose=self.opts.verbose)
        some_eigvals = sla.eigen_symmetric(hamilt, k=10, which='BE', return_eigenvectors=False)
        emin = min(some_eigvals)
        emin -= abs(.1*emin)
        emax = max(some_eigvals)
        emax += abs(.1*emax)
        p.step()

      # Rescale Hamiltonian
      p = Progress(1, 'Rescale Hamiltonian', verbose=self.opts.verbose)
      eps = np.pi/self.opts.trunc # At least for the Jackson kernel, pi/trunc is an excellent choice.
      a = (emax-emin)/(2-eps)
      b = (emax+emin)/2
      eye = spa.eye(*hamilt.shape, format='csc')
      rescham = (hamilt-eye*b)/a # Rescaled Hamiltonian
      p.step()

      # Initialization
      p = Progress(6, text='Initialize iteration', verbose=self.opts.verbose)
      phi = np.zeros((3, ne, ns), dtype=float)
      p.step()
      mu = np.zeros((self.opts.trunc, ns), dtype=float)
      p.step()
      for ind, site in enumerate(sites): # Can this loop be avoided?
        phi[0, site, ind] = 1.
      p.step()
      mu[0] = np.sum(phi[0]*phi[0], axis=0)
      p.step()
      phi[1] = rescham*phi[0]
      p.step()
      mu[1] = np.sum(phi[1]*phi[0], axis=0)
      p.step()

      # Iteration
      p = Progress((self.opts.trunc-1)/2, text='Calculate moments', verbose=self.opts.verbose)
      for n in xrange(1, self.opts.trunc/2): # This is the critical for-loop that cannot be avoided
        phi[2] = rescham*2*phi[1]-phi[0]
        mu[2*n] = 2*np.sum(phi[1]*phi[1], axis=0)-mu[0]
        mu[2*n+1] = 2*np.sum(phi[2]*phi[1], axis=0)-mu[1]
        phi[:2] = phi[-2:]
        p.step()
      if self.opts.trunc % 2 == 1: # If trunc is odd, calculate last moment
        phi[2] = rescham*2*phi[1]-phi[0]
        mu[self.opts.trunc-1] = 2*np.sum(phi[1]*phi[1], axis=0)-mu[0]
        p.step()

      # Apply kernel
      mu = kernel(mu) #/ne

      # Reconstruct function
      p = Progress(1, text='Reconstruct LDOS', verbose=self.opts.verbose)
      tt = 2*self.opts.trunc
      k = np.arange(tt)[:, None]
      n = np.arange(1, self.opts.trunc)
      x = np.cos(np.pi*(2*k+1)/2/tt)
      dens = (mu[0]+2*np.dot(np.cos(np.pi*n*(2*k+1)/2/tt), mu[1:]))/np.pi/np.sqrt(1-x**2) # ldos_density.shape == (tt,)
      p.step()

      # Rescale discretized energy axis back to original scale
      p = Progress(1, text='Rescale energy back to original range', verbose=self.opts.verbose)
      self.dout.ldos_energ = a*x+b # ldos_energy.shape == (tt,)
      self.dout.ldos_dens = dens/a # Do not forget this, so that the area under the DOS plot does not change
      p.step()

      # Add special comments
      self.cout.a = a
      self.cout.b = b
      self.cout.trunc = self.opts.trunc
    else:
      self.op.error('Unknown method to calculate LDOS: %s' % self.opts.method)

    # Save data
    return self.save()



class _Zeros(BaseProc):
  """Create dataset in HDF5 file. Fill the array-like dataset with zeros. Mainly used
  for testing purposes only."""
  # 25/02/2011
  version = '09/04/2011'
  usage = '%prog [options] filename'
  argtype = None
  nif = 0
  niof = 0
  nof = 1

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-n', '--name', dest='name', default='zeros', type=str, help='set name of the dataset')
    self.op.add_option('-s', '--shape', dest='shape', default='10', type=str, help='set shape of the array. Separate dimensions by commas')
    self.op.add_option('-d', '--dtype', dest='dtype', default='float', type=str, help='set data type of the array')

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)

    # Load data (even if there is not any, because we need fout to be filled)
    self.load()

    # Check options
    shape = tuple(opt2list(self.opts.shape))

    # Create dataset
    self.dout[self.opts.name] = np.zeros(shape, dtype=self.opts.dtype)

    # Save dataset
    return self.save(shellmode=True)





class _Me(CalcProc):
  """Determine band edges and mobility edges.

  Input: Systems that only differ in the system size.
  Output: Band edges and mobility edges for this particular disorder strength."""
  # 06/06/2011
  version = '06/06/2011'
  epilog = """Future visions:
  - different methods"""
  usage = '%prog [options] input_filenames output_filename'

  def __init__(self):
    CalcProc.__init__(self)

    # Set options
    self.op.add_option('-c', '--cutoff', default=None, type=float, dest='cutoff', help='set custom cutoff. Otherwise, a suitable cutoff is determined from the data')


  def __call__(self, *args, **kwargs):
    CalcProc.__call__(self, *args, **kwargs)

    # Check options
    assert self.opts.cutoff is None or self.opts.cutoff > 0., 'cutoff must be positive float'

    # Load data
    self.load('ados_dens', 'ados_energ', 'gdos_dens', 'gdos_energ')

    # Set cutoff
    if self.opts.cutoff is not None:
      cutoff = self.opts.cutoff
    else:
      # The idea of finding a suitable cutoff is to take the first and the last
      # values of all input densities and use their maximum (plus an additional
      # percentage to be sure)
      values = []
      for data in self.din:
        values.append(data.ados_dens[0])
        values.append(data.ados_dens[-1])
        values.append(data.gdos_dens[0])
        values.append(data.gdos_dens[-1])
      cutoff = abs(max(values))*1.01

    # Determine system sizes
    sizes = []
    for param in self.pin:
      sizes.append(np.prod(param.shape))
    sizes = np.array(sizes)
    msind = np.argmax(sizes) # maximum size index

    # Read off band edges (ADOS)
    a = np.diff(np.sign(self.din[msind].ados_dens-cutoff))
    self.dout.me_lbe = self.din[msind].ados_energ[a < 0] # list of left band edges
    self.dout.me_rbe = self.din[msind].ados_energ[a > 0] # list of right band edges
    # length of lbe or rbe is equal to the number of bands that have been found

    if self.opts.verbose:
      dump(lbe=self.dout.me_lbe, rbe=self.dout.me_rbe, msind=msind, ms=max(sizes), sizes=sizes, cutoff=cutoff)

    # Read off mobility edges for each system size (GDOS)
    lmes, rmes = [], []
    for data in self.din:
      a = np.diff(np.sign(data.gdos_dens-cutoff))
      lmes.append(data.gdos_energ[a < 0]) # list of left mobility edges (from localized to metallic)
      rmes.append(data.gdos_energ[a > 0]) # list of right mobility edges (from metallic to localized)

    lmes = np.array(lmes)
    rmes = np.array(rmes)

    if self.opts.verbose:
      dump(lmes=lmes, rmes=rmes)

    # Make 1/N fit to determine the mobility edges in the limit of infinite system size
    #m = Model(lambda x, p: 1-p[0]/(x-p[1]), strrep='f(x) = 1 - %.3e/(x - %.3e)', est=(1., -1.))
    m = Model(lambda x, p: p[0]/x+p[1], strrep='f(x) = %.3e/x + %.3e', est=(1., -1.)) # Shifted inverse function

    lme, rme = [], []
    for i in xrange(lmes.shape[1]):
      # Extrapolate left mobility edges
      m.leastsq(sizes, lmes[:, i])
      lme.append(m.param()[1])

      #import matplotlib.pyplot as plt

      #plt.figure()
      #plt.plot(sizes, lmes[:, i], 'o')
      #m.plot(fmt='r--', xnum=1000)
      #dump(m=m, sumls=m.sumls(), nfev=m.nfev(), mesg=m.mesg())

      # Extrapolate right mobility edges
      m.leastsq(sizes, rmes[:, i])
      rme.append(m.param()[1])

      #plt.figure()
      #plt.plot(sizes, rmes[:, i], 'o')
      #m.plot(fmt='r--', xnum=1000)
      #dump(m=m, sumls=m.sumls(), nfev=m.nfev(), mesg=m.mesg())

      #plt.show()
      #sys.exit()

    self.dout.me_lme = np.array(lme)
    self.dout.me_rme = np.array(rme)

    if self.opts.verbose:
      dump(lme=self.dout.me_lme, rme=self.dout.me_rme)


    # Add comments
    self.cout.cutoff = float(cutoff)

    # Save data
    self.save()


class _Loop(BaseProc):
  """Execute a command line multiple times, each time substituting certain
  numbers or characters.

  This is something like a for-loop on shell level. It can also work as a
  parallel for-loop (process-based parallelization) since the commands will
  be independent from each other in most cases.

  Note that loop commands can also be nested, what can be extremely convenient
  in some situations."""
  # 07/06/2011
  # former multiple.py from 02/12/2009-06/09/2010
  version = '07/06/2011'
  usage = '%prog [options] command_line'
  nif = nof = niof = 0
  epilog = """Future visions:
  - smarter way of status report, using carriage return, or even the curses
    module, allowing multiple output areas on the screen"""

  def __init__(self):
    BaseProc.__init__(self)

    # Set options
    self.op.add_option('-r', '--range', dest='range', default=None, type=str, help='iterate over integers, given by a common range definition (up to three values separated by colons). Multiple ranges may be specified, separated by commas.')
    self.op.add_option('-l', '--list', dest='list', default=None, type=str, help='iterate over a list of integers, separated by commas. May also contain range-like definitions with colons (however, the value after the second colon is restricted to positive integers only). Always runs over the cumulative sorted list of all values, where each value occures just once.')
    self.op.add_option('-a', '--abc', dest='abc', default=None, type=str, help='iterate over characters')
    self.op.add_option('-w', '--word', dest='word', default=None, type=str, help='iterate over words. Use commas to separate the words from each other')

    self.op.add_option('-c', '--char', dest='char', default='#', type=str, help='set character that will be substituted in the command line')
    self.op.add_option('-f', '--fill', dest='fill', default='0', type=str, help='set character that will be used to fill up unused space in the string representation of shorter numbers')

    self.op.add_option('-n', '--number-of-processes', dest='np', default=1, type=int, help='set number of processes that will be used. If greater than one, this process will only serve as a mother process starting and observing the other processes in the background. If set to 0, try to detect the number of CPU cores of this machine.')

    self.op.add_option('-s', '--sleep', dest='sleep', default=1., type=float, help='set time to sleep (in seconds) before checking the states of the subprocesses again')
    #self.op.add_option('-m', '--multiply',

    # Disable interspersed positional arguments. All options for this script
    # have to be specified in front of the command line that will be executed
    # in the loop.
    self.op.disable_interspersed_args()

  def __call__(self, *args, **kwargs):
    BaseProc.__call__(self, *args, **kwargs)
    import subprocess as sub

    # Check options
    assert len(self.opts.char) == 1, 'bad substitution character: %c. Only single character allowed' % self.opts.char
    assert len(self.opts.fill) == 1, 'bad filling character: %c. Only single character allowed' % self.opts.fill
    assert self.opts.np >= 0, 'bad number of processes: %i. Must be non-negative integer' % self.opts.np
    if self.opts.np == 0:
      self.opts.np = npc()
    assert self.opts.sleep > 0., 'bad sleeping time: %.3f. Must be positive float' % self.opts.sleep

    # Distinguish different modes (range, list, abc, word) and define list of
    # values
    if self.opts.range is not None:
      values = []
      ranges = self.opts.range.split(',')
      for r in ranges:
        values += range(*[int(value) if value != '' else 0 for value in r.split(':')])
    elif self.opts.list is not None:
      values = opt2ranges(self.opts.list)
    elif self.opts.abc is not None:
      values = [char for char in self.opts.abc]
    elif self.opts.word is not None:
      values = self.opts.word.split(',')
    else:
      self.op.error('no mode selected. Exactly one of the options range, list, abc or word must be specified. Append \'--help\' for help')
    values = [str(value) for value in values]
    if len(values) == 0:
      return

    # Build list of commands that have to be executed
    maxlen = max([len(value) for value in values])
    commands = []
    for value in values:
      cargs = []
      for arg in self.args:
        ind0 = 0
        if arg == '':
          arg = '\'\''
        while ind0 < len(arg):
          if arg[ind0] == self.opts.char:
            # Found the beginning of a substitution section
            left = ind0

            # Find end of the substitution section
            ind1 = left
            while ind1 < len(arg) and arg[ind1] == self.opts.char:
              ind1 += 1
            right = ind1

            if right-left < maxlen:
              self.op.error('Not enough substitution characters (%c) specified in the command line. At least %i are needed for the given values' % (self.opts.char, maxlen))
            withzeros = expandstr(value, length=right-left, char=self.opts.fill, flip=True)
            arg = arg[:left]+withzeros+arg[right:]
            ind0 = right
          ind0 += 1
        cargs.append(arg)
      command = ' '.join(cargs)
      commands.append(command)

    # Execute command lines
    if self.opts.np == 1:
      # Just execute the command lines consecutively in this process
      for command in commands:
        if self.opts.verbose:
          print '>', command
        os.system(command) #'source ~/.bashrc;%s' % command
    else:
      # Spawn subprocesses
      procs = [None for pind in range(self.opts.np)] # Status of the processes
      if self.opts.verbose and self.opts.np > 1:
        print 'using %i processes' % self.opts.np
      while len(commands) > 0:
        for pind in xrange(len(procs)):
          if procs[pind] == None or procs[pind].poll() != None:
            # Process has finished, let's start a new one

            # If there are more processes than command lines, the list of
            # commands may already be empty. Check that:
            if len(commands) == 0:
              continue

            # Select next command
            command = commands.pop(0)

            # Start new process
            procs[pind] = sub.Popen(command, shell=True) #'source ~/.bashrc;%s' % command
            if self.opts.verbose:
              if self.opts.np == 1:
                prompt = '>'
              else:
                prompt = 'proc%d>' % int(pind+1)
              print prompt, command

        # Wait some time before checking the process states again
        #if self.opts.np > 1:
        time.sleep(self.opts.sleep)

      # Finally, wait for all processes to finish
      for pind, proc in enumerate(procs):
        if proc != None:
          if self.opts.verbose and proc.poll() == None:
            print 'waiting for proc%d to finish...' % int(pind+1)
          proc.wait()






#=============================================#
# Automatically instanciate processor classes #
#=============================================#

proclist = []
for name in globals().keys():
  # Exclude certain classes
  if name in noprocs:
    continue

  # Is it a class?
  if inspect.isclass(eval(name)):
    if name[0] == '_' and name[1:] == capitalize(name[1:]): # Is this condition enough to identify the processor classes?
      globals()[name[1:].lower()] = eval(name)()
      proclist.append(name[1:].lower())
proclist.sort()





#=====================================#
# If this module is directly executed #
#=====================================#

if __name__ == '__main__':
  """What can we do here in the future?
  Maybe show a menu to select a function and get guidance what input is
  needed (interavtive use of the module)."""
  # 06/01/2011-07/02/2011

  # Execute command line (assume first argument to be the name of the script,
  # and the rest as arguments of that script)
  if len(sys.argv) > 1:
    sys.argv = sys.argv[1:]
    call()
  else:
    print __doc__
    print
    print 'List of available commands:'
    printcols(proclist)
    print
    print 'Get help for each command using --help or -h'
    print 'Example: tb ldos -h'
    print 'Or if ldos has it\'s own script file: ldos -h'